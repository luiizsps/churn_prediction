{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiizsps/AI_challenge/blob/main/Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prevendo Costumer Churn com Redes Neurais\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Introdução\n",
        "\n",
        "Utilizaremos o dataset churn.csv e um modelo de classificação binária, implementado através de redes neurais para prever o churn (cancelamento) de serviço por parte de clientes de uma empresa."
      ],
      "metadata": {
        "id": "BNpS-0puokv6"
      },
      "id": "BNpS-0puokv6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Etapas:\n",
        "####1 - Entendendo os dados\n",
        "Para começar, precisamos visualizar o dataset, entender as features que ele possui e sua distribuição. \n",
        "####2 - Pré-processamento\n",
        "Antes de utilização dos dados, é necessário transformar os dados categóricos em numéricos e verificar problemas na base de dados, como valores faltando ou outlines.\n",
        "####3 - Escolha das features\n",
        "Nesta etapa, esolheremos as features dos clientes que estão mais diretamente relacionadas ao churn para treinar nosso modelo.\n",
        "####4 - Normalização\n",
        "Antes de passar os dados pela rede neural, precisamos normalizá-los, a fim de evitar grande diferença de escala entre as features.\n",
        "####5 - Calibrando os hiperparâmetros\n",
        "Escolhendo importantes parâmetros para nossa rede neural, tais como: batch size, número de épocas e optimizador.\n",
        "####6 - Treinando o modelo\n",
        "Finalmente, chegamos à etapa de treinamento do modelo, passando as features e hiperparâmetros escolhidos para nossa rede neural.\n",
        "####7 - Resultados\n",
        "Por fim, avaliaremos nosso modelo atrvés das métricas escolhidas e interpretaremos os resultados.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7q2t1J3RuvJD"
      },
      "id": "7q2t1J3RuvJD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Entendendo os dados\n",
        "\n"
      ],
      "metadata": {
        "id": "KNjwogil03jc"
      },
      "id": "KNjwogil03jc"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8bd5d609",
      "metadata": {
        "id": "8bd5d609",
        "outputId": "07faab5d-3b98-4f1c-eaf0-cdf98229630a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  Female              0     Yes         No       1           No   \n",
              "1    Male              0      No         No      34          Yes   \n",
              "2    Male              0      No         No       2          Yes   \n",
              "3    Male              0      No         No      45           No   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
              "0  No phone service             DSL             No          Yes   \n",
              "1                No             DSL            Yes           No   \n",
              "2                No             DSL            Yes          Yes   \n",
              "3  No phone service             DSL            Yes           No   \n",
              "\n",
              "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
              "0               No          No          No              No  Month-to-month   \n",
              "1              Yes          No          No              No        One year   \n",
              "2               No          No          No              No  Month-to-month   \n",
              "3              Yes         Yes          No              No        One year   \n",
              "\n",
              "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
              "0              Yes           Electronic check           29.85        29.85   \n",
              "1               No               Mailed check           56.95       1889.5   \n",
              "2              Yes               Mailed check           53.85       108.15   \n",
              "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
              "\n",
              "  Churn  \n",
              "0    No  \n",
              "1    No  \n",
              "2   Yes  \n",
              "3    No  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db20edd9-6039-4af7-81ae-3c16fde22bd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db20edd9-6039-4af7-81ae-3c16fde22bd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db20edd9-6039-4af7-81ae-3c16fde22bd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db20edd9-6039-4af7-81ae-3c16fde22bd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# importa o dataset\n",
        "import pandas as pd\n",
        " \n",
        "path = r\"churn.csv\" \n",
        "df = pd.read_csv(path)\n",
        "df.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "a6a987bb",
      "metadata": {
        "id": "a6a987bb",
        "outputId": "9e3d9e82-c7f5-4577-a0c4-072bc15d371b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5174\n",
              "1    1869\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Exibe a distribuição dos dados das variáveis depedendentes\n",
        "df['Churn'].value_counts().plot.bar(color=['blue','red'])\n",
        "df['Churn'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nosso dataset possui um problema de balanceamento. Podemos observar atrvés do gráfico acima que somente 26,5% dos dados são de usuários que cancelaram o serviço. Isso significa que se o nosso modelo prever que nenhum usuário cancelou o serviço, a precisão do modelo é de 73,5%. Vamos voltar a este tópico posteriormente."
      ],
      "metadata": {
        "id": "eyAzGNUI1fuG"
      },
      "id": "eyAzGNUI1fuG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Pré-processamento"
      ],
      "metadata": {
        "id": "h5VnJqzPCwUj"
      },
      "id": "h5VnJqzPCwUj"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f384b15c",
      "metadata": {
        "id": "f384b15c",
        "outputId": "321c9adb-3952-44e3-fea1-450f183a057f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       1\n",
              "       ..\n",
              "7038    0\n",
              "7039    0\n",
              "7040    0\n",
              "7041    1\n",
              "7042    0\n",
              "Name: Churn, Length: 7043, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Transforma os dados categóricos do alvo y em dados numéricos\n",
        "df['Churn'] = [0 if x == 'No' else 1 for x in df['Churn']]\n",
        "df['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d2062fdd",
      "metadata": {
        "id": "d2062fdd",
        "outputId": "9499e407-510d-48e2-c8c6-3b6dc259e5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  Female              0     Yes         No       1           No   \n",
              "1    Male              0      No         No      34          Yes   \n",
              "2    Male              0      No         No       2          Yes   \n",
              "3    Male              0      No         No      45           No   \n",
              "4  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
              "0  No phone service             DSL             No          Yes   \n",
              "1                No             DSL            Yes           No   \n",
              "2                No             DSL            Yes          Yes   \n",
              "3  No phone service             DSL            Yes           No   \n",
              "4                No     Fiber optic             No           No   \n",
              "\n",
              "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
              "0               No          No          No              No  Month-to-month   \n",
              "1              Yes          No          No              No        One year   \n",
              "2               No          No          No              No  Month-to-month   \n",
              "3              Yes         Yes          No              No        One year   \n",
              "4               No          No          No              No  Month-to-month   \n",
              "\n",
              "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n",
              "0              Yes           Electronic check           29.85        29.85  \n",
              "1               No               Mailed check           56.95       1889.5  \n",
              "2              Yes               Mailed check           53.85       108.15  \n",
              "3               No  Bank transfer (automatic)           42.30      1840.75  \n",
              "4              Yes           Electronic check           70.70       151.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5baada68-0759-4fe0-a321-cb60b47d61b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5baada68-0759-4fe0-a321-cb60b47d61b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5baada68-0759-4fe0-a321-cb60b47d61b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5baada68-0759-4fe0-a321-cb60b47d61b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Separa a coluna de 'churn' do dataset\n",
        "df_x = df.drop('Churn', axis=1)\n",
        "df_y = df['Churn']\n",
        "\n",
        "df_x.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "937ac3d1",
      "metadata": {
        "id": "937ac3d1",
        "outputId": "c18591b2-0e2f-4a96-9f35-87f4e1010b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender tem 2 categorias únicas\n",
            "Partner tem 2 categorias únicas\n",
            "Dependents tem 2 categorias únicas\n",
            "PhoneService tem 2 categorias únicas\n",
            "MultipleLines tem 3 categorias únicas\n",
            "InternetService tem 3 categorias únicas\n",
            "OnlineSecurity tem 3 categorias únicas\n",
            "OnlineBackup tem 3 categorias únicas\n",
            "DeviceProtection tem 3 categorias únicas\n",
            "TechSupport tem 3 categorias únicas\n",
            "StreamingTV tem 3 categorias únicas\n",
            "StreamingMovies tem 3 categorias únicas\n",
            "Contract tem 3 categorias únicas\n",
            "PaperlessBilling tem 2 categorias únicas\n",
            "PaymentMethod tem 4 categorias únicas\n",
            "TotalCharges tem 6531 categorias únicas\n"
          ]
        }
      ],
      "source": [
        "# Função que analisa os dados categóricos\n",
        "def catergorias_unicas(df):\n",
        "  for nome_coluna in df.columns:\n",
        "    if df[nome_coluna].dtype == 'object':\n",
        "      num_categorias_unicas = len(df[nome_coluna].unique())\n",
        "      print(f\"{nome_coluna} tem {num_categorias_unicas} categorias únicas\")\n",
        "\n",
        "catergorias_unicas(df_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao passar pelo contador de categorias únicas, a feature 'TotalCharges' foi identificada como do tipo 'object', o que indica que essa coluna possui dados faltando."
      ],
      "metadata": {
        "id": "_0wijS6D3e5c"
      },
      "id": "_0wijS6D3e5c"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b3aea91b",
      "metadata": {
        "id": "b3aea91b",
        "outputId": "b4e0f622-10a7-4e44-e9ff-082690f313ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         29.85\n",
              "1       1889.50\n",
              "2        108.15\n",
              "3       1840.75\n",
              "4        151.65\n",
              "         ...   \n",
              "7038    1990.50\n",
              "7039    7362.90\n",
              "7040     346.45\n",
              "7041     306.60\n",
              "7042    6844.50\n",
              "Name: TotalCharges, Length: 7043, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Substitui os dados faltando por 0.\n",
        "x = df_x['TotalCharges']\n",
        "x = x.replace({\" \": 0})\n",
        "x = pd.to_numeric(x)\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0681b8ad",
      "metadata": {
        "id": "0681b8ad",
        "outputId": "a5c5d703-661e-43dd-932d-81adb81453be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         29.85\n",
              "1       1889.50\n",
              "2        108.15\n",
              "3       1840.75\n",
              "4        151.65\n",
              "         ...   \n",
              "7038    1990.50\n",
              "7039    7362.90\n",
              "7040     346.45\n",
              "7041     306.60\n",
              "7042    6844.50\n",
              "Name: TotalCharges, Length: 7043, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_x = df_x.drop('TotalCharges', axis=1)\n",
        "df_x['TotalCharges'] = x\n",
        "\n",
        "df_x['TotalCharges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0be03340",
      "metadata": {
        "id": "0be03340",
        "outputId": "4e99e69b-e0aa-4513-a4da-74f079cab234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SeniorCitizen  tenure  MonthlyCharges  TotalCharges  gender_Female  \\\n",
              "0              0       1           29.85         29.85              1   \n",
              "1              0      34           56.95       1889.50              0   \n",
              "2              0       2           53.85        108.15              0   \n",
              "3              0      45           42.30       1840.75              0   \n",
              "4              0       2           70.70        151.65              1   \n",
              "\n",
              "   gender_Male  Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  ...  \\\n",
              "0            0           0            1              1               0  ...   \n",
              "1            1           1            0              1               0  ...   \n",
              "2            1           1            0              1               0  ...   \n",
              "3            1           1            0              1               0  ...   \n",
              "4            0           1            0              1               0  ...   \n",
              "\n",
              "   StreamingMovies_Yes  Contract_Month-to-month  Contract_One year  \\\n",
              "0                    0                        1                  0   \n",
              "1                    0                        0                  1   \n",
              "2                    0                        1                  0   \n",
              "3                    0                        0                  1   \n",
              "4                    0                        1                  0   \n",
              "\n",
              "   Contract_Two year  PaperlessBilling_No  PaperlessBilling_Yes  \\\n",
              "0                  0                    0                     1   \n",
              "1                  0                    1                     0   \n",
              "2                  0                    0                     1   \n",
              "3                  0                    1                     0   \n",
              "4                  0                    0                     1   \n",
              "\n",
              "   PaymentMethod_Bank transfer (automatic)  \\\n",
              "0                                        0   \n",
              "1                                        0   \n",
              "2                                        0   \n",
              "3                                        1   \n",
              "4                                        0   \n",
              "\n",
              "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
              "0                                      0                               1   \n",
              "1                                      0                               0   \n",
              "2                                      0                               0   \n",
              "3                                      0                               0   \n",
              "4                                      0                               1   \n",
              "\n",
              "   PaymentMethod_Mailed check  \n",
              "0                           0  \n",
              "1                           1  \n",
              "2                           1  \n",
              "3                           0  \n",
              "4                           0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-904f2c28-c368-4467-be9c-25438d9748d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>tenure</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>gender_Female</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>Partner_No</th>\n",
              "      <th>Partner_Yes</th>\n",
              "      <th>Dependents_No</th>\n",
              "      <th>Dependents_Yes</th>\n",
              "      <th>...</th>\n",
              "      <th>StreamingMovies_Yes</th>\n",
              "      <th>Contract_Month-to-month</th>\n",
              "      <th>Contract_One year</th>\n",
              "      <th>Contract_Two year</th>\n",
              "      <th>PaperlessBilling_No</th>\n",
              "      <th>PaperlessBilling_Yes</th>\n",
              "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
              "      <th>PaymentMethod_Credit card (automatic)</th>\n",
              "      <th>PaymentMethod_Electronic check</th>\n",
              "      <th>PaymentMethod_Mailed check</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-904f2c28-c368-4467-be9c-25438d9748d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-904f2c28-c368-4467-be9c-25438d9748d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-904f2c28-c368-4467-be9c-25438d9748d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# A função get_dummies transforma os dados categóricos de uma coluna em novas colunas\n",
        "to_dummy_list = ['gender', 'Partner', 'Dependents', 'PhoneService','MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "def to_dummy(df, to_dummy_list):\n",
        "  for x in to_dummy_list:\n",
        "    dummies = pd.get_dummies(df[x], prefix=x, dummy_na=False)\n",
        "    df = df.drop(x, axis=1)\n",
        "    df = pd.concat([df, dummies], axis=1)\n",
        "  return df\n",
        "\n",
        "df_x = to_dummy(df_x, to_dummy_list)\n",
        "df_x.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d0a0d844",
      "metadata": {
        "id": "d0a0d844",
        "outputId": "b47c9833-276e-4e06-983c-01557ecfa36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender            0\n",
            "SeniorCitizen     0\n",
            "TotalCharges      0\n",
            "MonthlyCharges    0\n",
            "PaymentMethod     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Verificando se nosso dataset ainda possui dados faltando\n",
        "print(df.isnull().sum().sort_values(ascending=False).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e952ea3a",
      "metadata": {
        "id": "e952ea3a",
        "outputId": "ee6ff409-aa5c-4d55-f4b6-b82d38ff29fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Usando o algoritmo TukeyIQR para identificar outliers\n",
        "import numpy as np\n",
        "\n",
        "def find_ouliers_turkey(x):\n",
        "  q1 = np.percentile(x,25)\n",
        "  q3 = np.percentile(x,75)\n",
        "  iqr = q3 - q1\n",
        "  floor = q1 - 1.5*iqr\n",
        "  ceiling = q3 + 1.5*iqr\n",
        "  outlier_indicies = list(x.index[(x < floor) | (x > ceiling)])\n",
        "  outlier_values = list(x[outlier_indicies])\n",
        "  \n",
        "  return outlier_indicies, outlier_values\n",
        "\n",
        "outlier_indicies, outlier_values = find_ouliers_turkey(df_x['TotalCharges'])\n",
        "print(outlier_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6c731eb8",
      "metadata": {
        "id": "6c731eb8",
        "outputId": "b3092586-0e28-422a-a17b-efb8a2d3569d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "outlier_indicies, outlier_values = find_ouliers_turkey(df_x['tenure'])\n",
        "print(outlier_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O identificador de outliers procura por dados que se afstem muito dos valores médios, para evitar que estes prejudiquem nosso modelo."
      ],
      "metadata": {
        "id": "kmSlk1b04met"
      },
      "id": "kmSlk1b04met"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "04a6dd93",
      "metadata": {
        "id": "04a6dd93"
      },
      "outputs": [],
      "source": [
        "# Agora dividimos o dataset em conjuntos de treino, teste e validação.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.30, random_state=5, stratify=df_y)\n",
        "x_test, x_validation, y_test, y_validation = train_test_split(x_test, y_test, test_size=0.5, random_state=2, stratify=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao dividirmos o dataset, precisamos nos atentar novamente ao problema de desabalanceamento, nosso conjunto de validação precisa ser representativo do conjunto de teste. Para isso serve o parâmetro 'stratify', ele vai garantir que a proporção dos dados seja mantida. "
      ],
      "metadata": {
        "id": "Nhm5zVpy496b"
      },
      "id": "Nhm5zVpy496b"
    },
    {
      "cell_type": "code",
      "source": [
        "y_validation.value_counts() / y_validation.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCJCQhyA_Tt3",
        "outputId": "e2582912-8b32-46f3-caf7-98e4d70b1bf6"
      },
      "id": "lCJCQhyA_Tt3",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.734153\n",
              "1    0.265847\n",
              "Name: Churn, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Escolha das features"
      ],
      "metadata": {
        "id": "d98gE_Ecwtds"
      },
      "id": "d98gE_Ecwtds"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4e61738f",
      "metadata": {
        "id": "4e61738f",
        "outputId": "f3b08a2a-5468-4758-9be0-94133ad21a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tenure', 'MonthlyCharges', 'TotalCharges', 'InternetService_Fiber optic', 'InternetService_No', 'OnlineSecurity_No', 'OnlineSecurity_No internet service', 'OnlineBackup_No', 'OnlineBackup_No internet service', 'DeviceProtection_No', 'DeviceProtection_No internet service', 'TechSupport_No', 'TechSupport_No internet service', 'StreamingTV_No internet service', 'StreamingMovies_No internet service', 'Contract_Month-to-month', 'Contract_Two year', 'PaperlessBilling_No', 'PaperlessBilling_Yes', 'PaymentMethod_Electronic check']\n"
          ]
        }
      ],
      "source": [
        "# Seleciona as features que melhor se relacionam com o churn\n",
        "import sklearn.feature_selection\n",
        "\n",
        "select = sklearn.feature_selection.SelectKBest(k=20)\n",
        "selected_features = select.fit(x_train, y_train)\n",
        "indicies_selected = selected_features.get_support(indices=True)\n",
        "colnames_selected = [df_x.columns[i] for i in indicies_selected]\n",
        "\n",
        "x_train = x_train[colnames_selected]\n",
        "x_test = x_test[colnames_selected]\n",
        "x_validation = x_validation[colnames_selected]\n",
        "\n",
        "print(colnames_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "16e95b4b",
      "metadata": {
        "id": "16e95b4b",
        "outputId": "eb0bfe8c-5b55-44bb-9cb9-f4d984ae891b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# heatmap que exibe relação entre as features selecionadas e o churn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn \n",
        "\n",
        "x_train['Churn'] = y_train\n",
        "seaborn.heatmap(x_train.corr(),\n",
        "            cmap='Blues')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "55c021fb",
      "metadata": {
        "id": "55c021fb",
        "outputId": "1b2c43ce-4e39-40f8-a9b4-38087aa98e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      tenure  MonthlyCharges  TotalCharges  InternetService_Fiber optic  \\\n",
              "5974      10           20.05        218.50                            0   \n",
              "2954       7           75.45        480.75                            1   \n",
              "1329      72           19.40       1496.45                            0   \n",
              "1549       1           45.85         45.85                            0   \n",
              "4377      22           80.00       1706.45                            1   \n",
              "...      ...             ...           ...                          ...   \n",
              "2792      15           48.85        736.80                            0   \n",
              "6881      32           35.15       1051.05                            0   \n",
              "2906       6           48.80        297.35                            0   \n",
              "2823      39           20.45        790.00                            0   \n",
              "6643       3           74.60        239.05                            1   \n",
              "\n",
              "      InternetService_No  OnlineSecurity_No  \\\n",
              "5974                   1                  0   \n",
              "2954                   0                  1   \n",
              "1329                   1                  0   \n",
              "1549                   0                  1   \n",
              "4377                   0                  1   \n",
              "...                  ...                ...   \n",
              "2792                   0                  1   \n",
              "6881                   0                  0   \n",
              "2906                   0                  1   \n",
              "2823                   1                  0   \n",
              "6643                   0                  1   \n",
              "\n",
              "      OnlineSecurity_No internet service  OnlineBackup_No  \\\n",
              "5974                                   1                0   \n",
              "2954                                   0                1   \n",
              "1329                                   1                0   \n",
              "1549                                   0                1   \n",
              "4377                                   0                1   \n",
              "...                                  ...              ...   \n",
              "2792                                   0                0   \n",
              "6881                                   0                0   \n",
              "2906                                   0                1   \n",
              "2823                                   1                0   \n",
              "6643                                   0                0   \n",
              "\n",
              "      OnlineBackup_No internet service  DeviceProtection_No  \\\n",
              "5974                                 1                    0   \n",
              "2954                                 0                    1   \n",
              "1329                                 1                    0   \n",
              "1549                                 0                    1   \n",
              "4377                                 0                    1   \n",
              "...                                ...                  ...   \n",
              "2792                                 0                    1   \n",
              "6881                                 0                    1   \n",
              "2906                                 0                    1   \n",
              "2823                                 1                    0   \n",
              "6643                                 0                    1   \n",
              "\n",
              "      DeviceProtection_No internet service  TechSupport_No  \\\n",
              "5974                                     1               0   \n",
              "2954                                     0               1   \n",
              "1329                                     1               0   \n",
              "1549                                     0               1   \n",
              "4377                                     0               1   \n",
              "...                                    ...             ...   \n",
              "2792                                     0               1   \n",
              "6881                                     0               1   \n",
              "2906                                     0               0   \n",
              "2823                                     1               0   \n",
              "6643                                     0               1   \n",
              "\n",
              "      TechSupport_No internet service  StreamingTV_No internet service  \\\n",
              "5974                                1                                1   \n",
              "2954                                0                                0   \n",
              "1329                                1                                1   \n",
              "1549                                0                                0   \n",
              "4377                                0                                0   \n",
              "...                               ...                              ...   \n",
              "2792                                0                                0   \n",
              "6881                                0                                0   \n",
              "2906                                0                                0   \n",
              "2823                                1                                1   \n",
              "6643                                0                                0   \n",
              "\n",
              "      StreamingMovies_No internet service  Contract_Month-to-month  \\\n",
              "5974                                    1                        1   \n",
              "2954                                    0                        1   \n",
              "1329                                    1                        0   \n",
              "1549                                    0                        1   \n",
              "4377                                    0                        1   \n",
              "...                                   ...                      ...   \n",
              "2792                                    0                        1   \n",
              "6881                                    0                        1   \n",
              "2906                                    0                        1   \n",
              "2823                                    1                        0   \n",
              "6643                                    0                        1   \n",
              "\n",
              "      Contract_Two year  PaperlessBilling_No  PaperlessBilling_Yes  \\\n",
              "5974                  0                    0                     1   \n",
              "2954                  0                    1                     0   \n",
              "1329                  1                    1                     0   \n",
              "1549                  0                    0                     1   \n",
              "4377                  0                    0                     1   \n",
              "...                 ...                  ...                   ...   \n",
              "2792                  0                    1                     0   \n",
              "6881                  0                    0                     1   \n",
              "2906                  0                    0                     1   \n",
              "2823                  1                    0                     1   \n",
              "6643                  0                    0                     1   \n",
              "\n",
              "      PaymentMethod_Electronic check  \n",
              "5974                               0  \n",
              "2954                               0  \n",
              "1329                               0  \n",
              "1549                               0  \n",
              "4377                               0  \n",
              "...                              ...  \n",
              "2792                               1  \n",
              "6881                               1  \n",
              "2906                               0  \n",
              "2823                               0  \n",
              "6643                               0  \n",
              "\n",
              "[4930 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90949212-f55b-45e6-a747-949f2be6419f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenure</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>InternetService_Fiber optic</th>\n",
              "      <th>InternetService_No</th>\n",
              "      <th>OnlineSecurity_No</th>\n",
              "      <th>OnlineSecurity_No internet service</th>\n",
              "      <th>OnlineBackup_No</th>\n",
              "      <th>OnlineBackup_No internet service</th>\n",
              "      <th>DeviceProtection_No</th>\n",
              "      <th>DeviceProtection_No internet service</th>\n",
              "      <th>TechSupport_No</th>\n",
              "      <th>TechSupport_No internet service</th>\n",
              "      <th>StreamingTV_No internet service</th>\n",
              "      <th>StreamingMovies_No internet service</th>\n",
              "      <th>Contract_Month-to-month</th>\n",
              "      <th>Contract_Two year</th>\n",
              "      <th>PaperlessBilling_No</th>\n",
              "      <th>PaperlessBilling_Yes</th>\n",
              "      <th>PaymentMethod_Electronic check</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>10</td>\n",
              "      <td>20.05</td>\n",
              "      <td>218.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2954</th>\n",
              "      <td>7</td>\n",
              "      <td>75.45</td>\n",
              "      <td>480.75</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1329</th>\n",
              "      <td>72</td>\n",
              "      <td>19.40</td>\n",
              "      <td>1496.45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>1</td>\n",
              "      <td>45.85</td>\n",
              "      <td>45.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4377</th>\n",
              "      <td>22</td>\n",
              "      <td>80.00</td>\n",
              "      <td>1706.45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2792</th>\n",
              "      <td>15</td>\n",
              "      <td>48.85</td>\n",
              "      <td>736.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6881</th>\n",
              "      <td>32</td>\n",
              "      <td>35.15</td>\n",
              "      <td>1051.05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2906</th>\n",
              "      <td>6</td>\n",
              "      <td>48.80</td>\n",
              "      <td>297.35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2823</th>\n",
              "      <td>39</td>\n",
              "      <td>20.45</td>\n",
              "      <td>790.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6643</th>\n",
              "      <td>3</td>\n",
              "      <td>74.60</td>\n",
              "      <td>239.05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4930 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90949212-f55b-45e6-a747-949f2be6419f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90949212-f55b-45e6-a747-949f2be6419f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90949212-f55b-45e6-a747-949f2be6419f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x_train = x_train.drop('Churn', axis=1)\n",
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 - Normalização\n"
      ],
      "metadata": {
        "id": "zOnVzrEjyIP6"
      },
      "id": "zOnVzrEjyIP6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b83d29c",
      "metadata": {
        "id": "4b83d29c"
      },
      "outputs": [],
      "source": [
        "# Normalizando os dados\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bfe5f113",
      "metadata": {
        "id": "bfe5f113",
        "outputId": "343ea2c9-c927-4940-8524-61499871f624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.13888889, 0.01645885, 0.0251589 , 0.        , 1.        ,\n",
              "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
              "       1.        , 0.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "x_validation = scaler.transform(x_validation)\n",
        "\n",
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A normalização de dados transforma todas as entradas em uma mesma escala, neste caso, valores entre 0 e 1. "
      ],
      "metadata": {
        "id": "KtyJYU2QETUo"
      },
      "id": "KtyJYU2QETUo"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "993ab892",
      "metadata": {
        "id": "993ab892",
        "outputId": "9af1303a-7cc4-4186-c788-77b48d9aed29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7244, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# lidando com o desbalanceamento de dados no conjunto de treino\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "res = RandomOverSampler(random_state=42)\n",
        "x_train_res, y_train_res = res.fit_resample(x_train, y_train)\n",
        "\n",
        "x_train_res.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para lidar com o desbalanceamento dos dados, podemos utilizar duas técnicas: oversampling e undersampling. Escolhi utilizar oversampling, pois obtive melhor resultados com este método. A lógica por trás dos algoritmos é simples, o oversampling cria novas colunas baseando-se nas já existentes, enquanto que a undersampling exclue colunas. No fim, ambas garantem que o conjunto de dados seja balanceado, com 50% de entradas de usuários que cancelaram o serviço e 50% de usuários que não cancelaram. "
      ],
      "metadata": {
        "id": "_rTktwAMEzZS"
      },
      "id": "_rTktwAMEzZS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Calibrando os hiperparâmetros"
      ],
      "metadata": {
        "id": "WBmBuL79y3xJ"
      },
      "id": "WBmBuL79y3xJ"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "685d3f8e",
      "metadata": {
        "id": "685d3f8e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0e022f7d",
      "metadata": {
        "id": "0e022f7d"
      },
      "outputs": [],
      "source": [
        "def create_model(optimizer='adam'):\n",
        "    ann = Sequential()\n",
        "    ann.add(Dense(units=16, input_dim=20, activation='relu'))\n",
        "    ann.add(Dense(units=16, activation='relu'))\n",
        "    ann.add(Dense(units=1, activation='sigmoid'))\n",
        "    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b64b54",
      "metadata": {
        "id": "80b64b54"
      },
      "outputs": [],
      "source": [
        "# criando modelo temporário para grid search\n",
        "classifier = KerasClassifier(build_fn=create_model, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c37fb8dd",
      "metadata": {
        "id": "c37fb8dd",
        "outputId": "40a5189a-0a4a-4eb2-d9bb-c93508a67980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "46/46 - 1s - loss: 0.6604 - accuracy: 0.6175 - 1s/epoch - 26ms/step\n",
            "Epoch 2/100\n",
            "46/46 - 0s - loss: 0.5583 - accuracy: 0.7369 - 99ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "46/46 - 0s - loss: 0.5076 - accuracy: 0.7585 - 88ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "46/46 - 0s - loss: 0.4838 - accuracy: 0.7676 - 89ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7726 - 103ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "46/46 - 0s - loss: 0.4684 - accuracy: 0.7757 - 96ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "46/46 - 0s - loss: 0.4661 - accuracy: 0.7771 - 91ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "46/46 - 0s - loss: 0.4647 - accuracy: 0.7766 - 104ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "46/46 - 0s - loss: 0.4635 - accuracy: 0.7773 - 108ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "46/46 - 0s - loss: 0.4625 - accuracy: 0.7778 - 85ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "46/46 - 0s - loss: 0.4618 - accuracy: 0.7788 - 101ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "46/46 - 0s - loss: 0.4609 - accuracy: 0.7786 - 106ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "46/46 - 0s - loss: 0.4602 - accuracy: 0.7792 - 108ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7785 - 99ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7798 - 117ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "46/46 - 0s - loss: 0.4591 - accuracy: 0.7785 - 112ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "46/46 - 0s - loss: 0.4584 - accuracy: 0.7793 - 95ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7766 - 103ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7795 - 111ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "46/46 - 0s - loss: 0.4575 - accuracy: 0.7807 - 108ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "46/46 - 0s - loss: 0.4568 - accuracy: 0.7800 - 104ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "46/46 - 0s - loss: 0.4561 - accuracy: 0.7807 - 88ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "46/46 - 0s - loss: 0.4559 - accuracy: 0.7814 - 81ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "46/46 - 0s - loss: 0.4557 - accuracy: 0.7807 - 92ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "46/46 - 0s - loss: 0.4552 - accuracy: 0.7816 - 103ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "46/46 - 0s - loss: 0.4559 - accuracy: 0.7809 - 100ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "46/46 - 0s - loss: 0.4546 - accuracy: 0.7814 - 103ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "46/46 - 0s - loss: 0.4551 - accuracy: 0.7793 - 95ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "46/46 - 0s - loss: 0.4538 - accuracy: 0.7804 - 105ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "46/46 - 0s - loss: 0.4540 - accuracy: 0.7805 - 89ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "46/46 - 0s - loss: 0.4537 - accuracy: 0.7804 - 88ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "46/46 - 0s - loss: 0.4539 - accuracy: 0.7833 - 81ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "46/46 - 0s - loss: 0.4537 - accuracy: 0.7807 - 86ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7819 - 104ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7814 - 101ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7790 - 92ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "46/46 - 0s - loss: 0.4528 - accuracy: 0.7817 - 104ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "46/46 - 0s - loss: 0.4528 - accuracy: 0.7816 - 106ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "46/46 - 0s - loss: 0.4524 - accuracy: 0.7814 - 105ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "46/46 - 0s - loss: 0.4516 - accuracy: 0.7816 - 91ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "46/46 - 0s - loss: 0.4529 - accuracy: 0.7790 - 83ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "46/46 - 0s - loss: 0.4517 - accuracy: 0.7830 - 99ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "46/46 - 0s - loss: 0.4520 - accuracy: 0.7819 - 129ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "46/46 - 0s - loss: 0.4519 - accuracy: 0.7814 - 152ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7828 - 144ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "46/46 - 0s - loss: 0.4504 - accuracy: 0.7831 - 150ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7824 - 150ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "46/46 - 0s - loss: 0.4504 - accuracy: 0.7828 - 127ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "46/46 - 0s - loss: 0.4512 - accuracy: 0.7802 - 120ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "46/46 - 0s - loss: 0.4505 - accuracy: 0.7831 - 132ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "46/46 - 0s - loss: 0.4504 - accuracy: 0.7816 - 130ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "46/46 - 0s - loss: 0.4502 - accuracy: 0.7836 - 143ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7812 - 136ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "46/46 - 0s - loss: 0.4498 - accuracy: 0.7797 - 127ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "46/46 - 0s - loss: 0.4499 - accuracy: 0.7819 - 141ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "46/46 - 0s - loss: 0.4492 - accuracy: 0.7830 - 122ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7788 - 130ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "46/46 - 0s - loss: 0.4493 - accuracy: 0.7831 - 141ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "46/46 - 0s - loss: 0.4492 - accuracy: 0.7814 - 144ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "46/46 - 0s - loss: 0.4492 - accuracy: 0.7838 - 118ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "46/46 - 0s - loss: 0.4492 - accuracy: 0.7836 - 128ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "46/46 - 0s - loss: 0.4486 - accuracy: 0.7836 - 121ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7830 - 134ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "46/46 - 0s - loss: 0.4482 - accuracy: 0.7812 - 120ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7816 - 92ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7823 - 108ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "46/46 - 0s - loss: 0.4476 - accuracy: 0.7807 - 94ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "46/46 - 0s - loss: 0.4479 - accuracy: 0.7821 - 110ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "46/46 - 0s - loss: 0.4479 - accuracy: 0.7859 - 100ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7833 - 99ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "46/46 - 0s - loss: 0.4488 - accuracy: 0.7836 - 105ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "46/46 - 0s - loss: 0.4486 - accuracy: 0.7816 - 106ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "46/46 - 0s - loss: 0.4474 - accuracy: 0.7835 - 84ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7828 - 89ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "46/46 - 0s - loss: 0.4471 - accuracy: 0.7833 - 90ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "46/46 - 0s - loss: 0.4473 - accuracy: 0.7821 - 86ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "46/46 - 0s - loss: 0.4466 - accuracy: 0.7833 - 85ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "46/46 - 0s - loss: 0.4470 - accuracy: 0.7812 - 92ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7826 - 87ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "46/46 - 0s - loss: 0.4464 - accuracy: 0.7824 - 96ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7821 - 91ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "46/46 - 0s - loss: 0.4472 - accuracy: 0.7838 - 86ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7840 - 106ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "46/46 - 0s - loss: 0.4458 - accuracy: 0.7836 - 90ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7807 - 99ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "46/46 - 0s - loss: 0.4450 - accuracy: 0.7833 - 104ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7833 - 99ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "46/46 - 0s - loss: 0.4458 - accuracy: 0.7826 - 99ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7843 - 95ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "46/46 - 0s - loss: 0.4454 - accuracy: 0.7852 - 105ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "46/46 - 0s - loss: 0.4454 - accuracy: 0.7835 - 83ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "46/46 - 0s - loss: 0.4445 - accuracy: 0.7843 - 85ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7836 - 93ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7861 - 92ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7833 - 87ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "46/46 - 0s - loss: 0.4441 - accuracy: 0.7849 - 108ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "46/46 - 0s - loss: 0.4434 - accuracy: 0.7843 - 93ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "46/46 - 0s - loss: 0.4447 - accuracy: 0.7852 - 107ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "46/46 - 0s - loss: 0.4439 - accuracy: 0.7876 - 108ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "46/46 - 0s - loss: 0.4434 - accuracy: 0.7852 - 105ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.6425 - accuracy: 0.6561 - 216ms/epoch - 18ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6989 - accuracy: 0.4877 - 794ms/epoch - 17ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.6309 - accuracy: 0.7008 - 91ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.5989 - accuracy: 0.7384 - 85ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.5775 - accuracy: 0.7417 - 95ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.5598 - accuracy: 0.7439 - 84ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.5450 - accuracy: 0.7484 - 83ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.5334 - accuracy: 0.7532 - 86ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.5244 - accuracy: 0.7550 - 84ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.5173 - accuracy: 0.7565 - 83ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.5117 - accuracy: 0.7567 - 92ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.5074 - accuracy: 0.7575 - 81ms/epoch - 2ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.5039 - accuracy: 0.7600 - 81ms/epoch - 2ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.5011 - accuracy: 0.7612 - 94ms/epoch - 2ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.4987 - accuracy: 0.7632 - 80ms/epoch - 2ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.4967 - accuracy: 0.7634 - 90ms/epoch - 2ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.4950 - accuracy: 0.7629 - 107ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.4934 - accuracy: 0.7646 - 87ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.4921 - accuracy: 0.7648 - 88ms/epoch - 2ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.4909 - accuracy: 0.7648 - 97ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4899 - accuracy: 0.7624 - 91ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4889 - accuracy: 0.7648 - 87ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4880 - accuracy: 0.7648 - 81ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4871 - accuracy: 0.7660 - 79ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4862 - accuracy: 0.7664 - 92ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4856 - accuracy: 0.7682 - 85ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4849 - accuracy: 0.7682 - 97ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4843 - accuracy: 0.7676 - 91ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4837 - accuracy: 0.7682 - 94ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4832 - accuracy: 0.7672 - 87ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7695 - 91ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4822 - accuracy: 0.7688 - 104ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4818 - accuracy: 0.7682 - 101ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4814 - accuracy: 0.7691 - 85ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4810 - accuracy: 0.7693 - 94ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4807 - accuracy: 0.7698 - 82ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4804 - accuracy: 0.7698 - 82ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4800 - accuracy: 0.7717 - 91ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4796 - accuracy: 0.7695 - 90ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7691 - 89ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4790 - accuracy: 0.7698 - 86ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4787 - accuracy: 0.7686 - 84ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4785 - accuracy: 0.7701 - 103ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4782 - accuracy: 0.7696 - 107ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7695 - 79ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4777 - accuracy: 0.7705 - 91ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4773 - accuracy: 0.7689 - 81ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4772 - accuracy: 0.7691 - 89ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4769 - accuracy: 0.7684 - 88ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7688 - 91ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4765 - accuracy: 0.7696 - 88ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7696 - 89ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4762 - accuracy: 0.7682 - 103ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4759 - accuracy: 0.7696 - 89ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4757 - accuracy: 0.7686 - 87ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4755 - accuracy: 0.7689 - 81ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4753 - accuracy: 0.7691 - 131ms/epoch - 3ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4751 - accuracy: 0.7681 - 131ms/epoch - 3ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7701 - 117ms/epoch - 3ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7696 - 120ms/epoch - 3ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4748 - accuracy: 0.7684 - 126ms/epoch - 3ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4746 - accuracy: 0.7698 - 118ms/epoch - 3ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7695 - 112ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4743 - accuracy: 0.7686 - 111ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7691 - 138ms/epoch - 3ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7686 - 118ms/epoch - 3ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7693 - 118ms/epoch - 3ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4738 - accuracy: 0.7677 - 125ms/epoch - 3ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4738 - accuracy: 0.7695 - 132ms/epoch - 3ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7684 - 116ms/epoch - 3ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7672 - 113ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7684 - 115ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4733 - accuracy: 0.7681 - 116ms/epoch - 3ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4733 - accuracy: 0.7705 - 136ms/epoch - 3ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7689 - 135ms/epoch - 3ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4730 - accuracy: 0.7686 - 137ms/epoch - 3ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7689 - 137ms/epoch - 3ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7684 - 116ms/epoch - 3ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7691 - 108ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7688 - 97ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7688 - 105ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7689 - 95ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7689 - 82ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7681 - 84ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4721 - accuracy: 0.7689 - 84ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4721 - accuracy: 0.7693 - 82ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4720 - accuracy: 0.7686 - 94ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4718 - accuracy: 0.7696 - 76ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4717 - accuracy: 0.7684 - 75ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7689 - 78ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7695 - 88ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7703 - 81ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4715 - accuracy: 0.7693 - 81ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7679 - 87ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4712 - accuracy: 0.7686 - 80ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4711 - accuracy: 0.7686 - 79ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4710 - accuracy: 0.7695 - 81ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4711 - accuracy: 0.7696 - 87ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4709 - accuracy: 0.7698 - 83ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4707 - accuracy: 0.7696 - 80ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4707 - accuracy: 0.7707 - 80ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7676 - 75ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4707 - accuracy: 0.7714 - 91ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7705 - 79ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7679 - 93ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7703 - 84ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4703 - accuracy: 0.7705 - 80ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4702 - accuracy: 0.7686 - 88ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4702 - accuracy: 0.7686 - 101ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4701 - accuracy: 0.7707 - 90ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4701 - accuracy: 0.7688 - 80ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5420 - accuracy: 0.7129 - 189ms/epoch - 16ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6488 - accuracy: 0.6497 - 653ms/epoch - 14ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.6287 - accuracy: 0.6530 - 86ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.6117 - accuracy: 0.6538 - 82ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.5972 - accuracy: 0.6559 - 90ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.5856 - accuracy: 0.6626 - 89ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.5759 - accuracy: 0.6792 - 93ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.5677 - accuracy: 0.6970 - 91ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.5605 - accuracy: 0.7132 - 91ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.5541 - accuracy: 0.7234 - 104ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.5481 - accuracy: 0.7318 - 89ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.5425 - accuracy: 0.7386 - 89ms/epoch - 2ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.5372 - accuracy: 0.7443 - 89ms/epoch - 2ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.5323 - accuracy: 0.7484 - 92ms/epoch - 2ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.5279 - accuracy: 0.7520 - 84ms/epoch - 2ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.5238 - accuracy: 0.7546 - 91ms/epoch - 2ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.5201 - accuracy: 0.7603 - 108ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.5166 - accuracy: 0.7613 - 94ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.5134 - accuracy: 0.7626 - 91ms/epoch - 2ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.5105 - accuracy: 0.7632 - 101ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.5080 - accuracy: 0.7638 - 85ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.5057 - accuracy: 0.7643 - 87ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.5036 - accuracy: 0.7634 - 87ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.5017 - accuracy: 0.7636 - 80ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4999 - accuracy: 0.7627 - 80ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4983 - accuracy: 0.7619 - 89ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4970 - accuracy: 0.7622 - 101ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4957 - accuracy: 0.7626 - 104ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4945 - accuracy: 0.7627 - 95ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4934 - accuracy: 0.7636 - 97ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4924 - accuracy: 0.7645 - 87ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4914 - accuracy: 0.7639 - 87ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4907 - accuracy: 0.7658 - 83ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4898 - accuracy: 0.7653 - 79ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4890 - accuracy: 0.7658 - 90ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7639 - 92ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4876 - accuracy: 0.7653 - 102ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4870 - accuracy: 0.7638 - 101ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4865 - accuracy: 0.7660 - 98ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4860 - accuracy: 0.7672 - 100ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4855 - accuracy: 0.7681 - 99ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4851 - accuracy: 0.7676 - 97ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4846 - accuracy: 0.7662 - 78ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4841 - accuracy: 0.7677 - 88ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4838 - accuracy: 0.7681 - 86ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4834 - accuracy: 0.7674 - 93ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4831 - accuracy: 0.7667 - 87ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7662 - 94ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4824 - accuracy: 0.7674 - 104ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4820 - accuracy: 0.7672 - 90ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4818 - accuracy: 0.7658 - 95ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4815 - accuracy: 0.7660 - 98ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4813 - accuracy: 0.7657 - 82ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4810 - accuracy: 0.7676 - 80ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4809 - accuracy: 0.7660 - 89ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4807 - accuracy: 0.7665 - 81ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4803 - accuracy: 0.7665 - 82ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4803 - accuracy: 0.7660 - 83ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4800 - accuracy: 0.7670 - 85ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4798 - accuracy: 0.7667 - 100ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4798 - accuracy: 0.7662 - 89ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4795 - accuracy: 0.7657 - 89ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7669 - 108ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4792 - accuracy: 0.7662 - 83ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4790 - accuracy: 0.7660 - 84ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4789 - accuracy: 0.7660 - 91ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4787 - accuracy: 0.7660 - 84ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4785 - accuracy: 0.7669 - 121ms/epoch - 3ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4784 - accuracy: 0.7667 - 132ms/epoch - 3ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4783 - accuracy: 0.7665 - 152ms/epoch - 3ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4782 - accuracy: 0.7669 - 164ms/epoch - 4ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4781 - accuracy: 0.7665 - 130ms/epoch - 3ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4778 - accuracy: 0.7676 - 124ms/epoch - 3ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4778 - accuracy: 0.7662 - 125ms/epoch - 3ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7665 - 125ms/epoch - 3ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4775 - accuracy: 0.7672 - 125ms/epoch - 3ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4775 - accuracy: 0.7651 - 133ms/epoch - 3ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4772 - accuracy: 0.7684 - 153ms/epoch - 3ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4771 - accuracy: 0.7674 - 125ms/epoch - 3ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4771 - accuracy: 0.7669 - 111ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4769 - accuracy: 0.7664 - 102ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4768 - accuracy: 0.7653 - 134ms/epoch - 3ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4769 - accuracy: 0.7672 - 114ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4766 - accuracy: 0.7662 - 135ms/epoch - 3ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4766 - accuracy: 0.7669 - 114ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4765 - accuracy: 0.7667 - 136ms/epoch - 3ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7660 - 139ms/epoch - 3ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4762 - accuracy: 0.7670 - 131ms/epoch - 3ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4761 - accuracy: 0.7665 - 113ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4761 - accuracy: 0.7672 - 132ms/epoch - 3ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4759 - accuracy: 0.7670 - 95ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4759 - accuracy: 0.7681 - 85ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7676 - 84ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7670 - 84ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4757 - accuracy: 0.7672 - 90ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4755 - accuracy: 0.7670 - 84ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4754 - accuracy: 0.7670 - 75ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4754 - accuracy: 0.7670 - 78ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4753 - accuracy: 0.7688 - 75ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4752 - accuracy: 0.7667 - 73ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4751 - accuracy: 0.7662 - 90ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7674 - 79ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7660 - 77ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7677 - 80ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4746 - accuracy: 0.7686 - 82ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7672 - 86ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4746 - accuracy: 0.7670 - 101ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4746 - accuracy: 0.7688 - 81ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7677 - 82ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4743 - accuracy: 0.7701 - 76ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7667 - 85ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5145 - accuracy: 0.7371 - 242ms/epoch - 20ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6741 - accuracy: 0.6814 - 699ms/epoch - 15ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.6480 - accuracy: 0.6885 - 88ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.6276 - accuracy: 0.6846 - 85ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.6124 - accuracy: 0.6920 - 77ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.5993 - accuracy: 0.6999 - 74ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.5870 - accuracy: 0.7187 - 80ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.5752 - accuracy: 0.7275 - 75ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.5638 - accuracy: 0.7387 - 77ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.5534 - accuracy: 0.7451 - 77ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.5441 - accuracy: 0.7505 - 85ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.5359 - accuracy: 0.7524 - 76ms/epoch - 2ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.5288 - accuracy: 0.7543 - 84ms/epoch - 2ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.5226 - accuracy: 0.7577 - 75ms/epoch - 2ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.5174 - accuracy: 0.7610 - 100ms/epoch - 2ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.5129 - accuracy: 0.7612 - 79ms/epoch - 2ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.5093 - accuracy: 0.7622 - 82ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.5060 - accuracy: 0.7622 - 78ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.5032 - accuracy: 0.7634 - 111ms/epoch - 2ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.5008 - accuracy: 0.7645 - 79ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4987 - accuracy: 0.7645 - 87ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4969 - accuracy: 0.7653 - 83ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4950 - accuracy: 0.7655 - 83ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4933 - accuracy: 0.7653 - 80ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4918 - accuracy: 0.7650 - 83ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4904 - accuracy: 0.7657 - 85ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4891 - accuracy: 0.7655 - 79ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4879 - accuracy: 0.7658 - 91ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4868 - accuracy: 0.7646 - 81ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4859 - accuracy: 0.7662 - 88ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4849 - accuracy: 0.7665 - 77ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4840 - accuracy: 0.7665 - 80ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4835 - accuracy: 0.7660 - 88ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7664 - 87ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4821 - accuracy: 0.7670 - 81ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4816 - accuracy: 0.7667 - 90ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7667 - 94ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4807 - accuracy: 0.7674 - 89ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4802 - accuracy: 0.7670 - 80ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4799 - accuracy: 0.7670 - 80ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4795 - accuracy: 0.7670 - 83ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4791 - accuracy: 0.7674 - 88ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4787 - accuracy: 0.7676 - 82ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4786 - accuracy: 0.7679 - 90ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4782 - accuracy: 0.7681 - 79ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7682 - 88ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7684 - 85ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4774 - accuracy: 0.7684 - 88ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4772 - accuracy: 0.7691 - 80ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4770 - accuracy: 0.7676 - 80ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7686 - 88ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4766 - accuracy: 0.7679 - 84ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4765 - accuracy: 0.7677 - 90ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7665 - 83ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4761 - accuracy: 0.7665 - 80ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4760 - accuracy: 0.7674 - 84ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4759 - accuracy: 0.7669 - 87ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4759 - accuracy: 0.7681 - 89ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4756 - accuracy: 0.7681 - 85ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4755 - accuracy: 0.7693 - 83ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4754 - accuracy: 0.7681 - 91ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4753 - accuracy: 0.7674 - 84ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4752 - accuracy: 0.7681 - 84ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4751 - accuracy: 0.7674 - 84ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7686 - 88ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7681 - 81ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7677 - 88ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7672 - 91ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7686 - 86ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7681 - 87ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7674 - 97ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7686 - 89ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7676 - 81ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7676 - 78ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7679 - 84ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7682 - 88ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7686 - 86ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7681 - 87ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7679 - 82ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7679 - 88ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4739 - accuracy: 0.7676 - 90ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4738 - accuracy: 0.7676 - 89ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7684 - 84ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4737 - accuracy: 0.7681 - 81ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7670 - 80ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7676 - 79ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7679 - 91ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7677 - 87ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7677 - 79ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4733 - accuracy: 0.7682 - 87ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7693 - 87ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7672 - 88ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7682 - 101ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7679 - 95ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7674 - 104ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7691 - 105ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4730 - accuracy: 0.7672 - 89ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7676 - 105ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4727 - accuracy: 0.7674 - 92ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7674 - 99ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4727 - accuracy: 0.7674 - 87ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7679 - 95ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7672 - 103ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4727 - accuracy: 0.7681 - 91ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7677 - 85ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7670 - 84ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7670 - 140ms/epoch - 3ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7665 - 165ms/epoch - 4ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7672 - 135ms/epoch - 3ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7669 - 136ms/epoch - 3ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7667 - 139ms/epoch - 3ms/step\n",
            "12/12 - 0s - loss: 0.5490 - accuracy: 0.7205 - 227ms/epoch - 19ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6915 - accuracy: 0.5339 - 928ms/epoch - 20ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.6699 - accuracy: 0.6452 - 135ms/epoch - 3ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.6552 - accuracy: 0.6685 - 131ms/epoch - 3ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.6435 - accuracy: 0.6749 - 140ms/epoch - 3ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.6325 - accuracy: 0.6837 - 111ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.6216 - accuracy: 0.6909 - 84ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.6107 - accuracy: 0.7113 - 83ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.6000 - accuracy: 0.7211 - 79ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.5896 - accuracy: 0.7274 - 80ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.5799 - accuracy: 0.7308 - 84ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.5708 - accuracy: 0.7306 - 93ms/epoch - 2ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.5628 - accuracy: 0.7344 - 96ms/epoch - 2ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.5558 - accuracy: 0.7365 - 94ms/epoch - 2ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.5496 - accuracy: 0.7382 - 84ms/epoch - 2ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.5443 - accuracy: 0.7403 - 97ms/epoch - 2ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.5396 - accuracy: 0.7413 - 90ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.5354 - accuracy: 0.7429 - 90ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.5316 - accuracy: 0.7441 - 83ms/epoch - 2ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.5284 - accuracy: 0.7450 - 77ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.5254 - accuracy: 0.7455 - 76ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.5228 - accuracy: 0.7472 - 78ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.5205 - accuracy: 0.7470 - 97ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.5182 - accuracy: 0.7474 - 91ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.5158 - accuracy: 0.7498 - 82ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.5136 - accuracy: 0.7510 - 85ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.5116 - accuracy: 0.7506 - 86ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.5098 - accuracy: 0.7515 - 83ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.5083 - accuracy: 0.7503 - 82ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.5070 - accuracy: 0.7515 - 84ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.5057 - accuracy: 0.7515 - 76ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.5046 - accuracy: 0.7522 - 78ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.5035 - accuracy: 0.7534 - 84ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.5026 - accuracy: 0.7536 - 86ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.5017 - accuracy: 0.7539 - 79ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.5009 - accuracy: 0.7543 - 85ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.5002 - accuracy: 0.7544 - 79ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4996 - accuracy: 0.7544 - 91ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4990 - accuracy: 0.7550 - 85ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4984 - accuracy: 0.7548 - 83ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4978 - accuracy: 0.7539 - 102ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4972 - accuracy: 0.7550 - 88ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4969 - accuracy: 0.7565 - 84ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4964 - accuracy: 0.7560 - 78ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4959 - accuracy: 0.7572 - 81ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4954 - accuracy: 0.7569 - 88ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4951 - accuracy: 0.7572 - 90ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4947 - accuracy: 0.7574 - 79ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4945 - accuracy: 0.7562 - 99ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4941 - accuracy: 0.7574 - 78ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4938 - accuracy: 0.7569 - 81ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4935 - accuracy: 0.7563 - 78ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4933 - accuracy: 0.7563 - 76ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4930 - accuracy: 0.7572 - 76ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4927 - accuracy: 0.7562 - 78ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4926 - accuracy: 0.7574 - 89ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4922 - accuracy: 0.7562 - 82ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4921 - accuracy: 0.7563 - 80ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4918 - accuracy: 0.7567 - 90ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4917 - accuracy: 0.7569 - 86ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4915 - accuracy: 0.7572 - 86ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4913 - accuracy: 0.7572 - 80ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4911 - accuracy: 0.7581 - 75ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4910 - accuracy: 0.7579 - 85ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4906 - accuracy: 0.7557 - 78ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4906 - accuracy: 0.7579 - 80ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4904 - accuracy: 0.7575 - 81ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4904 - accuracy: 0.7575 - 97ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4902 - accuracy: 0.7572 - 81ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4900 - accuracy: 0.7593 - 82ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4899 - accuracy: 0.7581 - 98ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4898 - accuracy: 0.7586 - 79ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4897 - accuracy: 0.7598 - 80ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4895 - accuracy: 0.7584 - 75ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4893 - accuracy: 0.7588 - 80ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4893 - accuracy: 0.7601 - 77ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4891 - accuracy: 0.7586 - 80ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4891 - accuracy: 0.7586 - 76ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4890 - accuracy: 0.7598 - 78ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4889 - accuracy: 0.7605 - 77ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4887 - accuracy: 0.7591 - 83ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4887 - accuracy: 0.7581 - 81ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4886 - accuracy: 0.7596 - 92ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7582 - 83ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7601 - 80ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7586 - 84ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4882 - accuracy: 0.7600 - 76ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4882 - accuracy: 0.7588 - 84ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4881 - accuracy: 0.7589 - 75ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4879 - accuracy: 0.7613 - 89ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4879 - accuracy: 0.7598 - 90ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4878 - accuracy: 0.7603 - 87ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4879 - accuracy: 0.7579 - 80ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4877 - accuracy: 0.7598 - 98ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4877 - accuracy: 0.7594 - 85ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4875 - accuracy: 0.7600 - 84ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4872 - accuracy: 0.7615 - 77ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4874 - accuracy: 0.7586 - 84ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4872 - accuracy: 0.7593 - 79ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4872 - accuracy: 0.7593 - 79ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4871 - accuracy: 0.7593 - 80ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4871 - accuracy: 0.7612 - 86ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4871 - accuracy: 0.7600 - 82ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4870 - accuracy: 0.7610 - 85ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4869 - accuracy: 0.7596 - 78ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4869 - accuracy: 0.7610 - 123ms/epoch - 3ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4868 - accuracy: 0.7589 - 90ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4868 - accuracy: 0.7594 - 95ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4866 - accuracy: 0.7617 - 80ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4868 - accuracy: 0.7588 - 80ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4866 - accuracy: 0.7589 - 81ms/epoch - 2ms/step\n",
            "12/12 - 2s - loss: 0.4657 - accuracy: 0.7826 - 2s/epoch - 142ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.7586 - accuracy: 0.4058 - 1s/epoch - 23ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.6968 - accuracy: 0.5266 - 79ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.6696 - accuracy: 0.6308 - 83ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.6532 - accuracy: 0.6368 - 93ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.6401 - accuracy: 0.6473 - 91ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.6281 - accuracy: 0.6644 - 83ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.6164 - accuracy: 0.7000 - 82ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.6049 - accuracy: 0.7103 - 76ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.5937 - accuracy: 0.7279 - 81ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.5827 - accuracy: 0.7419 - 85ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.5720 - accuracy: 0.7467 - 89ms/epoch - 2ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.5619 - accuracy: 0.7493 - 91ms/epoch - 2ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.5525 - accuracy: 0.7526 - 91ms/epoch - 2ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.5440 - accuracy: 0.7562 - 91ms/epoch - 2ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.5362 - accuracy: 0.7547 - 98ms/epoch - 2ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.5293 - accuracy: 0.7559 - 95ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.5231 - accuracy: 0.7590 - 93ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.5176 - accuracy: 0.7574 - 83ms/epoch - 2ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.5127 - accuracy: 0.7602 - 82ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.5085 - accuracy: 0.7622 - 77ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.5047 - accuracy: 0.7616 - 82ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.5013 - accuracy: 0.7605 - 83ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4984 - accuracy: 0.7622 - 90ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4957 - accuracy: 0.7643 - 98ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4935 - accuracy: 0.7650 - 88ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4914 - accuracy: 0.7669 - 97ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4894 - accuracy: 0.7681 - 107ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4878 - accuracy: 0.7685 - 89ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4862 - accuracy: 0.7697 - 87ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4848 - accuracy: 0.7683 - 87ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4835 - accuracy: 0.7709 - 77ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4822 - accuracy: 0.7704 - 88ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7702 - 90ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4801 - accuracy: 0.7719 - 88ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4792 - accuracy: 0.7697 - 87ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4783 - accuracy: 0.7719 - 84ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7710 - 87ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7704 - 96ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4760 - accuracy: 0.7716 - 83ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4755 - accuracy: 0.7723 - 87ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7728 - 93ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7717 - 94ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4738 - accuracy: 0.7726 - 95ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7740 - 88ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7731 - 87ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7721 - 83ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7728 - 80ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4719 - accuracy: 0.7736 - 84ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4715 - accuracy: 0.7743 - 103ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4711 - accuracy: 0.7761 - 86ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4709 - accuracy: 0.7750 - 79ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4706 - accuracy: 0.7745 - 82ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7757 - 90ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4702 - accuracy: 0.7745 - 83ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4699 - accuracy: 0.7742 - 81ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4697 - accuracy: 0.7754 - 89ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4695 - accuracy: 0.7759 - 94ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4692 - accuracy: 0.7761 - 84ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4692 - accuracy: 0.7771 - 82ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4690 - accuracy: 0.7762 - 84ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4687 - accuracy: 0.7776 - 88ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4686 - accuracy: 0.7788 - 85ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4684 - accuracy: 0.7781 - 93ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4681 - accuracy: 0.7786 - 81ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4680 - accuracy: 0.7785 - 86ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4678 - accuracy: 0.7798 - 83ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4675 - accuracy: 0.7767 - 83ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4675 - accuracy: 0.7798 - 85ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4673 - accuracy: 0.7762 - 83ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4672 - accuracy: 0.7797 - 86ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4670 - accuracy: 0.7776 - 82ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4669 - accuracy: 0.7802 - 92ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4667 - accuracy: 0.7788 - 83ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4667 - accuracy: 0.7786 - 87ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4666 - accuracy: 0.7792 - 83ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4663 - accuracy: 0.7807 - 127ms/epoch - 3ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4664 - accuracy: 0.7786 - 86ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4662 - accuracy: 0.7793 - 85ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4661 - accuracy: 0.7781 - 89ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4660 - accuracy: 0.7790 - 92ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4660 - accuracy: 0.7797 - 87ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7795 - 82ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4657 - accuracy: 0.7798 - 96ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4657 - accuracy: 0.7788 - 93ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4655 - accuracy: 0.7797 - 78ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4655 - accuracy: 0.7786 - 93ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4653 - accuracy: 0.7804 - 95ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4653 - accuracy: 0.7798 - 98ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4654 - accuracy: 0.7798 - 102ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4652 - accuracy: 0.7800 - 102ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4652 - accuracy: 0.7790 - 95ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4650 - accuracy: 0.7800 - 89ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4651 - accuracy: 0.7786 - 101ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4650 - accuracy: 0.7797 - 84ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4649 - accuracy: 0.7781 - 83ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4648 - accuracy: 0.7805 - 80ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4648 - accuracy: 0.7786 - 102ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4648 - accuracy: 0.7792 - 93ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4647 - accuracy: 0.7802 - 91ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7798 - 98ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7802 - 91ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7790 - 87ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4645 - accuracy: 0.7792 - 81ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7802 - 85ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4643 - accuracy: 0.7805 - 86ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4643 - accuracy: 0.7793 - 136ms/epoch - 3ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4642 - accuracy: 0.7790 - 122ms/epoch - 3ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4641 - accuracy: 0.7833 - 128ms/epoch - 3ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4643 - accuracy: 0.7798 - 127ms/epoch - 3ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4642 - accuracy: 0.7798 - 126ms/epoch - 3ms/step\n",
            "12/12 - 0s - loss: 0.7059 - accuracy: 0.6602 - 210ms/epoch - 18ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 2s - loss: 0.6729 - accuracy: 0.5681 - 2s/epoch - 34ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.5567 - accuracy: 0.7494 - 116ms/epoch - 3ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.5040 - accuracy: 0.7581 - 119ms/epoch - 3ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.4905 - accuracy: 0.7657 - 126ms/epoch - 3ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.4844 - accuracy: 0.7670 - 178ms/epoch - 4ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7703 - 157ms/epoch - 3ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.4791 - accuracy: 0.7695 - 146ms/epoch - 3ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7719 - 135ms/epoch - 3ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.4762 - accuracy: 0.7724 - 125ms/epoch - 3ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7727 - 142ms/epoch - 3ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7698 - 122ms/epoch - 3ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7722 - 154ms/epoch - 3ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.4715 - accuracy: 0.7726 - 144ms/epoch - 3ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7724 - 146ms/epoch - 3ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.4703 - accuracy: 0.7717 - 136ms/epoch - 3ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.4694 - accuracy: 0.7743 - 102ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.4691 - accuracy: 0.7698 - 94ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.4682 - accuracy: 0.7688 - 81ms/epoch - 2ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.4677 - accuracy: 0.7707 - 86ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4678 - accuracy: 0.7696 - 95ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4672 - accuracy: 0.7722 - 103ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4663 - accuracy: 0.7703 - 95ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4659 - accuracy: 0.7707 - 87ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7719 - 95ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4647 - accuracy: 0.7695 - 88ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4643 - accuracy: 0.7753 - 89ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7712 - 81ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7714 - 86ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4630 - accuracy: 0.7712 - 82ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4630 - accuracy: 0.7758 - 88ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4624 - accuracy: 0.7758 - 107ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4625 - accuracy: 0.7717 - 87ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4618 - accuracy: 0.7722 - 85ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4619 - accuracy: 0.7726 - 91ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4614 - accuracy: 0.7722 - 102ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4600 - accuracy: 0.7757 - 88ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4607 - accuracy: 0.7758 - 84ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4606 - accuracy: 0.7779 - 94ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4596 - accuracy: 0.7745 - 85ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7739 - 92ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4588 - accuracy: 0.7748 - 103ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4586 - accuracy: 0.7767 - 101ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4585 - accuracy: 0.7764 - 93ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4580 - accuracy: 0.7762 - 91ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4581 - accuracy: 0.7777 - 94ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4578 - accuracy: 0.7743 - 88ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7753 - 89ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4567 - accuracy: 0.7764 - 83ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4566 - accuracy: 0.7770 - 87ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4561 - accuracy: 0.7784 - 91ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4553 - accuracy: 0.7800 - 88ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4554 - accuracy: 0.7774 - 89ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4549 - accuracy: 0.7793 - 99ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7791 - 84ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4539 - accuracy: 0.7824 - 90ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4539 - accuracy: 0.7786 - 96ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4534 - accuracy: 0.7802 - 98ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4534 - accuracy: 0.7777 - 87ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4533 - accuracy: 0.7784 - 95ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4524 - accuracy: 0.7810 - 89ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4522 - accuracy: 0.7815 - 87ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4514 - accuracy: 0.7827 - 94ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4520 - accuracy: 0.7783 - 102ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7831 - 107ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7805 - 98ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4504 - accuracy: 0.7826 - 88ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4498 - accuracy: 0.7850 - 90ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4508 - accuracy: 0.7829 - 86ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4500 - accuracy: 0.7821 - 88ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4491 - accuracy: 0.7831 - 86ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4494 - accuracy: 0.7843 - 86ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4495 - accuracy: 0.7822 - 94ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4488 - accuracy: 0.7883 - 106ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4489 - accuracy: 0.7869 - 107ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4482 - accuracy: 0.7858 - 94ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4474 - accuracy: 0.7862 - 101ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7834 - 89ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4475 - accuracy: 0.7879 - 87ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4469 - accuracy: 0.7860 - 93ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4468 - accuracy: 0.7862 - 88ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4469 - accuracy: 0.7872 - 85ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4474 - accuracy: 0.7852 - 96ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4472 - accuracy: 0.7877 - 95ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4456 - accuracy: 0.7905 - 111ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7872 - 91ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7858 - 110ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4458 - accuracy: 0.7891 - 92ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4456 - accuracy: 0.7857 - 102ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7907 - 88ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4451 - accuracy: 0.7871 - 84ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7884 - 88ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7888 - 89ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4444 - accuracy: 0.7891 - 94ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4437 - accuracy: 0.7907 - 107ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7879 - 93ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7852 - 110ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4439 - accuracy: 0.7895 - 107ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4432 - accuracy: 0.7879 - 114ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4432 - accuracy: 0.7883 - 102ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4432 - accuracy: 0.7917 - 90ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4429 - accuracy: 0.7919 - 111ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4427 - accuracy: 0.7888 - 118ms/epoch - 3ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4432 - accuracy: 0.7893 - 114ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4422 - accuracy: 0.7910 - 113ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4423 - accuracy: 0.7917 - 108ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4416 - accuracy: 0.7902 - 95ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4417 - accuracy: 0.7896 - 96ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4417 - accuracy: 0.7896 - 89ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4416 - accuracy: 0.7890 - 90ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4414 - accuracy: 0.7895 - 88ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5346 - accuracy: 0.7212 - 208ms/epoch - 17ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6472 - accuracy: 0.6314 - 1s/epoch - 27ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.5538 - accuracy: 0.7237 - 105ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.5102 - accuracy: 0.7541 - 88ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.4954 - accuracy: 0.7624 - 93ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.4890 - accuracy: 0.7629 - 95ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.4851 - accuracy: 0.7657 - 94ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.4822 - accuracy: 0.7662 - 94ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.4806 - accuracy: 0.7686 - 103ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.4784 - accuracy: 0.7674 - 99ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.4764 - accuracy: 0.7677 - 109ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.4768 - accuracy: 0.7691 - 92ms/epoch - 2ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7710 - 94ms/epoch - 2ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7679 - 86ms/epoch - 2ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7672 - 82ms/epoch - 2ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7691 - 93ms/epoch - 2ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.4721 - accuracy: 0.7688 - 94ms/epoch - 2ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7710 - 96ms/epoch - 2ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.4703 - accuracy: 0.7681 - 138ms/epoch - 3ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.4699 - accuracy: 0.7715 - 143ms/epoch - 3ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4700 - accuracy: 0.7708 - 160ms/epoch - 3ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4704 - accuracy: 0.7681 - 136ms/epoch - 3ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4692 - accuracy: 0.7710 - 125ms/epoch - 3ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4682 - accuracy: 0.7736 - 129ms/epoch - 3ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4689 - accuracy: 0.7700 - 171ms/epoch - 4ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4684 - accuracy: 0.7724 - 136ms/epoch - 3ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4676 - accuracy: 0.7722 - 175ms/epoch - 4ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4675 - accuracy: 0.7705 - 153ms/epoch - 3ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4673 - accuracy: 0.7710 - 121ms/epoch - 3ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4664 - accuracy: 0.7729 - 141ms/epoch - 3ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7696 - 143ms/epoch - 3ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4659 - accuracy: 0.7701 - 156ms/epoch - 3ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4660 - accuracy: 0.7717 - 155ms/epoch - 3ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4651 - accuracy: 0.7698 - 165ms/epoch - 4ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4650 - accuracy: 0.7726 - 144ms/epoch - 3ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4643 - accuracy: 0.7738 - 129ms/epoch - 3ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7722 - 139ms/epoch - 3ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7712 - 121ms/epoch - 3ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4630 - accuracy: 0.7760 - 99ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4634 - accuracy: 0.7708 - 94ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4629 - accuracy: 0.7717 - 94ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4624 - accuracy: 0.7741 - 94ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4625 - accuracy: 0.7753 - 96ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4619 - accuracy: 0.7745 - 83ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4635 - accuracy: 0.7743 - 94ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4615 - accuracy: 0.7791 - 88ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4611 - accuracy: 0.7729 - 88ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4609 - accuracy: 0.7726 - 85ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4604 - accuracy: 0.7743 - 96ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4604 - accuracy: 0.7745 - 90ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4598 - accuracy: 0.7727 - 101ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4603 - accuracy: 0.7770 - 98ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4598 - accuracy: 0.7726 - 106ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4592 - accuracy: 0.7755 - 99ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7760 - 92ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4592 - accuracy: 0.7745 - 88ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4607 - accuracy: 0.7750 - 93ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4585 - accuracy: 0.7741 - 93ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4593 - accuracy: 0.7765 - 88ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7772 - 96ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4577 - accuracy: 0.7786 - 81ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4583 - accuracy: 0.7783 - 83ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4575 - accuracy: 0.7784 - 82ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4571 - accuracy: 0.7762 - 90ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4568 - accuracy: 0.7786 - 82ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4563 - accuracy: 0.7784 - 82ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4560 - accuracy: 0.7776 - 79ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4558 - accuracy: 0.7793 - 91ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4563 - accuracy: 0.7803 - 91ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4573 - accuracy: 0.7765 - 91ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4556 - accuracy: 0.7781 - 82ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4550 - accuracy: 0.7789 - 81ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4549 - accuracy: 0.7814 - 98ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4546 - accuracy: 0.7765 - 90ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7803 - 104ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4537 - accuracy: 0.7781 - 94ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4538 - accuracy: 0.7819 - 81ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4534 - accuracy: 0.7783 - 86ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7788 - 88ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7812 - 84ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4526 - accuracy: 0.7826 - 92ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4534 - accuracy: 0.7793 - 99ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7772 - 101ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7807 - 87ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4523 - accuracy: 0.7822 - 85ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4539 - accuracy: 0.7814 - 96ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4525 - accuracy: 0.7767 - 84ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4516 - accuracy: 0.7796 - 87ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4516 - accuracy: 0.7810 - 92ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7793 - 99ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4517 - accuracy: 0.7764 - 90ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4514 - accuracy: 0.7815 - 95ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4509 - accuracy: 0.7822 - 100ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4502 - accuracy: 0.7789 - 91ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7803 - 100ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4513 - accuracy: 0.7864 - 110ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4500 - accuracy: 0.7817 - 84ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4499 - accuracy: 0.7819 - 91ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4495 - accuracy: 0.7833 - 96ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4502 - accuracy: 0.7821 - 103ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4503 - accuracy: 0.7826 - 111ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4503 - accuracy: 0.7791 - 95ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7821 - 94ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7791 - 85ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7829 - 92ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4493 - accuracy: 0.7808 - 105ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4489 - accuracy: 0.7831 - 90ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7821 - 104ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7834 - 89ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4481 - accuracy: 0.7853 - 98ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7848 - 113ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5190 - accuracy: 0.7170 - 225ms/epoch - 19ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6101 - accuracy: 0.6233 - 1s/epoch - 27ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.5548 - accuracy: 0.7472 - 100ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.5153 - accuracy: 0.7632 - 94ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.4956 - accuracy: 0.7677 - 109ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.4868 - accuracy: 0.7691 - 103ms/epoch - 2ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.4816 - accuracy: 0.7686 - 103ms/epoch - 2ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7689 - 109ms/epoch - 2ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.4765 - accuracy: 0.7715 - 92ms/epoch - 2ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.4743 - accuracy: 0.7708 - 102ms/epoch - 2ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7701 - 95ms/epoch - 2ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.4710 - accuracy: 0.7734 - 116ms/epoch - 3ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7707 - 133ms/epoch - 3ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.4690 - accuracy: 0.7731 - 179ms/epoch - 4ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.4694 - accuracy: 0.7739 - 155ms/epoch - 3ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.4680 - accuracy: 0.7738 - 151ms/epoch - 3ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.4676 - accuracy: 0.7724 - 140ms/epoch - 3ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.4666 - accuracy: 0.7748 - 147ms/epoch - 3ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.4653 - accuracy: 0.7752 - 141ms/epoch - 3ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.4650 - accuracy: 0.7748 - 151ms/epoch - 3ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4645 - accuracy: 0.7755 - 163ms/epoch - 4ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4635 - accuracy: 0.7770 - 148ms/epoch - 3ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4628 - accuracy: 0.7755 - 139ms/epoch - 3ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4621 - accuracy: 0.7788 - 140ms/epoch - 3ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4618 - accuracy: 0.7777 - 131ms/epoch - 3ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4612 - accuracy: 0.7783 - 150ms/epoch - 3ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4613 - accuracy: 0.7786 - 133ms/epoch - 3ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4606 - accuracy: 0.7784 - 147ms/epoch - 3ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4601 - accuracy: 0.7803 - 165ms/epoch - 4ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4593 - accuracy: 0.7808 - 143ms/epoch - 3ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4589 - accuracy: 0.7812 - 137ms/epoch - 3ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4600 - accuracy: 0.7795 - 130ms/epoch - 3ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7810 - 91ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4586 - accuracy: 0.7798 - 95ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4573 - accuracy: 0.7817 - 103ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7824 - 104ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4566 - accuracy: 0.7834 - 99ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4562 - accuracy: 0.7836 - 109ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4558 - accuracy: 0.7829 - 93ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4557 - accuracy: 0.7815 - 101ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4557 - accuracy: 0.7824 - 110ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4552 - accuracy: 0.7838 - 102ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4561 - accuracy: 0.7853 - 104ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4544 - accuracy: 0.7822 - 104ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7852 - 104ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4537 - accuracy: 0.7841 - 99ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7840 - 93ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7833 - 93ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4531 - accuracy: 0.7824 - 92ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7852 - 89ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7879 - 102ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4529 - accuracy: 0.7858 - 102ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4524 - accuracy: 0.7850 - 92ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4518 - accuracy: 0.7867 - 91ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4516 - accuracy: 0.7860 - 94ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4514 - accuracy: 0.7907 - 94ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4524 - accuracy: 0.7850 - 109ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4516 - accuracy: 0.7883 - 94ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4505 - accuracy: 0.7898 - 91ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4507 - accuracy: 0.7858 - 89ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7865 - 117ms/epoch - 3ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4500 - accuracy: 0.7888 - 94ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7879 - 91ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4499 - accuracy: 0.7865 - 94ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7895 - 92ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4498 - accuracy: 0.7867 - 87ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4489 - accuracy: 0.7896 - 86ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7907 - 88ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7883 - 86ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4495 - accuracy: 0.7877 - 81ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4505 - accuracy: 0.7865 - 83ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4497 - accuracy: 0.7872 - 103ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4490 - accuracy: 0.7914 - 89ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4481 - accuracy: 0.7888 - 92ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4478 - accuracy: 0.7898 - 101ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4477 - accuracy: 0.7929 - 99ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4481 - accuracy: 0.7891 - 103ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4475 - accuracy: 0.7910 - 99ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4483 - accuracy: 0.7879 - 90ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4468 - accuracy: 0.7941 - 90ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4468 - accuracy: 0.7888 - 89ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4472 - accuracy: 0.7912 - 108ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4468 - accuracy: 0.7928 - 91ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4466 - accuracy: 0.7903 - 102ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4457 - accuracy: 0.7931 - 97ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4457 - accuracy: 0.7902 - 88ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4463 - accuracy: 0.7881 - 83ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7928 - 90ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7950 - 90ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7874 - 96ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4460 - accuracy: 0.7881 - 99ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7926 - 116ms/epoch - 3ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7929 - 103ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4442 - accuracy: 0.7945 - 107ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4446 - accuracy: 0.7905 - 141ms/epoch - 3ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7931 - 98ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4436 - accuracy: 0.7890 - 90ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4455 - accuracy: 0.7877 - 96ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4433 - accuracy: 0.7915 - 100ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4425 - accuracy: 0.7910 - 106ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4424 - accuracy: 0.7931 - 97ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4424 - accuracy: 0.7915 - 92ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4427 - accuracy: 0.7910 - 104ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4430 - accuracy: 0.7905 - 83ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4417 - accuracy: 0.7919 - 95ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4415 - accuracy: 0.7945 - 96ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4424 - accuracy: 0.7924 - 88ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4411 - accuracy: 0.7952 - 85ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4419 - accuracy: 0.7922 - 85ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4403 - accuracy: 0.7914 - 82ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4404 - accuracy: 0.7928 - 97ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5417 - accuracy: 0.7046 - 202ms/epoch - 17ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6996 - accuracy: 0.5370 - 1s/epoch - 27ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.5843 - accuracy: 0.7211 - 85ms/epoch - 2ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.5409 - accuracy: 0.7344 - 91ms/epoch - 2ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.5182 - accuracy: 0.7462 - 92ms/epoch - 2ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.5070 - accuracy: 0.7486 - 152ms/epoch - 3ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.5008 - accuracy: 0.7505 - 144ms/epoch - 3ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.4972 - accuracy: 0.7536 - 140ms/epoch - 3ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.4939 - accuracy: 0.7538 - 124ms/epoch - 3ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.4915 - accuracy: 0.7543 - 127ms/epoch - 3ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.4894 - accuracy: 0.7581 - 119ms/epoch - 3ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.4886 - accuracy: 0.7581 - 131ms/epoch - 3ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.4871 - accuracy: 0.7598 - 115ms/epoch - 3ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.4866 - accuracy: 0.7579 - 139ms/epoch - 3ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.4857 - accuracy: 0.7589 - 144ms/epoch - 3ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.4854 - accuracy: 0.7608 - 133ms/epoch - 3ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.4843 - accuracy: 0.7612 - 128ms/epoch - 3ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.4838 - accuracy: 0.7588 - 118ms/epoch - 3ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.4841 - accuracy: 0.7584 - 129ms/epoch - 3ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.4825 - accuracy: 0.7593 - 159ms/epoch - 3ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7613 - 162ms/epoch - 4ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4816 - accuracy: 0.7622 - 155ms/epoch - 3ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4821 - accuracy: 0.7600 - 140ms/epoch - 3ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7601 - 133ms/epoch - 3ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7591 - 130ms/epoch - 3ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4805 - accuracy: 0.7593 - 126ms/epoch - 3ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7601 - 94ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4804 - accuracy: 0.7601 - 88ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4797 - accuracy: 0.7613 - 101ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4796 - accuracy: 0.7598 - 111ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4797 - accuracy: 0.7608 - 88ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7593 - 86ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4785 - accuracy: 0.7619 - 82ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4780 - accuracy: 0.7589 - 83ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4784 - accuracy: 0.7608 - 83ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4777 - accuracy: 0.7615 - 86ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7601 - 96ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4791 - accuracy: 0.7612 - 89ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4769 - accuracy: 0.7605 - 89ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4781 - accuracy: 0.7601 - 86ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7613 - 109ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4761 - accuracy: 0.7617 - 93ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7612 - 91ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7629 - 96ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7634 - 89ms/epoch - 2ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4752 - accuracy: 0.7629 - 88ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4748 - accuracy: 0.7631 - 99ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7632 - 102ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7619 - 103ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7620 - 98ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7651 - 121ms/epoch - 3ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7626 - 110ms/epoch - 2ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7646 - 99ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7657 - 102ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7627 - 92ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7655 - 93ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7669 - 114ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4719 - accuracy: 0.7650 - 115ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4717 - accuracy: 0.7627 - 100ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4712 - accuracy: 0.7655 - 107ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4711 - accuracy: 0.7665 - 92ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4713 - accuracy: 0.7632 - 91ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4706 - accuracy: 0.7643 - 89ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4710 - accuracy: 0.7645 - 89ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4703 - accuracy: 0.7643 - 86ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4706 - accuracy: 0.7645 - 97ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4710 - accuracy: 0.7645 - 107ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4706 - accuracy: 0.7643 - 95ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4694 - accuracy: 0.7651 - 93ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4691 - accuracy: 0.7670 - 88ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4691 - accuracy: 0.7636 - 110ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4694 - accuracy: 0.7646 - 85ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4687 - accuracy: 0.7650 - 84ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4686 - accuracy: 0.7684 - 95ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4683 - accuracy: 0.7651 - 88ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4686 - accuracy: 0.7664 - 94ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4683 - accuracy: 0.7664 - 97ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4679 - accuracy: 0.7655 - 108ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4670 - accuracy: 0.7657 - 91ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4682 - accuracy: 0.7689 - 87ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4688 - accuracy: 0.7641 - 98ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4663 - accuracy: 0.7677 - 99ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4668 - accuracy: 0.7677 - 89ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4668 - accuracy: 0.7679 - 94ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4663 - accuracy: 0.7664 - 89ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4662 - accuracy: 0.7677 - 87ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4665 - accuracy: 0.7667 - 95ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4653 - accuracy: 0.7677 - 97ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4659 - accuracy: 0.7686 - 84ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4655 - accuracy: 0.7665 - 91ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4656 - accuracy: 0.7674 - 104ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4657 - accuracy: 0.7669 - 95ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7686 - 85ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4664 - accuracy: 0.7655 - 93ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4661 - accuracy: 0.7650 - 85ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7664 - 102ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4649 - accuracy: 0.7676 - 108ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7643 - 91ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4641 - accuracy: 0.7693 - 90ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7682 - 97ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4637 - accuracy: 0.7684 - 94ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7670 - 100ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7650 - 91ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4640 - accuracy: 0.7674 - 82ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4638 - accuracy: 0.7679 - 86ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4662 - accuracy: 0.7664 - 109ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4645 - accuracy: 0.7691 - 90ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7684 - 102ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4627 - accuracy: 0.7698 - 92ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4631 - accuracy: 0.7679 - 101ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4627 - accuracy: 0.7676 - 91ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.4604 - accuracy: 0.7716 - 213ms/epoch - 18ms/step\n",
            "Epoch 1/110\n",
            "46/46 - 1s - loss: 0.6381 - accuracy: 0.6061 - 1s/epoch - 29ms/step\n",
            "Epoch 2/110\n",
            "46/46 - 0s - loss: 0.5591 - accuracy: 0.7191 - 177ms/epoch - 4ms/step\n",
            "Epoch 3/110\n",
            "46/46 - 0s - loss: 0.5128 - accuracy: 0.7522 - 158ms/epoch - 3ms/step\n",
            "Epoch 4/110\n",
            "46/46 - 0s - loss: 0.4864 - accuracy: 0.7647 - 137ms/epoch - 3ms/step\n",
            "Epoch 5/110\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7702 - 151ms/epoch - 3ms/step\n",
            "Epoch 6/110\n",
            "46/46 - 0s - loss: 0.4700 - accuracy: 0.7710 - 129ms/epoch - 3ms/step\n",
            "Epoch 7/110\n",
            "46/46 - 0s - loss: 0.4674 - accuracy: 0.7767 - 123ms/epoch - 3ms/step\n",
            "Epoch 8/110\n",
            "46/46 - 0s - loss: 0.4649 - accuracy: 0.7771 - 139ms/epoch - 3ms/step\n",
            "Epoch 9/110\n",
            "46/46 - 0s - loss: 0.4633 - accuracy: 0.7804 - 148ms/epoch - 3ms/step\n",
            "Epoch 10/110\n",
            "46/46 - 0s - loss: 0.4619 - accuracy: 0.7809 - 152ms/epoch - 3ms/step\n",
            "Epoch 11/110\n",
            "46/46 - 0s - loss: 0.4613 - accuracy: 0.7807 - 134ms/epoch - 3ms/step\n",
            "Epoch 12/110\n",
            "46/46 - 0s - loss: 0.4610 - accuracy: 0.7821 - 146ms/epoch - 3ms/step\n",
            "Epoch 13/110\n",
            "46/46 - 0s - loss: 0.4598 - accuracy: 0.7819 - 131ms/epoch - 3ms/step\n",
            "Epoch 14/110\n",
            "46/46 - 0s - loss: 0.4590 - accuracy: 0.7814 - 122ms/epoch - 3ms/step\n",
            "Epoch 15/110\n",
            "46/46 - 0s - loss: 0.4590 - accuracy: 0.7821 - 165ms/epoch - 4ms/step\n",
            "Epoch 16/110\n",
            "46/46 - 0s - loss: 0.4586 - accuracy: 0.7805 - 136ms/epoch - 3ms/step\n",
            "Epoch 17/110\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7814 - 142ms/epoch - 3ms/step\n",
            "Epoch 18/110\n",
            "46/46 - 0s - loss: 0.4577 - accuracy: 0.7804 - 143ms/epoch - 3ms/step\n",
            "Epoch 19/110\n",
            "46/46 - 0s - loss: 0.4574 - accuracy: 0.7804 - 106ms/epoch - 2ms/step\n",
            "Epoch 20/110\n",
            "46/46 - 0s - loss: 0.4563 - accuracy: 0.7814 - 88ms/epoch - 2ms/step\n",
            "Epoch 21/110\n",
            "46/46 - 0s - loss: 0.4559 - accuracy: 0.7790 - 111ms/epoch - 2ms/step\n",
            "Epoch 22/110\n",
            "46/46 - 0s - loss: 0.4552 - accuracy: 0.7790 - 97ms/epoch - 2ms/step\n",
            "Epoch 23/110\n",
            "46/46 - 0s - loss: 0.4549 - accuracy: 0.7824 - 101ms/epoch - 2ms/step\n",
            "Epoch 24/110\n",
            "46/46 - 0s - loss: 0.4553 - accuracy: 0.7783 - 95ms/epoch - 2ms/step\n",
            "Epoch 25/110\n",
            "46/46 - 0s - loss: 0.4554 - accuracy: 0.7823 - 99ms/epoch - 2ms/step\n",
            "Epoch 26/110\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7807 - 92ms/epoch - 2ms/step\n",
            "Epoch 27/110\n",
            "46/46 - 0s - loss: 0.4541 - accuracy: 0.7792 - 87ms/epoch - 2ms/step\n",
            "Epoch 28/110\n",
            "46/46 - 0s - loss: 0.4539 - accuracy: 0.7797 - 98ms/epoch - 2ms/step\n",
            "Epoch 29/110\n",
            "46/46 - 0s - loss: 0.4537 - accuracy: 0.7819 - 82ms/epoch - 2ms/step\n",
            "Epoch 30/110\n",
            "46/46 - 0s - loss: 0.4534 - accuracy: 0.7859 - 103ms/epoch - 2ms/step\n",
            "Epoch 31/110\n",
            "46/46 - 0s - loss: 0.4526 - accuracy: 0.7802 - 104ms/epoch - 2ms/step\n",
            "Epoch 32/110\n",
            "46/46 - 0s - loss: 0.4525 - accuracy: 0.7831 - 93ms/epoch - 2ms/step\n",
            "Epoch 33/110\n",
            "46/46 - 0s - loss: 0.4525 - accuracy: 0.7800 - 98ms/epoch - 2ms/step\n",
            "Epoch 34/110\n",
            "46/46 - 0s - loss: 0.4523 - accuracy: 0.7802 - 109ms/epoch - 2ms/step\n",
            "Epoch 35/110\n",
            "46/46 - 0s - loss: 0.4523 - accuracy: 0.7838 - 99ms/epoch - 2ms/step\n",
            "Epoch 36/110\n",
            "46/46 - 0s - loss: 0.4514 - accuracy: 0.7847 - 105ms/epoch - 2ms/step\n",
            "Epoch 37/110\n",
            "46/46 - 0s - loss: 0.4511 - accuracy: 0.7819 - 85ms/epoch - 2ms/step\n",
            "Epoch 38/110\n",
            "46/46 - 0s - loss: 0.4512 - accuracy: 0.7811 - 102ms/epoch - 2ms/step\n",
            "Epoch 39/110\n",
            "46/46 - 0s - loss: 0.4509 - accuracy: 0.7850 - 90ms/epoch - 2ms/step\n",
            "Epoch 40/110\n",
            "46/46 - 0s - loss: 0.4507 - accuracy: 0.7814 - 89ms/epoch - 2ms/step\n",
            "Epoch 41/110\n",
            "46/46 - 0s - loss: 0.4503 - accuracy: 0.7833 - 90ms/epoch - 2ms/step\n",
            "Epoch 42/110\n",
            "46/46 - 0s - loss: 0.4502 - accuracy: 0.7819 - 110ms/epoch - 2ms/step\n",
            "Epoch 43/110\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7845 - 98ms/epoch - 2ms/step\n",
            "Epoch 44/110\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7828 - 118ms/epoch - 3ms/step\n",
            "Epoch 45/110\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7833 - 92ms/epoch - 2ms/step\n",
            "Epoch 46/110\n",
            "46/46 - 0s - loss: 0.4498 - accuracy: 0.7824 - 91ms/epoch - 2ms/step\n",
            "Epoch 47/110\n",
            "46/46 - 0s - loss: 0.4493 - accuracy: 0.7855 - 89ms/epoch - 2ms/step\n",
            "Epoch 48/110\n",
            "46/46 - 0s - loss: 0.4488 - accuracy: 0.7835 - 106ms/epoch - 2ms/step\n",
            "Epoch 49/110\n",
            "46/46 - 0s - loss: 0.4490 - accuracy: 0.7831 - 101ms/epoch - 2ms/step\n",
            "Epoch 50/110\n",
            "46/46 - 0s - loss: 0.4480 - accuracy: 0.7849 - 98ms/epoch - 2ms/step\n",
            "Epoch 51/110\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7847 - 119ms/epoch - 3ms/step\n",
            "Epoch 52/110\n",
            "46/46 - 0s - loss: 0.4476 - accuracy: 0.7842 - 102ms/epoch - 2ms/step\n",
            "Epoch 53/110\n",
            "46/46 - 0s - loss: 0.4479 - accuracy: 0.7835 - 90ms/epoch - 2ms/step\n",
            "Epoch 54/110\n",
            "46/46 - 0s - loss: 0.4474 - accuracy: 0.7849 - 94ms/epoch - 2ms/step\n",
            "Epoch 55/110\n",
            "46/46 - 0s - loss: 0.4469 - accuracy: 0.7845 - 93ms/epoch - 2ms/step\n",
            "Epoch 56/110\n",
            "46/46 - 0s - loss: 0.4463 - accuracy: 0.7852 - 86ms/epoch - 2ms/step\n",
            "Epoch 57/110\n",
            "46/46 - 0s - loss: 0.4465 - accuracy: 0.7859 - 85ms/epoch - 2ms/step\n",
            "Epoch 58/110\n",
            "46/46 - 0s - loss: 0.4466 - accuracy: 0.7847 - 104ms/epoch - 2ms/step\n",
            "Epoch 59/110\n",
            "46/46 - 0s - loss: 0.4468 - accuracy: 0.7840 - 89ms/epoch - 2ms/step\n",
            "Epoch 60/110\n",
            "46/46 - 0s - loss: 0.4464 - accuracy: 0.7843 - 89ms/epoch - 2ms/step\n",
            "Epoch 61/110\n",
            "46/46 - 0s - loss: 0.4455 - accuracy: 0.7855 - 90ms/epoch - 2ms/step\n",
            "Epoch 62/110\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7852 - 95ms/epoch - 2ms/step\n",
            "Epoch 63/110\n",
            "46/46 - 0s - loss: 0.4450 - accuracy: 0.7883 - 87ms/epoch - 2ms/step\n",
            "Epoch 64/110\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7871 - 88ms/epoch - 2ms/step\n",
            "Epoch 65/110\n",
            "46/46 - 0s - loss: 0.4447 - accuracy: 0.7861 - 94ms/epoch - 2ms/step\n",
            "Epoch 66/110\n",
            "46/46 - 0s - loss: 0.4441 - accuracy: 0.7867 - 85ms/epoch - 2ms/step\n",
            "Epoch 67/110\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7852 - 88ms/epoch - 2ms/step\n",
            "Epoch 68/110\n",
            "46/46 - 0s - loss: 0.4447 - accuracy: 0.7871 - 86ms/epoch - 2ms/step\n",
            "Epoch 69/110\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7871 - 88ms/epoch - 2ms/step\n",
            "Epoch 70/110\n",
            "46/46 - 0s - loss: 0.4439 - accuracy: 0.7869 - 87ms/epoch - 2ms/step\n",
            "Epoch 71/110\n",
            "46/46 - 0s - loss: 0.4430 - accuracy: 0.7855 - 92ms/epoch - 2ms/step\n",
            "Epoch 72/110\n",
            "46/46 - 0s - loss: 0.4435 - accuracy: 0.7886 - 101ms/epoch - 2ms/step\n",
            "Epoch 73/110\n",
            "46/46 - 0s - loss: 0.4432 - accuracy: 0.7881 - 94ms/epoch - 2ms/step\n",
            "Epoch 74/110\n",
            "46/46 - 0s - loss: 0.4434 - accuracy: 0.7869 - 102ms/epoch - 2ms/step\n",
            "Epoch 75/110\n",
            "46/46 - 0s - loss: 0.4423 - accuracy: 0.7871 - 100ms/epoch - 2ms/step\n",
            "Epoch 76/110\n",
            "46/46 - 0s - loss: 0.4432 - accuracy: 0.7873 - 94ms/epoch - 2ms/step\n",
            "Epoch 77/110\n",
            "46/46 - 0s - loss: 0.4420 - accuracy: 0.7869 - 84ms/epoch - 2ms/step\n",
            "Epoch 78/110\n",
            "46/46 - 0s - loss: 0.4422 - accuracy: 0.7876 - 99ms/epoch - 2ms/step\n",
            "Epoch 79/110\n",
            "46/46 - 0s - loss: 0.4425 - accuracy: 0.7867 - 95ms/epoch - 2ms/step\n",
            "Epoch 80/110\n",
            "46/46 - 0s - loss: 0.4430 - accuracy: 0.7866 - 104ms/epoch - 2ms/step\n",
            "Epoch 81/110\n",
            "46/46 - 0s - loss: 0.4419 - accuracy: 0.7883 - 95ms/epoch - 2ms/step\n",
            "Epoch 82/110\n",
            "46/46 - 0s - loss: 0.4417 - accuracy: 0.7874 - 103ms/epoch - 2ms/step\n",
            "Epoch 83/110\n",
            "46/46 - 0s - loss: 0.4417 - accuracy: 0.7874 - 92ms/epoch - 2ms/step\n",
            "Epoch 84/110\n",
            "46/46 - 0s - loss: 0.4414 - accuracy: 0.7883 - 95ms/epoch - 2ms/step\n",
            "Epoch 85/110\n",
            "46/46 - 0s - loss: 0.4406 - accuracy: 0.7890 - 106ms/epoch - 2ms/step\n",
            "Epoch 86/110\n",
            "46/46 - 0s - loss: 0.4413 - accuracy: 0.7888 - 90ms/epoch - 2ms/step\n",
            "Epoch 87/110\n",
            "46/46 - 0s - loss: 0.4411 - accuracy: 0.7907 - 86ms/epoch - 2ms/step\n",
            "Epoch 88/110\n",
            "46/46 - 0s - loss: 0.4405 - accuracy: 0.7886 - 82ms/epoch - 2ms/step\n",
            "Epoch 89/110\n",
            "46/46 - 0s - loss: 0.4403 - accuracy: 0.7897 - 89ms/epoch - 2ms/step\n",
            "Epoch 90/110\n",
            "46/46 - 0s - loss: 0.4400 - accuracy: 0.7881 - 98ms/epoch - 2ms/step\n",
            "Epoch 91/110\n",
            "46/46 - 0s - loss: 0.4404 - accuracy: 0.7911 - 91ms/epoch - 2ms/step\n",
            "Epoch 92/110\n",
            "46/46 - 0s - loss: 0.4399 - accuracy: 0.7886 - 86ms/epoch - 2ms/step\n",
            "Epoch 93/110\n",
            "46/46 - 0s - loss: 0.4398 - accuracy: 0.7886 - 105ms/epoch - 2ms/step\n",
            "Epoch 94/110\n",
            "46/46 - 0s - loss: 0.4400 - accuracy: 0.7871 - 99ms/epoch - 2ms/step\n",
            "Epoch 95/110\n",
            "46/46 - 0s - loss: 0.4403 - accuracy: 0.7914 - 86ms/epoch - 2ms/step\n",
            "Epoch 96/110\n",
            "46/46 - 0s - loss: 0.4395 - accuracy: 0.7873 - 88ms/epoch - 2ms/step\n",
            "Epoch 97/110\n",
            "46/46 - 0s - loss: 0.4398 - accuracy: 0.7880 - 87ms/epoch - 2ms/step\n",
            "Epoch 98/110\n",
            "46/46 - 0s - loss: 0.4390 - accuracy: 0.7881 - 90ms/epoch - 2ms/step\n",
            "Epoch 99/110\n",
            "46/46 - 0s - loss: 0.4402 - accuracy: 0.7895 - 85ms/epoch - 2ms/step\n",
            "Epoch 100/110\n",
            "46/46 - 0s - loss: 0.4394 - accuracy: 0.7888 - 100ms/epoch - 2ms/step\n",
            "Epoch 101/110\n",
            "46/46 - 0s - loss: 0.4397 - accuracy: 0.7888 - 87ms/epoch - 2ms/step\n",
            "Epoch 102/110\n",
            "46/46 - 0s - loss: 0.4387 - accuracy: 0.7873 - 89ms/epoch - 2ms/step\n",
            "Epoch 103/110\n",
            "46/46 - 0s - loss: 0.4391 - accuracy: 0.7883 - 94ms/epoch - 2ms/step\n",
            "Epoch 104/110\n",
            "46/46 - 0s - loss: 0.4400 - accuracy: 0.7867 - 94ms/epoch - 2ms/step\n",
            "Epoch 105/110\n",
            "46/46 - 0s - loss: 0.4396 - accuracy: 0.7900 - 99ms/epoch - 2ms/step\n",
            "Epoch 106/110\n",
            "46/46 - 0s - loss: 0.4386 - accuracy: 0.7899 - 88ms/epoch - 2ms/step\n",
            "Epoch 107/110\n",
            "46/46 - 0s - loss: 0.4395 - accuracy: 0.7852 - 85ms/epoch - 2ms/step\n",
            "Epoch 108/110\n",
            "46/46 - 0s - loss: 0.4383 - accuracy: 0.7893 - 86ms/epoch - 2ms/step\n",
            "Epoch 109/110\n",
            "46/46 - 0s - loss: 0.4379 - accuracy: 0.7890 - 83ms/epoch - 2ms/step\n",
            "Epoch 110/110\n",
            "46/46 - 0s - loss: 0.4386 - accuracy: 0.7899 - 88ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.6686 - accuracy: 0.6436 - 229ms/epoch - 19ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6762 - accuracy: 0.5591 - 943ms/epoch - 20ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.6549 - accuracy: 0.6711 - 105ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.6397 - accuracy: 0.6676 - 110ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.6261 - accuracy: 0.6818 - 112ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.6149 - accuracy: 0.6934 - 103ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.6043 - accuracy: 0.6959 - 104ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.5943 - accuracy: 0.6992 - 125ms/epoch - 3ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.5844 - accuracy: 0.7046 - 135ms/epoch - 3ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.5749 - accuracy: 0.7108 - 109ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.5665 - accuracy: 0.7223 - 127ms/epoch - 3ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.5589 - accuracy: 0.7358 - 120ms/epoch - 3ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.5522 - accuracy: 0.7389 - 123ms/epoch - 3ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.5460 - accuracy: 0.7432 - 108ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.5405 - accuracy: 0.7500 - 103ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.5355 - accuracy: 0.7505 - 101ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.5308 - accuracy: 0.7519 - 106ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.5265 - accuracy: 0.7527 - 120ms/epoch - 3ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.5227 - accuracy: 0.7539 - 115ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.5191 - accuracy: 0.7596 - 119ms/epoch - 3ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.5159 - accuracy: 0.7603 - 140ms/epoch - 3ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.5129 - accuracy: 0.7626 - 95ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.5101 - accuracy: 0.7632 - 98ms/epoch - 2ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.5075 - accuracy: 0.7646 - 100ms/epoch - 2ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.5050 - accuracy: 0.7660 - 100ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.5028 - accuracy: 0.7662 - 85ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.5007 - accuracy: 0.7657 - 87ms/epoch - 2ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4989 - accuracy: 0.7655 - 75ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4972 - accuracy: 0.7679 - 93ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4955 - accuracy: 0.7681 - 81ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4942 - accuracy: 0.7679 - 78ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4929 - accuracy: 0.7662 - 80ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4917 - accuracy: 0.7670 - 89ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4906 - accuracy: 0.7682 - 80ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4895 - accuracy: 0.7676 - 79ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7686 - 82ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4874 - accuracy: 0.7670 - 89ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4867 - accuracy: 0.7672 - 77ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4859 - accuracy: 0.7677 - 91ms/epoch - 2ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4852 - accuracy: 0.7686 - 80ms/epoch - 2ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4847 - accuracy: 0.7682 - 87ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4840 - accuracy: 0.7681 - 80ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4834 - accuracy: 0.7689 - 83ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4829 - accuracy: 0.7688 - 81ms/epoch - 2ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4824 - accuracy: 0.7681 - 79ms/epoch - 2ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4820 - accuracy: 0.7686 - 80ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4816 - accuracy: 0.7686 - 82ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4812 - accuracy: 0.7679 - 90ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4808 - accuracy: 0.7696 - 86ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4805 - accuracy: 0.7674 - 97ms/epoch - 2ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4801 - accuracy: 0.7695 - 84ms/epoch - 2ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4799 - accuracy: 0.7682 - 81ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4796 - accuracy: 0.7691 - 80ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7677 - 80ms/epoch - 2ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4790 - accuracy: 0.7684 - 82ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4789 - accuracy: 0.7689 - 83ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4785 - accuracy: 0.7700 - 80ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4784 - accuracy: 0.7682 - 93ms/epoch - 2ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4781 - accuracy: 0.7681 - 85ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4780 - accuracy: 0.7696 - 95ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4778 - accuracy: 0.7698 - 94ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7681 - 105ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4774 - accuracy: 0.7695 - 87ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4773 - accuracy: 0.7707 - 88ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4772 - accuracy: 0.7693 - 91ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4770 - accuracy: 0.7681 - 87ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4768 - accuracy: 0.7691 - 82ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7681 - 89ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4765 - accuracy: 0.7689 - 81ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7682 - 84ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7682 - 82ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4760 - accuracy: 0.7670 - 90ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4760 - accuracy: 0.7686 - 93ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7696 - 84ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7677 - 80ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4756 - accuracy: 0.7698 - 88ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4755 - accuracy: 0.7676 - 90ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4754 - accuracy: 0.7676 - 86ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4752 - accuracy: 0.7672 - 76ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4752 - accuracy: 0.7664 - 97ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7669 - 88ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7664 - 93ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7676 - 96ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7664 - 103ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7674 - 90ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7665 - 86ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7682 - 86ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7672 - 79ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7693 - 98ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7684 - 86ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7669 - 94ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4739 - accuracy: 0.7677 - 90ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4739 - accuracy: 0.7681 - 97ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4739 - accuracy: 0.7676 - 86ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4737 - accuracy: 0.7679 - 97ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7681 - 89ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7679 - 96ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7669 - 80ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7679 - 79ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7674 - 78ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4733 - accuracy: 0.7676 - 82ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7682 - 79ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7677 - 83ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4730 - accuracy: 0.7682 - 84ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4730 - accuracy: 0.7688 - 82ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4730 - accuracy: 0.7684 - 95ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7665 - 96ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7684 - 81ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7676 - 83ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4727 - accuracy: 0.7670 - 91ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7682 - 82ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7667 - 78ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7676 - 77ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7676 - 92ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7688 - 79ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7664 - 83ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7669 - 111ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7676 - 86ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7682 - 83ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7674 - 80ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7681 - 82ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5313 - accuracy: 0.7315 - 198ms/epoch - 17ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6542 - accuracy: 0.6274 - 791ms/epoch - 17ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.6086 - accuracy: 0.7230 - 106ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.5825 - accuracy: 0.7294 - 129ms/epoch - 3ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.5657 - accuracy: 0.7330 - 129ms/epoch - 3ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.5527 - accuracy: 0.7391 - 139ms/epoch - 3ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.5425 - accuracy: 0.7420 - 114ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.5344 - accuracy: 0.7446 - 133ms/epoch - 3ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.5279 - accuracy: 0.7467 - 129ms/epoch - 3ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.5227 - accuracy: 0.7489 - 128ms/epoch - 3ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.5185 - accuracy: 0.7484 - 120ms/epoch - 3ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.5151 - accuracy: 0.7503 - 121ms/epoch - 3ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.5120 - accuracy: 0.7519 - 148ms/epoch - 3ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.5094 - accuracy: 0.7531 - 148ms/epoch - 3ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.5072 - accuracy: 0.7531 - 126ms/epoch - 3ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.5052 - accuracy: 0.7541 - 106ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.5034 - accuracy: 0.7548 - 104ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.5018 - accuracy: 0.7550 - 104ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.5003 - accuracy: 0.7544 - 117ms/epoch - 3ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4990 - accuracy: 0.7551 - 125ms/epoch - 3ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4979 - accuracy: 0.7558 - 118ms/epoch - 3ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4968 - accuracy: 0.7565 - 148ms/epoch - 3ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4959 - accuracy: 0.7581 - 122ms/epoch - 3ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4950 - accuracy: 0.7577 - 124ms/epoch - 3ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4942 - accuracy: 0.7593 - 118ms/epoch - 3ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4935 - accuracy: 0.7594 - 124ms/epoch - 3ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4929 - accuracy: 0.7601 - 85ms/epoch - 2ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4922 - accuracy: 0.7594 - 78ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4917 - accuracy: 0.7605 - 79ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4912 - accuracy: 0.7608 - 88ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4906 - accuracy: 0.7603 - 84ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4902 - accuracy: 0.7613 - 83ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4897 - accuracy: 0.7610 - 89ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4893 - accuracy: 0.7607 - 80ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4888 - accuracy: 0.7607 - 78ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4885 - accuracy: 0.7612 - 104ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4881 - accuracy: 0.7629 - 93ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4877 - accuracy: 0.7626 - 86ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4874 - accuracy: 0.7632 - 93ms/epoch - 2ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4871 - accuracy: 0.7631 - 92ms/epoch - 2ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4868 - accuracy: 0.7636 - 95ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4863 - accuracy: 0.7639 - 88ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4862 - accuracy: 0.7636 - 85ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4859 - accuracy: 0.7634 - 93ms/epoch - 2ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4857 - accuracy: 0.7638 - 78ms/epoch - 2ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4854 - accuracy: 0.7631 - 79ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4853 - accuracy: 0.7638 - 88ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4851 - accuracy: 0.7641 - 77ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4849 - accuracy: 0.7641 - 83ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4846 - accuracy: 0.7641 - 83ms/epoch - 2ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4845 - accuracy: 0.7643 - 82ms/epoch - 2ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4842 - accuracy: 0.7636 - 88ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4841 - accuracy: 0.7632 - 86ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4839 - accuracy: 0.7641 - 85ms/epoch - 2ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4837 - accuracy: 0.7648 - 93ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4836 - accuracy: 0.7641 - 86ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4834 - accuracy: 0.7650 - 78ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4831 - accuracy: 0.7653 - 82ms/epoch - 2ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4832 - accuracy: 0.7648 - 81ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4830 - accuracy: 0.7646 - 86ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7648 - 85ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7657 - 83ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4825 - accuracy: 0.7646 - 95ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4824 - accuracy: 0.7662 - 98ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4823 - accuracy: 0.7657 - 89ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4821 - accuracy: 0.7657 - 87ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4820 - accuracy: 0.7658 - 96ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4818 - accuracy: 0.7667 - 87ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4817 - accuracy: 0.7660 - 85ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4816 - accuracy: 0.7674 - 90ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4815 - accuracy: 0.7662 - 86ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4814 - accuracy: 0.7670 - 92ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4812 - accuracy: 0.7670 - 83ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4812 - accuracy: 0.7677 - 94ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4810 - accuracy: 0.7667 - 86ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4810 - accuracy: 0.7672 - 89ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4808 - accuracy: 0.7674 - 87ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4807 - accuracy: 0.7674 - 90ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4805 - accuracy: 0.7676 - 78ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4806 - accuracy: 0.7670 - 80ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4805 - accuracy: 0.7681 - 100ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4803 - accuracy: 0.7684 - 90ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4802 - accuracy: 0.7684 - 92ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4801 - accuracy: 0.7684 - 90ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4799 - accuracy: 0.7679 - 84ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4799 - accuracy: 0.7682 - 87ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4798 - accuracy: 0.7682 - 80ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4797 - accuracy: 0.7684 - 86ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4796 - accuracy: 0.7686 - 92ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4796 - accuracy: 0.7679 - 77ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4794 - accuracy: 0.7688 - 84ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7679 - 96ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4792 - accuracy: 0.7679 - 82ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4790 - accuracy: 0.7684 - 82ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4792 - accuracy: 0.7689 - 81ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4789 - accuracy: 0.7686 - 83ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4790 - accuracy: 0.7686 - 79ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4789 - accuracy: 0.7686 - 84ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4787 - accuracy: 0.7684 - 77ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4786 - accuracy: 0.7677 - 80ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4786 - accuracy: 0.7682 - 88ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4785 - accuracy: 0.7682 - 89ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4785 - accuracy: 0.7686 - 87ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4783 - accuracy: 0.7679 - 86ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4783 - accuracy: 0.7688 - 78ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4782 - accuracy: 0.7676 - 83ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4781 - accuracy: 0.7688 - 100ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4780 - accuracy: 0.7693 - 83ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7682 - 82ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7670 - 94ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7677 - 73ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4777 - accuracy: 0.7688 - 95ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4775 - accuracy: 0.7693 - 76ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7682 - 81ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7676 - 80ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7679 - 88ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4774 - accuracy: 0.7682 - 89ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4773 - accuracy: 0.7686 - 86ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4773 - accuracy: 0.7681 - 87ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4771 - accuracy: 0.7682 - 81ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4772 - accuracy: 0.7684 - 81ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5101 - accuracy: 0.7405 - 213ms/epoch - 18ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6894 - accuracy: 0.5619 - 804ms/epoch - 17ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.6684 - accuracy: 0.5952 - 89ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.6503 - accuracy: 0.6095 - 127ms/epoch - 3ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.6348 - accuracy: 0.6473 - 137ms/epoch - 3ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.6209 - accuracy: 0.6616 - 122ms/epoch - 3ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.6077 - accuracy: 0.6799 - 114ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.5952 - accuracy: 0.7028 - 118ms/epoch - 3ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.5826 - accuracy: 0.7165 - 111ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.5704 - accuracy: 0.7286 - 106ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.5592 - accuracy: 0.7375 - 112ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.5491 - accuracy: 0.7448 - 125ms/epoch - 3ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.5399 - accuracy: 0.7491 - 116ms/epoch - 3ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.5318 - accuracy: 0.7487 - 122ms/epoch - 3ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.5247 - accuracy: 0.7520 - 134ms/epoch - 3ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.5186 - accuracy: 0.7558 - 111ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.5136 - accuracy: 0.7555 - 126ms/epoch - 3ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.5092 - accuracy: 0.7574 - 135ms/epoch - 3ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.5056 - accuracy: 0.7603 - 135ms/epoch - 3ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.5026 - accuracy: 0.7612 - 145ms/epoch - 3ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.5001 - accuracy: 0.7624 - 119ms/epoch - 3ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4979 - accuracy: 0.7627 - 138ms/epoch - 3ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4960 - accuracy: 0.7643 - 139ms/epoch - 3ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4945 - accuracy: 0.7646 - 118ms/epoch - 3ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4932 - accuracy: 0.7664 - 111ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4919 - accuracy: 0.7670 - 105ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4909 - accuracy: 0.7664 - 119ms/epoch - 3ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4900 - accuracy: 0.7658 - 90ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4891 - accuracy: 0.7653 - 77ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7651 - 81ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4878 - accuracy: 0.7648 - 83ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4873 - accuracy: 0.7651 - 84ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4866 - accuracy: 0.7650 - 88ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4860 - accuracy: 0.7657 - 76ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4855 - accuracy: 0.7650 - 78ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4850 - accuracy: 0.7660 - 75ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4845 - accuracy: 0.7658 - 77ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4840 - accuracy: 0.7667 - 92ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4835 - accuracy: 0.7667 - 92ms/epoch - 2ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4831 - accuracy: 0.7665 - 81ms/epoch - 2ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4828 - accuracy: 0.7669 - 78ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4824 - accuracy: 0.7672 - 78ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4819 - accuracy: 0.7679 - 78ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4816 - accuracy: 0.7679 - 79ms/epoch - 2ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4812 - accuracy: 0.7677 - 81ms/epoch - 2ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4809 - accuracy: 0.7696 - 75ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4807 - accuracy: 0.7672 - 115ms/epoch - 3ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4804 - accuracy: 0.7682 - 81ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4801 - accuracy: 0.7684 - 77ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4798 - accuracy: 0.7695 - 97ms/epoch - 2ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4795 - accuracy: 0.7681 - 98ms/epoch - 2ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7684 - 82ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4791 - accuracy: 0.7693 - 93ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4788 - accuracy: 0.7689 - 102ms/epoch - 2ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4786 - accuracy: 0.7677 - 102ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4783 - accuracy: 0.7705 - 101ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4782 - accuracy: 0.7688 - 87ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7700 - 91ms/epoch - 2ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4777 - accuracy: 0.7686 - 104ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4774 - accuracy: 0.7698 - 106ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4774 - accuracy: 0.7689 - 87ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4771 - accuracy: 0.7698 - 74ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4771 - accuracy: 0.7705 - 83ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4769 - accuracy: 0.7691 - 85ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7700 - 87ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4766 - accuracy: 0.7701 - 82ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4764 - accuracy: 0.7689 - 83ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4763 - accuracy: 0.7695 - 90ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4762 - accuracy: 0.7691 - 83ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4761 - accuracy: 0.7696 - 87ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4759 - accuracy: 0.7695 - 83ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7708 - 93ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4756 - accuracy: 0.7693 - 83ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4756 - accuracy: 0.7705 - 91ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4754 - accuracy: 0.7701 - 96ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4753 - accuracy: 0.7707 - 100ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4751 - accuracy: 0.7703 - 80ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4752 - accuracy: 0.7693 - 77ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4750 - accuracy: 0.7698 - 76ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7700 - 83ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4748 - accuracy: 0.7691 - 80ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4746 - accuracy: 0.7712 - 79ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7705 - 90ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7705 - 80ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7701 - 84ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7703 - 88ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7705 - 91ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7705 - 85ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4739 - accuracy: 0.7714 - 79ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4737 - accuracy: 0.7707 - 77ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4737 - accuracy: 0.7705 - 86ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4736 - accuracy: 0.7708 - 79ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7712 - 87ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4733 - accuracy: 0.7722 - 102ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4733 - accuracy: 0.7710 - 86ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7707 - 92ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7708 - 93ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4730 - accuracy: 0.7717 - 79ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4728 - accuracy: 0.7714 - 89ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7717 - 88ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7720 - 80ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7712 - 85ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7715 - 84ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7720 - 83ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7724 - 93ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7729 - 80ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7724 - 83ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4722 - accuracy: 0.7724 - 82ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4720 - accuracy: 0.7729 - 85ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4719 - accuracy: 0.7729 - 83ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4719 - accuracy: 0.7726 - 90ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4718 - accuracy: 0.7731 - 84ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4717 - accuracy: 0.7733 - 79ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7727 - 86ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4715 - accuracy: 0.7731 - 89ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7734 - 82ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7719 - 90ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4713 - accuracy: 0.7731 - 89ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4711 - accuracy: 0.7707 - 90ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4712 - accuracy: 0.7734 - 90ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4711 - accuracy: 0.7720 - 86ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5535 - accuracy: 0.7219 - 193ms/epoch - 16ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6855 - accuracy: 0.5374 - 796ms/epoch - 17ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.6582 - accuracy: 0.6264 - 92ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.6357 - accuracy: 0.6884 - 89ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.6161 - accuracy: 0.7203 - 130ms/epoch - 3ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.5994 - accuracy: 0.7324 - 106ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.5851 - accuracy: 0.7401 - 102ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.5731 - accuracy: 0.7441 - 147ms/epoch - 3ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.5630 - accuracy: 0.7439 - 124ms/epoch - 3ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.5545 - accuracy: 0.7439 - 111ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.5472 - accuracy: 0.7451 - 110ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.5410 - accuracy: 0.7455 - 138ms/epoch - 3ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.5357 - accuracy: 0.7443 - 126ms/epoch - 3ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.5312 - accuracy: 0.7463 - 124ms/epoch - 3ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.5273 - accuracy: 0.7455 - 125ms/epoch - 3ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.5238 - accuracy: 0.7451 - 136ms/epoch - 3ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.5209 - accuracy: 0.7465 - 124ms/epoch - 3ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.5184 - accuracy: 0.7475 - 106ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.5161 - accuracy: 0.7486 - 103ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.5141 - accuracy: 0.7489 - 126ms/epoch - 3ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.5123 - accuracy: 0.7493 - 117ms/epoch - 3ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.5108 - accuracy: 0.7505 - 108ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.5095 - accuracy: 0.7494 - 118ms/epoch - 3ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.5083 - accuracy: 0.7512 - 119ms/epoch - 3ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.5072 - accuracy: 0.7505 - 104ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.5062 - accuracy: 0.7532 - 102ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.5054 - accuracy: 0.7527 - 128ms/epoch - 3ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.5045 - accuracy: 0.7525 - 122ms/epoch - 3ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.5037 - accuracy: 0.7520 - 136ms/epoch - 3ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.5030 - accuracy: 0.7538 - 78ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.5025 - accuracy: 0.7539 - 78ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.5019 - accuracy: 0.7551 - 90ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.5014 - accuracy: 0.7543 - 90ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.5008 - accuracy: 0.7553 - 78ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.5004 - accuracy: 0.7555 - 77ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.5000 - accuracy: 0.7574 - 77ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4996 - accuracy: 0.7572 - 75ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4992 - accuracy: 0.7579 - 83ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4988 - accuracy: 0.7588 - 82ms/epoch - 2ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4984 - accuracy: 0.7584 - 81ms/epoch - 2ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4981 - accuracy: 0.7581 - 80ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4977 - accuracy: 0.7584 - 88ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4975 - accuracy: 0.7584 - 87ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4971 - accuracy: 0.7577 - 96ms/epoch - 2ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4970 - accuracy: 0.7579 - 92ms/epoch - 2ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4966 - accuracy: 0.7591 - 89ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4963 - accuracy: 0.7588 - 96ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4960 - accuracy: 0.7581 - 81ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4958 - accuracy: 0.7579 - 80ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4956 - accuracy: 0.7581 - 92ms/epoch - 2ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4954 - accuracy: 0.7586 - 114ms/epoch - 2ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4951 - accuracy: 0.7579 - 92ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4949 - accuracy: 0.7593 - 87ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4947 - accuracy: 0.7589 - 91ms/epoch - 2ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4946 - accuracy: 0.7582 - 82ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4943 - accuracy: 0.7593 - 86ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4943 - accuracy: 0.7596 - 79ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4941 - accuracy: 0.7605 - 85ms/epoch - 2ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4938 - accuracy: 0.7600 - 78ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4936 - accuracy: 0.7605 - 86ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4935 - accuracy: 0.7594 - 80ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4933 - accuracy: 0.7588 - 81ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4932 - accuracy: 0.7603 - 79ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4930 - accuracy: 0.7601 - 86ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4928 - accuracy: 0.7603 - 84ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4927 - accuracy: 0.7600 - 100ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4926 - accuracy: 0.7612 - 80ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4924 - accuracy: 0.7598 - 79ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4924 - accuracy: 0.7603 - 78ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4921 - accuracy: 0.7612 - 79ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4921 - accuracy: 0.7605 - 75ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4919 - accuracy: 0.7610 - 86ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4918 - accuracy: 0.7600 - 77ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4916 - accuracy: 0.7619 - 85ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4915 - accuracy: 0.7605 - 76ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4914 - accuracy: 0.7610 - 82ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4912 - accuracy: 0.7603 - 84ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4912 - accuracy: 0.7600 - 96ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4911 - accuracy: 0.7601 - 83ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4910 - accuracy: 0.7612 - 71ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4908 - accuracy: 0.7598 - 79ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4907 - accuracy: 0.7605 - 82ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4906 - accuracy: 0.7605 - 81ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4905 - accuracy: 0.7612 - 84ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4904 - accuracy: 0.7608 - 84ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4904 - accuracy: 0.7607 - 109ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4902 - accuracy: 0.7607 - 83ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4901 - accuracy: 0.7603 - 80ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4900 - accuracy: 0.7615 - 97ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4899 - accuracy: 0.7607 - 85ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4898 - accuracy: 0.7610 - 77ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4897 - accuracy: 0.7605 - 80ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4896 - accuracy: 0.7617 - 78ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4895 - accuracy: 0.7605 - 81ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4895 - accuracy: 0.7619 - 96ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4893 - accuracy: 0.7608 - 81ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4892 - accuracy: 0.7601 - 87ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4891 - accuracy: 0.7615 - 78ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4892 - accuracy: 0.7608 - 79ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4889 - accuracy: 0.7612 - 88ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4889 - accuracy: 0.7608 - 89ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4888 - accuracy: 0.7615 - 79ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4888 - accuracy: 0.7620 - 80ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4887 - accuracy: 0.7617 - 77ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4886 - accuracy: 0.7620 - 77ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4885 - accuracy: 0.7612 - 85ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7610 - 95ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4883 - accuracy: 0.7619 - 82ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4882 - accuracy: 0.7620 - 90ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4882 - accuracy: 0.7613 - 90ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4881 - accuracy: 0.7624 - 87ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4880 - accuracy: 0.7622 - 79ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4878 - accuracy: 0.7603 - 99ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4879 - accuracy: 0.7627 - 78ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4877 - accuracy: 0.7610 - 80ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4877 - accuracy: 0.7622 - 80ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4876 - accuracy: 0.7620 - 78ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4876 - accuracy: 0.7627 - 81ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4875 - accuracy: 0.7617 - 81ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4874 - accuracy: 0.7619 - 94ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4873 - accuracy: 0.7613 - 93ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.4768 - accuracy: 0.7805 - 200ms/epoch - 17ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.7407 - accuracy: 0.4400 - 777ms/epoch - 17ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.6601 - accuracy: 0.5999 - 110ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.6259 - accuracy: 0.6586 - 83ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.6054 - accuracy: 0.6825 - 91ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.5903 - accuracy: 0.6896 - 89ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.5787 - accuracy: 0.7003 - 79ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.5681 - accuracy: 0.7276 - 115ms/epoch - 3ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.5582 - accuracy: 0.7431 - 84ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.5488 - accuracy: 0.7576 - 80ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.5400 - accuracy: 0.7602 - 84ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.5319 - accuracy: 0.7626 - 88ms/epoch - 2ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.5244 - accuracy: 0.7659 - 87ms/epoch - 2ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.5176 - accuracy: 0.7650 - 97ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.5117 - accuracy: 0.7628 - 83ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.5063 - accuracy: 0.7614 - 81ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.5016 - accuracy: 0.7624 - 89ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.4973 - accuracy: 0.7638 - 82ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.4934 - accuracy: 0.7647 - 87ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4899 - accuracy: 0.7648 - 82ms/epoch - 2ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4869 - accuracy: 0.7654 - 84ms/epoch - 2ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4841 - accuracy: 0.7666 - 83ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4817 - accuracy: 0.7683 - 87ms/epoch - 2ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4796 - accuracy: 0.7690 - 86ms/epoch - 2ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4774 - accuracy: 0.7709 - 91ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4755 - accuracy: 0.7712 - 78ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4739 - accuracy: 0.7719 - 81ms/epoch - 2ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4724 - accuracy: 0.7712 - 81ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4712 - accuracy: 0.7721 - 91ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4702 - accuracy: 0.7724 - 77ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4693 - accuracy: 0.7724 - 77ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4683 - accuracy: 0.7721 - 89ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4675 - accuracy: 0.7738 - 82ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4670 - accuracy: 0.7731 - 76ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4665 - accuracy: 0.7740 - 84ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4660 - accuracy: 0.7747 - 94ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4655 - accuracy: 0.7743 - 86ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4651 - accuracy: 0.7750 - 83ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4647 - accuracy: 0.7761 - 115ms/epoch - 3ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7766 - 131ms/epoch - 3ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4641 - accuracy: 0.7754 - 111ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4638 - accuracy: 0.7767 - 109ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4636 - accuracy: 0.7750 - 107ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4634 - accuracy: 0.7766 - 122ms/epoch - 3ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4632 - accuracy: 0.7766 - 122ms/epoch - 3ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4631 - accuracy: 0.7757 - 120ms/epoch - 3ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4628 - accuracy: 0.7759 - 103ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4626 - accuracy: 0.7750 - 106ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4625 - accuracy: 0.7774 - 111ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4623 - accuracy: 0.7785 - 123ms/epoch - 3ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4623 - accuracy: 0.7771 - 121ms/epoch - 3ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4621 - accuracy: 0.7780 - 110ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4620 - accuracy: 0.7773 - 110ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4619 - accuracy: 0.7792 - 132ms/epoch - 3ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4617 - accuracy: 0.7792 - 111ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4616 - accuracy: 0.7788 - 109ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4615 - accuracy: 0.7790 - 106ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4613 - accuracy: 0.7786 - 119ms/epoch - 3ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4613 - accuracy: 0.7783 - 142ms/epoch - 3ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4612 - accuracy: 0.7785 - 130ms/epoch - 3ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4612 - accuracy: 0.7785 - 140ms/epoch - 3ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4610 - accuracy: 0.7793 - 121ms/epoch - 3ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4609 - accuracy: 0.7788 - 119ms/epoch - 3ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4608 - accuracy: 0.7800 - 115ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4607 - accuracy: 0.7776 - 92ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4606 - accuracy: 0.7790 - 98ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4605 - accuracy: 0.7790 - 85ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4603 - accuracy: 0.7797 - 80ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4603 - accuracy: 0.7816 - 86ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4602 - accuracy: 0.7802 - 89ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4601 - accuracy: 0.7804 - 79ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4600 - accuracy: 0.7809 - 97ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4599 - accuracy: 0.7809 - 74ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4597 - accuracy: 0.7805 - 81ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4597 - accuracy: 0.7805 - 79ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4594 - accuracy: 0.7790 - 75ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4596 - accuracy: 0.7816 - 85ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4594 - accuracy: 0.7790 - 99ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7807 - 84ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4593 - accuracy: 0.7805 - 87ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4593 - accuracy: 0.7805 - 99ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4592 - accuracy: 0.7809 - 87ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4590 - accuracy: 0.7802 - 87ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4590 - accuracy: 0.7814 - 95ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4588 - accuracy: 0.7800 - 90ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7805 - 85ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7811 - 86ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7800 - 80ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4586 - accuracy: 0.7804 - 98ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4585 - accuracy: 0.7804 - 81ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4584 - accuracy: 0.7814 - 97ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4583 - accuracy: 0.7798 - 81ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4584 - accuracy: 0.7798 - 81ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4583 - accuracy: 0.7800 - 89ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4582 - accuracy: 0.7802 - 78ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4582 - accuracy: 0.7797 - 75ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4581 - accuracy: 0.7802 - 79ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4581 - accuracy: 0.7805 - 76ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4580 - accuracy: 0.7795 - 79ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4580 - accuracy: 0.7805 - 103ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7798 - 85ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4578 - accuracy: 0.7804 - 87ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7804 - 83ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7800 - 92ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4577 - accuracy: 0.7805 - 80ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7798 - 80ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4575 - accuracy: 0.7807 - 81ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7819 - 93ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4575 - accuracy: 0.7804 - 80ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4574 - accuracy: 0.7804 - 84ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4574 - accuracy: 0.7809 - 80ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4573 - accuracy: 0.7819 - 100ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4573 - accuracy: 0.7807 - 83ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4572 - accuracy: 0.7805 - 81ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4571 - accuracy: 0.7795 - 98ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4571 - accuracy: 0.7811 - 90ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4571 - accuracy: 0.7802 - 85ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7821 - 76ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4569 - accuracy: 0.7812 - 87ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7797 - 77ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4569 - accuracy: 0.7819 - 83ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.6876 - accuracy: 0.6519 - 218ms/epoch - 18ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6876 - accuracy: 0.4935 - 1s/epoch - 23ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.5913 - accuracy: 0.7274 - 102ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.5465 - accuracy: 0.7541 - 86ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.5094 - accuracy: 0.7596 - 85ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.4907 - accuracy: 0.7660 - 79ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.4830 - accuracy: 0.7684 - 82ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.4786 - accuracy: 0.7691 - 90ms/epoch - 2ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.4760 - accuracy: 0.7703 - 85ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.4744 - accuracy: 0.7707 - 98ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.4735 - accuracy: 0.7712 - 87ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.4743 - accuracy: 0.7739 - 86ms/epoch - 2ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7698 - 92ms/epoch - 2ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.4713 - accuracy: 0.7696 - 88ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7688 - 87ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.4700 - accuracy: 0.7689 - 86ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.4690 - accuracy: 0.7700 - 83ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.4708 - accuracy: 0.7731 - 85ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.4699 - accuracy: 0.7672 - 84ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4679 - accuracy: 0.7686 - 91ms/epoch - 2ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4679 - accuracy: 0.7695 - 106ms/epoch - 2ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4680 - accuracy: 0.7698 - 93ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4669 - accuracy: 0.7672 - 99ms/epoch - 2ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4665 - accuracy: 0.7686 - 89ms/epoch - 2ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7715 - 81ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4662 - accuracy: 0.7686 - 92ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4649 - accuracy: 0.7679 - 82ms/epoch - 2ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4642 - accuracy: 0.7701 - 83ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4650 - accuracy: 0.7715 - 91ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4642 - accuracy: 0.7695 - 89ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4634 - accuracy: 0.7695 - 89ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7707 - 95ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4629 - accuracy: 0.7700 - 90ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4629 - accuracy: 0.7708 - 86ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4620 - accuracy: 0.7717 - 100ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4616 - accuracy: 0.7693 - 91ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4615 - accuracy: 0.7714 - 86ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4609 - accuracy: 0.7696 - 81ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4603 - accuracy: 0.7717 - 140ms/epoch - 3ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7724 - 136ms/epoch - 3ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7764 - 154ms/epoch - 3ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4592 - accuracy: 0.7734 - 122ms/epoch - 3ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4594 - accuracy: 0.7726 - 159ms/epoch - 3ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4582 - accuracy: 0.7748 - 128ms/epoch - 3ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7757 - 122ms/epoch - 3ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4588 - accuracy: 0.7734 - 133ms/epoch - 3ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4573 - accuracy: 0.7783 - 138ms/epoch - 3ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4594 - accuracy: 0.7764 - 157ms/epoch - 3ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7784 - 134ms/epoch - 3ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4564 - accuracy: 0.7781 - 146ms/epoch - 3ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4564 - accuracy: 0.7789 - 126ms/epoch - 3ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4566 - accuracy: 0.7769 - 115ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4555 - accuracy: 0.7805 - 125ms/epoch - 3ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4554 - accuracy: 0.7810 - 140ms/epoch - 3ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4557 - accuracy: 0.7834 - 159ms/epoch - 3ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4549 - accuracy: 0.7821 - 170ms/epoch - 4ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4551 - accuracy: 0.7781 - 174ms/epoch - 4ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4547 - accuracy: 0.7831 - 152ms/epoch - 3ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4545 - accuracy: 0.7808 - 90ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4541 - accuracy: 0.7819 - 97ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7833 - 99ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4537 - accuracy: 0.7822 - 101ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4533 - accuracy: 0.7833 - 99ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7805 - 104ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4538 - accuracy: 0.7802 - 83ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4528 - accuracy: 0.7840 - 96ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4528 - accuracy: 0.7848 - 82ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4518 - accuracy: 0.7834 - 80ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7826 - 85ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4516 - accuracy: 0.7819 - 98ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4518 - accuracy: 0.7802 - 88ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4514 - accuracy: 0.7834 - 106ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4520 - accuracy: 0.7843 - 112ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7840 - 104ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4513 - accuracy: 0.7829 - 100ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4495 - accuracy: 0.7841 - 100ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4506 - accuracy: 0.7829 - 88ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4501 - accuracy: 0.7833 - 85ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4505 - accuracy: 0.7843 - 87ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4497 - accuracy: 0.7824 - 84ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4494 - accuracy: 0.7824 - 89ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7857 - 107ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4497 - accuracy: 0.7850 - 100ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4491 - accuracy: 0.7838 - 99ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7810 - 108ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4491 - accuracy: 0.7846 - 98ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4481 - accuracy: 0.7833 - 85ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4483 - accuracy: 0.7855 - 91ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4489 - accuracy: 0.7841 - 96ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4487 - accuracy: 0.7829 - 88ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4483 - accuracy: 0.7862 - 93ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4482 - accuracy: 0.7831 - 87ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4481 - accuracy: 0.7838 - 93ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4474 - accuracy: 0.7857 - 94ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4471 - accuracy: 0.7848 - 95ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4464 - accuracy: 0.7865 - 86ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4473 - accuracy: 0.7833 - 86ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4467 - accuracy: 0.7840 - 88ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7864 - 84ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4464 - accuracy: 0.7869 - 81ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4463 - accuracy: 0.7871 - 85ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4473 - accuracy: 0.7822 - 83ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7852 - 86ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4453 - accuracy: 0.7869 - 93ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4458 - accuracy: 0.7862 - 92ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4450 - accuracy: 0.7862 - 101ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7862 - 92ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4456 - accuracy: 0.7840 - 83ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4454 - accuracy: 0.7876 - 81ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4450 - accuracy: 0.7864 - 85ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4455 - accuracy: 0.7874 - 85ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4460 - accuracy: 0.7871 - 98ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7848 - 107ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4438 - accuracy: 0.7871 - 98ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4437 - accuracy: 0.7840 - 89ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4464 - accuracy: 0.7869 - 87ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4445 - accuracy: 0.7884 - 107ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7860 - 82ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7864 - 88ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4444 - accuracy: 0.7836 - 102ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4434 - accuracy: 0.7853 - 124ms/epoch - 3ms/step\n",
            "12/12 - 0s - loss: 0.5448 - accuracy: 0.7067 - 284ms/epoch - 24ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6984 - accuracy: 0.5381 - 1s/epoch - 28ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.5877 - accuracy: 0.6901 - 131ms/epoch - 3ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.5360 - accuracy: 0.7432 - 148ms/epoch - 3ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.5043 - accuracy: 0.7581 - 96ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.4922 - accuracy: 0.7636 - 85ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.4875 - accuracy: 0.7667 - 85ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.4841 - accuracy: 0.7700 - 88ms/epoch - 2ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.4821 - accuracy: 0.7710 - 84ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.4804 - accuracy: 0.7695 - 100ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.4793 - accuracy: 0.7682 - 84ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.4783 - accuracy: 0.7688 - 78ms/epoch - 2ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.4776 - accuracy: 0.7714 - 80ms/epoch - 2ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.4768 - accuracy: 0.7677 - 83ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.4758 - accuracy: 0.7705 - 88ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.4748 - accuracy: 0.7693 - 88ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7695 - 98ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.4745 - accuracy: 0.7681 - 95ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.4746 - accuracy: 0.7684 - 88ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7717 - 84ms/epoch - 2ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4732 - accuracy: 0.7688 - 94ms/epoch - 2ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7689 - 89ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4723 - accuracy: 0.7710 - 128ms/epoch - 3ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7715 - 140ms/epoch - 3ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7703 - 126ms/epoch - 3ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4714 - accuracy: 0.7691 - 150ms/epoch - 3ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7743 - 132ms/epoch - 3ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4707 - accuracy: 0.7724 - 137ms/epoch - 3ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4700 - accuracy: 0.7708 - 127ms/epoch - 3ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4690 - accuracy: 0.7745 - 119ms/epoch - 3ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4695 - accuracy: 0.7722 - 146ms/epoch - 3ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4689 - accuracy: 0.7712 - 111ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4683 - accuracy: 0.7755 - 131ms/epoch - 3ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4683 - accuracy: 0.7770 - 132ms/epoch - 3ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4689 - accuracy: 0.7710 - 129ms/epoch - 3ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4679 - accuracy: 0.7736 - 123ms/epoch - 3ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4674 - accuracy: 0.7765 - 123ms/epoch - 3ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4673 - accuracy: 0.7745 - 122ms/epoch - 3ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4670 - accuracy: 0.7765 - 121ms/epoch - 3ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4664 - accuracy: 0.7753 - 133ms/epoch - 3ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4663 - accuracy: 0.7774 - 137ms/epoch - 3ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4662 - accuracy: 0.7745 - 138ms/epoch - 3ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4659 - accuracy: 0.7743 - 132ms/epoch - 3ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4656 - accuracy: 0.7743 - 124ms/epoch - 3ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4655 - accuracy: 0.7764 - 121ms/epoch - 3ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4656 - accuracy: 0.7748 - 97ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4645 - accuracy: 0.7769 - 86ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4651 - accuracy: 0.7746 - 86ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7777 - 96ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7769 - 88ms/epoch - 2ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4650 - accuracy: 0.7755 - 89ms/epoch - 2ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4643 - accuracy: 0.7784 - 97ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4633 - accuracy: 0.7726 - 83ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4633 - accuracy: 0.7764 - 83ms/epoch - 2ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7738 - 84ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4640 - accuracy: 0.7733 - 88ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4632 - accuracy: 0.7774 - 90ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4630 - accuracy: 0.7770 - 82ms/epoch - 2ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4624 - accuracy: 0.7795 - 86ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4625 - accuracy: 0.7757 - 100ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4624 - accuracy: 0.7803 - 99ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4622 - accuracy: 0.7770 - 89ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4626 - accuracy: 0.7757 - 89ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4618 - accuracy: 0.7762 - 85ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4615 - accuracy: 0.7779 - 86ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4621 - accuracy: 0.7770 - 80ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4603 - accuracy: 0.7817 - 95ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4609 - accuracy: 0.7791 - 85ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4604 - accuracy: 0.7764 - 95ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4598 - accuracy: 0.7808 - 91ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4597 - accuracy: 0.7793 - 88ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4594 - accuracy: 0.7821 - 87ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4608 - accuracy: 0.7753 - 95ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4592 - accuracy: 0.7788 - 82ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4608 - accuracy: 0.7765 - 84ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4593 - accuracy: 0.7750 - 90ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4584 - accuracy: 0.7793 - 89ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4592 - accuracy: 0.7802 - 95ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4586 - accuracy: 0.7798 - 85ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4580 - accuracy: 0.7829 - 86ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4583 - accuracy: 0.7802 - 81ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7783 - 84ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4579 - accuracy: 0.7821 - 98ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4578 - accuracy: 0.7814 - 91ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4578 - accuracy: 0.7814 - 82ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4574 - accuracy: 0.7784 - 86ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4577 - accuracy: 0.7757 - 92ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7821 - 86ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4571 - accuracy: 0.7819 - 95ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4575 - accuracy: 0.7802 - 97ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4565 - accuracy: 0.7817 - 85ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4564 - accuracy: 0.7817 - 83ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4562 - accuracy: 0.7807 - 89ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4572 - accuracy: 0.7789 - 99ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4563 - accuracy: 0.7789 - 80ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4553 - accuracy: 0.7840 - 76ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4560 - accuracy: 0.7841 - 87ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4567 - accuracy: 0.7793 - 78ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4560 - accuracy: 0.7803 - 80ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4552 - accuracy: 0.7812 - 102ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4555 - accuracy: 0.7833 - 85ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4550 - accuracy: 0.7802 - 92ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4544 - accuracy: 0.7824 - 94ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4545 - accuracy: 0.7840 - 90ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4546 - accuracy: 0.7833 - 84ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4545 - accuracy: 0.7838 - 96ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4550 - accuracy: 0.7834 - 88ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4566 - accuracy: 0.7789 - 86ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4539 - accuracy: 0.7838 - 85ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7848 - 83ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7846 - 94ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4538 - accuracy: 0.7838 - 101ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7843 - 90ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4545 - accuracy: 0.7841 - 85ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4544 - accuracy: 0.7833 - 100ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4533 - accuracy: 0.7833 - 92ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7858 - 87ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4529 - accuracy: 0.7810 - 90ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4542 - accuracy: 0.7855 - 80ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4528 - accuracy: 0.7826 - 79ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4528 - accuracy: 0.7853 - 88ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5054 - accuracy: 0.7308 - 175ms/epoch - 15ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 2s - loss: 0.6272 - accuracy: 0.6450 - 2s/epoch - 53ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.5649 - accuracy: 0.7301 - 94ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.5131 - accuracy: 0.7603 - 95ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.4888 - accuracy: 0.7624 - 95ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.4802 - accuracy: 0.7664 - 95ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.4775 - accuracy: 0.7660 - 92ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.4748 - accuracy: 0.7646 - 92ms/epoch - 2ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7665 - 86ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.4719 - accuracy: 0.7669 - 82ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7664 - 94ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.4702 - accuracy: 0.7684 - 92ms/epoch - 2ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.4692 - accuracy: 0.7684 - 91ms/epoch - 2ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.4696 - accuracy: 0.7688 - 83ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.4683 - accuracy: 0.7696 - 94ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.4672 - accuracy: 0.7703 - 95ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.4666 - accuracy: 0.7684 - 100ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.4657 - accuracy: 0.7700 - 100ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.4656 - accuracy: 0.7707 - 101ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4652 - accuracy: 0.7698 - 87ms/epoch - 2ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4651 - accuracy: 0.7695 - 96ms/epoch - 2ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4642 - accuracy: 0.7688 - 91ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4638 - accuracy: 0.7714 - 96ms/epoch - 2ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4635 - accuracy: 0.7727 - 86ms/epoch - 2ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4640 - accuracy: 0.7739 - 108ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4627 - accuracy: 0.7712 - 91ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4622 - accuracy: 0.7752 - 98ms/epoch - 2ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4621 - accuracy: 0.7726 - 96ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4615 - accuracy: 0.7720 - 85ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4613 - accuracy: 0.7752 - 88ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4615 - accuracy: 0.7738 - 118ms/epoch - 3ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4611 - accuracy: 0.7748 - 91ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4602 - accuracy: 0.7769 - 92ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4611 - accuracy: 0.7745 - 92ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4604 - accuracy: 0.7758 - 105ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4595 - accuracy: 0.7765 - 101ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4601 - accuracy: 0.7770 - 95ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4591 - accuracy: 0.7800 - 143ms/epoch - 3ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4590 - accuracy: 0.7796 - 123ms/epoch - 3ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4588 - accuracy: 0.7772 - 134ms/epoch - 3ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4587 - accuracy: 0.7798 - 147ms/epoch - 3ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4582 - accuracy: 0.7789 - 124ms/epoch - 3ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4586 - accuracy: 0.7795 - 140ms/epoch - 3ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4571 - accuracy: 0.7819 - 142ms/epoch - 3ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7781 - 130ms/epoch - 3ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4575 - accuracy: 0.7786 - 124ms/epoch - 3ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7810 - 115ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4562 - accuracy: 0.7786 - 143ms/epoch - 3ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7781 - 127ms/epoch - 3ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4560 - accuracy: 0.7815 - 150ms/epoch - 3ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4572 - accuracy: 0.7789 - 170ms/epoch - 4ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4569 - accuracy: 0.7781 - 134ms/epoch - 3ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4550 - accuracy: 0.7860 - 130ms/epoch - 3ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4552 - accuracy: 0.7798 - 138ms/epoch - 3ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4550 - accuracy: 0.7815 - 129ms/epoch - 3ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4549 - accuracy: 0.7814 - 130ms/epoch - 3ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4552 - accuracy: 0.7834 - 164ms/epoch - 4ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4549 - accuracy: 0.7819 - 161ms/epoch - 4ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4544 - accuracy: 0.7821 - 96ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4540 - accuracy: 0.7803 - 86ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7819 - 80ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4536 - accuracy: 0.7810 - 96ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4532 - accuracy: 0.7840 - 83ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4531 - accuracy: 0.7822 - 92ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4529 - accuracy: 0.7819 - 85ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4533 - accuracy: 0.7833 - 82ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4525 - accuracy: 0.7829 - 90ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4525 - accuracy: 0.7848 - 93ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7848 - 102ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4527 - accuracy: 0.7812 - 91ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4519 - accuracy: 0.7814 - 94ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7833 - 85ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4517 - accuracy: 0.7821 - 87ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4514 - accuracy: 0.7834 - 95ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4513 - accuracy: 0.7841 - 101ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4524 - accuracy: 0.7843 - 94ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4499 - accuracy: 0.7841 - 97ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4502 - accuracy: 0.7883 - 88ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4497 - accuracy: 0.7858 - 104ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4504 - accuracy: 0.7834 - 86ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4502 - accuracy: 0.7867 - 89ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4496 - accuracy: 0.7833 - 94ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4490 - accuracy: 0.7858 - 89ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4488 - accuracy: 0.7850 - 91ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4485 - accuracy: 0.7848 - 87ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4486 - accuracy: 0.7857 - 89ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4482 - accuracy: 0.7853 - 87ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4484 - accuracy: 0.7838 - 96ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4486 - accuracy: 0.7843 - 98ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4478 - accuracy: 0.7865 - 114ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4472 - accuracy: 0.7871 - 102ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4477 - accuracy: 0.7896 - 91ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4470 - accuracy: 0.7867 - 98ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4470 - accuracy: 0.7836 - 104ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4463 - accuracy: 0.7876 - 105ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4465 - accuracy: 0.7855 - 107ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4470 - accuracy: 0.7884 - 109ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7871 - 99ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4463 - accuracy: 0.7857 - 100ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7891 - 96ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4455 - accuracy: 0.7891 - 91ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7871 - 90ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7905 - 93ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4458 - accuracy: 0.7869 - 93ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4462 - accuracy: 0.7869 - 88ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4451 - accuracy: 0.7886 - 105ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4447 - accuracy: 0.7858 - 93ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4444 - accuracy: 0.7879 - 94ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7884 - 110ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4444 - accuracy: 0.7909 - 103ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4435 - accuracy: 0.7867 - 89ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4435 - accuracy: 0.7912 - 85ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4435 - accuracy: 0.7884 - 87ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4441 - accuracy: 0.7907 - 93ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4431 - accuracy: 0.7893 - 101ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4433 - accuracy: 0.7909 - 95ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4429 - accuracy: 0.7872 - 96ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4426 - accuracy: 0.7909 - 108ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4430 - accuracy: 0.7893 - 106ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4415 - accuracy: 0.7921 - 98ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4418 - accuracy: 0.7903 - 99ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.5379 - accuracy: 0.7095 - 221ms/epoch - 18ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6435 - accuracy: 0.6492 - 1s/epoch - 28ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.5855 - accuracy: 0.7398 - 99ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.5392 - accuracy: 0.7463 - 92ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.5166 - accuracy: 0.7513 - 89ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.5055 - accuracy: 0.7569 - 86ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.4986 - accuracy: 0.7569 - 91ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.4949 - accuracy: 0.7594 - 102ms/epoch - 2ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.4928 - accuracy: 0.7594 - 105ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.4913 - accuracy: 0.7593 - 104ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.4899 - accuracy: 0.7563 - 99ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.4910 - accuracy: 0.7591 - 90ms/epoch - 2ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.4884 - accuracy: 0.7617 - 89ms/epoch - 2ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.4872 - accuracy: 0.7593 - 86ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.4864 - accuracy: 0.7613 - 93ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.4885 - accuracy: 0.7589 - 86ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.4856 - accuracy: 0.7624 - 84ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.4849 - accuracy: 0.7613 - 84ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.4843 - accuracy: 0.7600 - 94ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4835 - accuracy: 0.7617 - 88ms/epoch - 2ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4830 - accuracy: 0.7639 - 85ms/epoch - 2ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4830 - accuracy: 0.7591 - 87ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4827 - accuracy: 0.7615 - 92ms/epoch - 2ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4818 - accuracy: 0.7634 - 117ms/epoch - 3ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4817 - accuracy: 0.7620 - 141ms/epoch - 3ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4810 - accuracy: 0.7624 - 126ms/epoch - 3ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4807 - accuracy: 0.7601 - 134ms/epoch - 3ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4811 - accuracy: 0.7626 - 155ms/epoch - 3ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4808 - accuracy: 0.7608 - 133ms/epoch - 3ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4815 - accuracy: 0.7634 - 138ms/epoch - 3ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4790 - accuracy: 0.7610 - 135ms/epoch - 3ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4794 - accuracy: 0.7620 - 124ms/epoch - 3ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4786 - accuracy: 0.7634 - 143ms/epoch - 3ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4782 - accuracy: 0.7629 - 142ms/epoch - 3ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4778 - accuracy: 0.7646 - 162ms/epoch - 4ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4779 - accuracy: 0.7650 - 144ms/epoch - 3ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4780 - accuracy: 0.7632 - 148ms/epoch - 3ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4770 - accuracy: 0.7643 - 123ms/epoch - 3ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4770 - accuracy: 0.7638 - 115ms/epoch - 3ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4767 - accuracy: 0.7645 - 140ms/epoch - 3ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4760 - accuracy: 0.7620 - 129ms/epoch - 3ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4764 - accuracy: 0.7629 - 119ms/epoch - 3ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4757 - accuracy: 0.7655 - 151ms/epoch - 3ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4754 - accuracy: 0.7677 - 156ms/epoch - 3ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4762 - accuracy: 0.7648 - 97ms/epoch - 2ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4749 - accuracy: 0.7653 - 90ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4748 - accuracy: 0.7657 - 89ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4747 - accuracy: 0.7660 - 87ms/epoch - 2ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7667 - 99ms/epoch - 2ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4743 - accuracy: 0.7632 - 99ms/epoch - 2ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4740 - accuracy: 0.7664 - 95ms/epoch - 2ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4734 - accuracy: 0.7667 - 97ms/epoch - 2ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4742 - accuracy: 0.7665 - 105ms/epoch - 2ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4741 - accuracy: 0.7653 - 107ms/epoch - 2ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7667 - 106ms/epoch - 2ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7682 - 90ms/epoch - 2ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4731 - accuracy: 0.7684 - 96ms/epoch - 2ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7660 - 90ms/epoch - 2ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4729 - accuracy: 0.7700 - 105ms/epoch - 2ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4725 - accuracy: 0.7667 - 101ms/epoch - 2ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7705 - 105ms/epoch - 2ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4718 - accuracy: 0.7688 - 103ms/epoch - 2ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4716 - accuracy: 0.7689 - 93ms/epoch - 2ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4726 - accuracy: 0.7662 - 98ms/epoch - 2ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4706 - accuracy: 0.7700 - 98ms/epoch - 2ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4703 - accuracy: 0.7674 - 100ms/epoch - 2ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4700 - accuracy: 0.7719 - 89ms/epoch - 2ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4705 - accuracy: 0.7691 - 87ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4701 - accuracy: 0.7701 - 107ms/epoch - 2ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4704 - accuracy: 0.7689 - 92ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4699 - accuracy: 0.7696 - 90ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4692 - accuracy: 0.7710 - 92ms/epoch - 2ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4698 - accuracy: 0.7665 - 102ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4690 - accuracy: 0.7719 - 99ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4696 - accuracy: 0.7681 - 85ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4691 - accuracy: 0.7707 - 96ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4688 - accuracy: 0.7714 - 86ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4687 - accuracy: 0.7703 - 88ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4686 - accuracy: 0.7710 - 110ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4695 - accuracy: 0.7693 - 97ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4679 - accuracy: 0.7701 - 90ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4674 - accuracy: 0.7712 - 91ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4686 - accuracy: 0.7698 - 105ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4682 - accuracy: 0.7714 - 96ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4673 - accuracy: 0.7695 - 92ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4674 - accuracy: 0.7734 - 90ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4674 - accuracy: 0.7701 - 92ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4674 - accuracy: 0.7720 - 87ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4672 - accuracy: 0.7705 - 117ms/epoch - 3ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4669 - accuracy: 0.7715 - 92ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4669 - accuracy: 0.7729 - 94ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4666 - accuracy: 0.7712 - 105ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4661 - accuracy: 0.7712 - 93ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7720 - 100ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4664 - accuracy: 0.7708 - 98ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4657 - accuracy: 0.7736 - 87ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4656 - accuracy: 0.7731 - 96ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4661 - accuracy: 0.7710 - 92ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7719 - 89ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4653 - accuracy: 0.7717 - 104ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4651 - accuracy: 0.7720 - 100ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4657 - accuracy: 0.7714 - 109ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4653 - accuracy: 0.7734 - 106ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4652 - accuracy: 0.7691 - 100ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4649 - accuracy: 0.7719 - 95ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4648 - accuracy: 0.7734 - 96ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7724 - 82ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4645 - accuracy: 0.7708 - 93ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7715 - 117ms/epoch - 3ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4641 - accuracy: 0.7769 - 111ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4641 - accuracy: 0.7714 - 87ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4647 - accuracy: 0.7733 - 98ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4638 - accuracy: 0.7731 - 122ms/epoch - 3ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4639 - accuracy: 0.7720 - 103ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4641 - accuracy: 0.7734 - 88ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4631 - accuracy: 0.7739 - 89ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4640 - accuracy: 0.7727 - 95ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4644 - accuracy: 0.7719 - 98ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4629 - accuracy: 0.7736 - 104ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4626 - accuracy: 0.7731 - 92ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4631 - accuracy: 0.7729 - 99ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.4642 - accuracy: 0.7619 - 210ms/epoch - 17ms/step\n",
            "Epoch 1/120\n",
            "46/46 - 1s - loss: 0.6844 - accuracy: 0.5138 - 1s/epoch - 26ms/step\n",
            "Epoch 2/120\n",
            "46/46 - 0s - loss: 0.5742 - accuracy: 0.7447 - 96ms/epoch - 2ms/step\n",
            "Epoch 3/120\n",
            "46/46 - 0s - loss: 0.5056 - accuracy: 0.7609 - 90ms/epoch - 2ms/step\n",
            "Epoch 4/120\n",
            "46/46 - 0s - loss: 0.4801 - accuracy: 0.7660 - 96ms/epoch - 2ms/step\n",
            "Epoch 5/120\n",
            "46/46 - 0s - loss: 0.4701 - accuracy: 0.7759 - 93ms/epoch - 2ms/step\n",
            "Epoch 6/120\n",
            "46/46 - 0s - loss: 0.4658 - accuracy: 0.7783 - 97ms/epoch - 2ms/step\n",
            "Epoch 7/120\n",
            "46/46 - 0s - loss: 0.4646 - accuracy: 0.7790 - 103ms/epoch - 2ms/step\n",
            "Epoch 8/120\n",
            "46/46 - 0s - loss: 0.4625 - accuracy: 0.7761 - 89ms/epoch - 2ms/step\n",
            "Epoch 9/120\n",
            "46/46 - 0s - loss: 0.4621 - accuracy: 0.7795 - 107ms/epoch - 2ms/step\n",
            "Epoch 10/120\n",
            "46/46 - 0s - loss: 0.4609 - accuracy: 0.7776 - 100ms/epoch - 2ms/step\n",
            "Epoch 11/120\n",
            "46/46 - 0s - loss: 0.4604 - accuracy: 0.7800 - 109ms/epoch - 2ms/step\n",
            "Epoch 12/120\n",
            "46/46 - 0s - loss: 0.4596 - accuracy: 0.7764 - 96ms/epoch - 2ms/step\n",
            "Epoch 13/120\n",
            "46/46 - 0s - loss: 0.4594 - accuracy: 0.7792 - 94ms/epoch - 2ms/step\n",
            "Epoch 14/120\n",
            "46/46 - 0s - loss: 0.4596 - accuracy: 0.7792 - 100ms/epoch - 2ms/step\n",
            "Epoch 15/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7802 - 88ms/epoch - 2ms/step\n",
            "Epoch 16/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7802 - 98ms/epoch - 2ms/step\n",
            "Epoch 17/120\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7793 - 95ms/epoch - 2ms/step\n",
            "Epoch 18/120\n",
            "46/46 - 0s - loss: 0.4576 - accuracy: 0.7814 - 89ms/epoch - 2ms/step\n",
            "Epoch 19/120\n",
            "46/46 - 0s - loss: 0.4570 - accuracy: 0.7816 - 114ms/epoch - 2ms/step\n",
            "Epoch 20/120\n",
            "46/46 - 0s - loss: 0.4556 - accuracy: 0.7812 - 102ms/epoch - 2ms/step\n",
            "Epoch 21/120\n",
            "46/46 - 0s - loss: 0.4560 - accuracy: 0.7836 - 103ms/epoch - 2ms/step\n",
            "Epoch 22/120\n",
            "46/46 - 0s - loss: 0.4554 - accuracy: 0.7816 - 112ms/epoch - 2ms/step\n",
            "Epoch 23/120\n",
            "46/46 - 0s - loss: 0.4547 - accuracy: 0.7821 - 91ms/epoch - 2ms/step\n",
            "Epoch 24/120\n",
            "46/46 - 0s - loss: 0.4546 - accuracy: 0.7802 - 89ms/epoch - 2ms/step\n",
            "Epoch 25/120\n",
            "46/46 - 0s - loss: 0.4541 - accuracy: 0.7838 - 100ms/epoch - 2ms/step\n",
            "Epoch 26/120\n",
            "46/46 - 0s - loss: 0.4529 - accuracy: 0.7824 - 100ms/epoch - 2ms/step\n",
            "Epoch 27/120\n",
            "46/46 - 0s - loss: 0.4544 - accuracy: 0.7798 - 93ms/epoch - 2ms/step\n",
            "Epoch 28/120\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7845 - 85ms/epoch - 2ms/step\n",
            "Epoch 29/120\n",
            "46/46 - 0s - loss: 0.4525 - accuracy: 0.7828 - 104ms/epoch - 2ms/step\n",
            "Epoch 30/120\n",
            "46/46 - 0s - loss: 0.4530 - accuracy: 0.7830 - 97ms/epoch - 2ms/step\n",
            "Epoch 31/120\n",
            "46/46 - 0s - loss: 0.4522 - accuracy: 0.7830 - 97ms/epoch - 2ms/step\n",
            "Epoch 32/120\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7819 - 95ms/epoch - 2ms/step\n",
            "Epoch 33/120\n",
            "46/46 - 0s - loss: 0.4510 - accuracy: 0.7857 - 86ms/epoch - 2ms/step\n",
            "Epoch 34/120\n",
            "46/46 - 0s - loss: 0.4517 - accuracy: 0.7833 - 88ms/epoch - 2ms/step\n",
            "Epoch 35/120\n",
            "46/46 - 0s - loss: 0.4506 - accuracy: 0.7843 - 93ms/epoch - 2ms/step\n",
            "Epoch 36/120\n",
            "46/46 - 0s - loss: 0.4500 - accuracy: 0.7849 - 93ms/epoch - 2ms/step\n",
            "Epoch 37/120\n",
            "46/46 - 0s - loss: 0.4505 - accuracy: 0.7850 - 88ms/epoch - 2ms/step\n",
            "Epoch 38/120\n",
            "46/46 - 0s - loss: 0.4504 - accuracy: 0.7861 - 108ms/epoch - 2ms/step\n",
            "Epoch 39/120\n",
            "46/46 - 0s - loss: 0.4493 - accuracy: 0.7861 - 97ms/epoch - 2ms/step\n",
            "Epoch 40/120\n",
            "46/46 - 0s - loss: 0.4493 - accuracy: 0.7892 - 102ms/epoch - 2ms/step\n",
            "Epoch 41/120\n",
            "46/46 - 0s - loss: 0.4494 - accuracy: 0.7876 - 91ms/epoch - 2ms/step\n",
            "Epoch 42/120\n",
            "46/46 - 0s - loss: 0.4492 - accuracy: 0.7866 - 85ms/epoch - 2ms/step\n",
            "Epoch 43/120\n",
            "46/46 - 0s - loss: 0.4483 - accuracy: 0.7861 - 87ms/epoch - 2ms/step\n",
            "Epoch 44/120\n",
            "46/46 - 0s - loss: 0.4486 - accuracy: 0.7871 - 103ms/epoch - 2ms/step\n",
            "Epoch 45/120\n",
            "46/46 - 0s - loss: 0.4479 - accuracy: 0.7876 - 92ms/epoch - 2ms/step\n",
            "Epoch 46/120\n",
            "46/46 - 0s - loss: 0.4478 - accuracy: 0.7850 - 87ms/epoch - 2ms/step\n",
            "Epoch 47/120\n",
            "46/46 - 0s - loss: 0.4485 - accuracy: 0.7881 - 169ms/epoch - 4ms/step\n",
            "Epoch 48/120\n",
            "46/46 - 0s - loss: 0.4478 - accuracy: 0.7878 - 136ms/epoch - 3ms/step\n",
            "Epoch 49/120\n",
            "46/46 - 0s - loss: 0.4489 - accuracy: 0.7859 - 151ms/epoch - 3ms/step\n",
            "Epoch 50/120\n",
            "46/46 - 0s - loss: 0.4491 - accuracy: 0.7845 - 151ms/epoch - 3ms/step\n",
            "Epoch 51/120\n",
            "46/46 - 0s - loss: 0.4469 - accuracy: 0.7886 - 132ms/epoch - 3ms/step\n",
            "Epoch 52/120\n",
            "46/46 - 0s - loss: 0.4471 - accuracy: 0.7867 - 127ms/epoch - 3ms/step\n",
            "Epoch 53/120\n",
            "46/46 - 0s - loss: 0.4472 - accuracy: 0.7864 - 157ms/epoch - 3ms/step\n",
            "Epoch 54/120\n",
            "46/46 - 0s - loss: 0.4467 - accuracy: 0.7886 - 142ms/epoch - 3ms/step\n",
            "Epoch 55/120\n",
            "46/46 - 0s - loss: 0.4457 - accuracy: 0.7876 - 159ms/epoch - 3ms/step\n",
            "Epoch 56/120\n",
            "46/46 - 0s - loss: 0.4466 - accuracy: 0.7878 - 166ms/epoch - 4ms/step\n",
            "Epoch 57/120\n",
            "46/46 - 0s - loss: 0.4470 - accuracy: 0.7866 - 159ms/epoch - 3ms/step\n",
            "Epoch 58/120\n",
            "46/46 - 0s - loss: 0.4459 - accuracy: 0.7899 - 134ms/epoch - 3ms/step\n",
            "Epoch 59/120\n",
            "46/46 - 0s - loss: 0.4455 - accuracy: 0.7886 - 161ms/epoch - 4ms/step\n",
            "Epoch 60/120\n",
            "46/46 - 0s - loss: 0.4454 - accuracy: 0.7880 - 149ms/epoch - 3ms/step\n",
            "Epoch 61/120\n",
            "46/46 - 0s - loss: 0.4453 - accuracy: 0.7900 - 154ms/epoch - 3ms/step\n",
            "Epoch 62/120\n",
            "46/46 - 0s - loss: 0.4451 - accuracy: 0.7892 - 153ms/epoch - 3ms/step\n",
            "Epoch 63/120\n",
            "46/46 - 0s - loss: 0.4458 - accuracy: 0.7861 - 131ms/epoch - 3ms/step\n",
            "Epoch 64/120\n",
            "46/46 - 0s - loss: 0.4451 - accuracy: 0.7888 - 134ms/epoch - 3ms/step\n",
            "Epoch 65/120\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7909 - 125ms/epoch - 3ms/step\n",
            "Epoch 66/120\n",
            "46/46 - 0s - loss: 0.4447 - accuracy: 0.7862 - 124ms/epoch - 3ms/step\n",
            "Epoch 67/120\n",
            "46/46 - 0s - loss: 0.4449 - accuracy: 0.7895 - 96ms/epoch - 2ms/step\n",
            "Epoch 68/120\n",
            "46/46 - 0s - loss: 0.4441 - accuracy: 0.7888 - 116ms/epoch - 3ms/step\n",
            "Epoch 69/120\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7874 - 99ms/epoch - 2ms/step\n",
            "Epoch 70/120\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7904 - 87ms/epoch - 2ms/step\n",
            "Epoch 71/120\n",
            "46/46 - 0s - loss: 0.4448 - accuracy: 0.7892 - 117ms/epoch - 3ms/step\n",
            "Epoch 72/120\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7892 - 85ms/epoch - 2ms/step\n",
            "Epoch 73/120\n",
            "46/46 - 0s - loss: 0.4445 - accuracy: 0.7878 - 96ms/epoch - 2ms/step\n",
            "Epoch 74/120\n",
            "46/46 - 0s - loss: 0.4440 - accuracy: 0.7874 - 92ms/epoch - 2ms/step\n",
            "Epoch 75/120\n",
            "46/46 - 0s - loss: 0.4443 - accuracy: 0.7886 - 90ms/epoch - 2ms/step\n",
            "Epoch 76/120\n",
            "46/46 - 0s - loss: 0.4435 - accuracy: 0.7914 - 100ms/epoch - 2ms/step\n",
            "Epoch 77/120\n",
            "46/46 - 0s - loss: 0.4434 - accuracy: 0.7899 - 87ms/epoch - 2ms/step\n",
            "Epoch 78/120\n",
            "46/46 - 0s - loss: 0.4451 - accuracy: 0.7876 - 84ms/epoch - 2ms/step\n",
            "Epoch 79/120\n",
            "46/46 - 0s - loss: 0.4437 - accuracy: 0.7864 - 90ms/epoch - 2ms/step\n",
            "Epoch 80/120\n",
            "46/46 - 0s - loss: 0.4437 - accuracy: 0.7893 - 86ms/epoch - 2ms/step\n",
            "Epoch 81/120\n",
            "46/46 - 0s - loss: 0.4429 - accuracy: 0.7895 - 92ms/epoch - 2ms/step\n",
            "Epoch 82/120\n",
            "46/46 - 0s - loss: 0.4427 - accuracy: 0.7883 - 83ms/epoch - 2ms/step\n",
            "Epoch 83/120\n",
            "46/46 - 0s - loss: 0.4430 - accuracy: 0.7893 - 95ms/epoch - 2ms/step\n",
            "Epoch 84/120\n",
            "46/46 - 0s - loss: 0.4424 - accuracy: 0.7876 - 86ms/epoch - 2ms/step\n",
            "Epoch 85/120\n",
            "46/46 - 0s - loss: 0.4420 - accuracy: 0.7895 - 87ms/epoch - 2ms/step\n",
            "Epoch 86/120\n",
            "46/46 - 0s - loss: 0.4424 - accuracy: 0.7897 - 87ms/epoch - 2ms/step\n",
            "Epoch 87/120\n",
            "46/46 - 0s - loss: 0.4424 - accuracy: 0.7885 - 97ms/epoch - 2ms/step\n",
            "Epoch 88/120\n",
            "46/46 - 0s - loss: 0.4423 - accuracy: 0.7895 - 93ms/epoch - 2ms/step\n",
            "Epoch 89/120\n",
            "46/46 - 0s - loss: 0.4417 - accuracy: 0.7899 - 91ms/epoch - 2ms/step\n",
            "Epoch 90/120\n",
            "46/46 - 0s - loss: 0.4420 - accuracy: 0.7895 - 100ms/epoch - 2ms/step\n",
            "Epoch 91/120\n",
            "46/46 - 0s - loss: 0.4419 - accuracy: 0.7890 - 93ms/epoch - 2ms/step\n",
            "Epoch 92/120\n",
            "46/46 - 0s - loss: 0.4429 - accuracy: 0.7866 - 98ms/epoch - 2ms/step\n",
            "Epoch 93/120\n",
            "46/46 - 0s - loss: 0.4421 - accuracy: 0.7878 - 93ms/epoch - 2ms/step\n",
            "Epoch 94/120\n",
            "46/46 - 0s - loss: 0.4429 - accuracy: 0.7850 - 85ms/epoch - 2ms/step\n",
            "Epoch 95/120\n",
            "46/46 - 0s - loss: 0.4414 - accuracy: 0.7893 - 84ms/epoch - 2ms/step\n",
            "Epoch 96/120\n",
            "46/46 - 0s - loss: 0.4430 - accuracy: 0.7878 - 85ms/epoch - 2ms/step\n",
            "Epoch 97/120\n",
            "46/46 - 0s - loss: 0.4420 - accuracy: 0.7867 - 84ms/epoch - 2ms/step\n",
            "Epoch 98/120\n",
            "46/46 - 0s - loss: 0.4414 - accuracy: 0.7892 - 96ms/epoch - 2ms/step\n",
            "Epoch 99/120\n",
            "46/46 - 0s - loss: 0.4412 - accuracy: 0.7912 - 90ms/epoch - 2ms/step\n",
            "Epoch 100/120\n",
            "46/46 - 0s - loss: 0.4413 - accuracy: 0.7892 - 92ms/epoch - 2ms/step\n",
            "Epoch 101/120\n",
            "46/46 - 0s - loss: 0.4410 - accuracy: 0.7876 - 87ms/epoch - 2ms/step\n",
            "Epoch 102/120\n",
            "46/46 - 0s - loss: 0.4409 - accuracy: 0.7905 - 89ms/epoch - 2ms/step\n",
            "Epoch 103/120\n",
            "46/46 - 0s - loss: 0.4415 - accuracy: 0.7890 - 96ms/epoch - 2ms/step\n",
            "Epoch 104/120\n",
            "46/46 - 0s - loss: 0.4407 - accuracy: 0.7878 - 97ms/epoch - 2ms/step\n",
            "Epoch 105/120\n",
            "46/46 - 0s - loss: 0.4401 - accuracy: 0.7900 - 90ms/epoch - 2ms/step\n",
            "Epoch 106/120\n",
            "46/46 - 0s - loss: 0.4401 - accuracy: 0.7873 - 88ms/epoch - 2ms/step\n",
            "Epoch 107/120\n",
            "46/46 - 0s - loss: 0.4396 - accuracy: 0.7893 - 106ms/epoch - 2ms/step\n",
            "Epoch 108/120\n",
            "46/46 - 0s - loss: 0.4397 - accuracy: 0.7895 - 92ms/epoch - 2ms/step\n",
            "Epoch 109/120\n",
            "46/46 - 0s - loss: 0.4397 - accuracy: 0.7876 - 91ms/epoch - 2ms/step\n",
            "Epoch 110/120\n",
            "46/46 - 0s - loss: 0.4394 - accuracy: 0.7892 - 109ms/epoch - 2ms/step\n",
            "Epoch 111/120\n",
            "46/46 - 0s - loss: 0.4393 - accuracy: 0.7914 - 97ms/epoch - 2ms/step\n",
            "Epoch 112/120\n",
            "46/46 - 0s - loss: 0.4390 - accuracy: 0.7900 - 93ms/epoch - 2ms/step\n",
            "Epoch 113/120\n",
            "46/46 - 0s - loss: 0.4391 - accuracy: 0.7871 - 106ms/epoch - 2ms/step\n",
            "Epoch 114/120\n",
            "46/46 - 0s - loss: 0.4391 - accuracy: 0.7900 - 89ms/epoch - 2ms/step\n",
            "Epoch 115/120\n",
            "46/46 - 0s - loss: 0.4395 - accuracy: 0.7859 - 89ms/epoch - 2ms/step\n",
            "Epoch 116/120\n",
            "46/46 - 0s - loss: 0.4390 - accuracy: 0.7881 - 90ms/epoch - 2ms/step\n",
            "Epoch 117/120\n",
            "46/46 - 0s - loss: 0.4393 - accuracy: 0.7885 - 95ms/epoch - 2ms/step\n",
            "Epoch 118/120\n",
            "46/46 - 0s - loss: 0.4393 - accuracy: 0.7876 - 90ms/epoch - 2ms/step\n",
            "Epoch 119/120\n",
            "46/46 - 0s - loss: 0.4387 - accuracy: 0.7876 - 85ms/epoch - 2ms/step\n",
            "Epoch 120/120\n",
            "46/46 - 0s - loss: 0.4377 - accuracy: 0.7880 - 89ms/epoch - 2ms/step\n",
            "12/12 - 0s - loss: 0.6535 - accuracy: 0.6809 - 215ms/epoch - 18ms/step\n",
            "Epoch 1/90\n",
            "227/227 - 2s - loss: 0.5886 - accuracy: 0.7015 - 2s/epoch - 7ms/step\n",
            "Epoch 2/90\n",
            "227/227 - 0s - loss: 0.4989 - accuracy: 0.7590 - 406ms/epoch - 2ms/step\n",
            "Epoch 3/90\n",
            "227/227 - 0s - loss: 0.4883 - accuracy: 0.7621 - 373ms/epoch - 2ms/step\n",
            "Epoch 4/90\n",
            "227/227 - 0s - loss: 0.4833 - accuracy: 0.7644 - 403ms/epoch - 2ms/step\n",
            "Epoch 5/90\n",
            "227/227 - 0s - loss: 0.4802 - accuracy: 0.7620 - 387ms/epoch - 2ms/step\n",
            "Epoch 6/90\n",
            "227/227 - 0s - loss: 0.4772 - accuracy: 0.7681 - 415ms/epoch - 2ms/step\n",
            "Epoch 7/90\n",
            "227/227 - 0s - loss: 0.4753 - accuracy: 0.7650 - 404ms/epoch - 2ms/step\n",
            "Epoch 8/90\n",
            "227/227 - 0s - loss: 0.4745 - accuracy: 0.7666 - 439ms/epoch - 2ms/step\n",
            "Epoch 9/90\n",
            "227/227 - 1s - loss: 0.4728 - accuracy: 0.7659 - 645ms/epoch - 3ms/step\n",
            "Epoch 10/90\n",
            "227/227 - 1s - loss: 0.4727 - accuracy: 0.7685 - 686ms/epoch - 3ms/step\n",
            "Epoch 11/90\n",
            "227/227 - 1s - loss: 0.4709 - accuracy: 0.7675 - 671ms/epoch - 3ms/step\n",
            "Epoch 12/90\n",
            "227/227 - 1s - loss: 0.4702 - accuracy: 0.7659 - 576ms/epoch - 3ms/step\n",
            "Epoch 13/90\n",
            "227/227 - 0s - loss: 0.4713 - accuracy: 0.7668 - 379ms/epoch - 2ms/step\n",
            "Epoch 14/90\n",
            "227/227 - 0s - loss: 0.4691 - accuracy: 0.7684 - 409ms/epoch - 2ms/step\n",
            "Epoch 15/90\n",
            "227/227 - 0s - loss: 0.4685 - accuracy: 0.7696 - 380ms/epoch - 2ms/step\n",
            "Epoch 16/90\n",
            "227/227 - 0s - loss: 0.4691 - accuracy: 0.7689 - 388ms/epoch - 2ms/step\n",
            "Epoch 17/90\n",
            "227/227 - 0s - loss: 0.4673 - accuracy: 0.7682 - 369ms/epoch - 2ms/step\n",
            "Epoch 18/90\n",
            "227/227 - 0s - loss: 0.4663 - accuracy: 0.7725 - 388ms/epoch - 2ms/step\n",
            "Epoch 19/90\n",
            "227/227 - 0s - loss: 0.4662 - accuracy: 0.7721 - 409ms/epoch - 2ms/step\n",
            "Epoch 20/90\n",
            "227/227 - 0s - loss: 0.4668 - accuracy: 0.7706 - 426ms/epoch - 2ms/step\n",
            "Epoch 21/90\n",
            "227/227 - 0s - loss: 0.4655 - accuracy: 0.7724 - 440ms/epoch - 2ms/step\n",
            "Epoch 22/90\n",
            "227/227 - 0s - loss: 0.4654 - accuracy: 0.7699 - 387ms/epoch - 2ms/step\n",
            "Epoch 23/90\n",
            "227/227 - 0s - loss: 0.4636 - accuracy: 0.7754 - 397ms/epoch - 2ms/step\n",
            "Epoch 24/90\n",
            "227/227 - 0s - loss: 0.4633 - accuracy: 0.7711 - 407ms/epoch - 2ms/step\n",
            "Epoch 25/90\n",
            "227/227 - 0s - loss: 0.4637 - accuracy: 0.7721 - 376ms/epoch - 2ms/step\n",
            "Epoch 26/90\n",
            "227/227 - 0s - loss: 0.4632 - accuracy: 0.7711 - 407ms/epoch - 2ms/step\n",
            "Epoch 27/90\n",
            "227/227 - 0s - loss: 0.4616 - accuracy: 0.7733 - 370ms/epoch - 2ms/step\n",
            "Epoch 28/90\n",
            "227/227 - 0s - loss: 0.4626 - accuracy: 0.7732 - 387ms/epoch - 2ms/step\n",
            "Epoch 29/90\n",
            "227/227 - 0s - loss: 0.4611 - accuracy: 0.7746 - 402ms/epoch - 2ms/step\n",
            "Epoch 30/90\n",
            "227/227 - 0s - loss: 0.4611 - accuracy: 0.7703 - 369ms/epoch - 2ms/step\n",
            "Epoch 31/90\n",
            "227/227 - 0s - loss: 0.4609 - accuracy: 0.7755 - 410ms/epoch - 2ms/step\n",
            "Epoch 32/90\n",
            "227/227 - 0s - loss: 0.4597 - accuracy: 0.7765 - 389ms/epoch - 2ms/step\n",
            "Epoch 33/90\n",
            "227/227 - 0s - loss: 0.4605 - accuracy: 0.7719 - 404ms/epoch - 2ms/step\n",
            "Epoch 34/90\n",
            "227/227 - 0s - loss: 0.4595 - accuracy: 0.7742 - 428ms/epoch - 2ms/step\n",
            "Epoch 35/90\n",
            "227/227 - 0s - loss: 0.4591 - accuracy: 0.7753 - 377ms/epoch - 2ms/step\n",
            "Epoch 36/90\n",
            "227/227 - 0s - loss: 0.4587 - accuracy: 0.7746 - 401ms/epoch - 2ms/step\n",
            "Epoch 37/90\n",
            "227/227 - 0s - loss: 0.4579 - accuracy: 0.7748 - 485ms/epoch - 2ms/step\n",
            "Epoch 38/90\n",
            "227/227 - 1s - loss: 0.4589 - accuracy: 0.7766 - 660ms/epoch - 3ms/step\n",
            "Epoch 39/90\n",
            "227/227 - 1s - loss: 0.4574 - accuracy: 0.7760 - 594ms/epoch - 3ms/step\n",
            "Epoch 40/90\n",
            "227/227 - 1s - loss: 0.4571 - accuracy: 0.7762 - 557ms/epoch - 2ms/step\n",
            "Epoch 41/90\n",
            "227/227 - 1s - loss: 0.4572 - accuracy: 0.7740 - 574ms/epoch - 3ms/step\n",
            "Epoch 42/90\n",
            "227/227 - 0s - loss: 0.4564 - accuracy: 0.7766 - 364ms/epoch - 2ms/step\n",
            "Epoch 43/90\n",
            "227/227 - 0s - loss: 0.4561 - accuracy: 0.7773 - 365ms/epoch - 2ms/step\n",
            "Epoch 44/90\n",
            "227/227 - 0s - loss: 0.4556 - accuracy: 0.7789 - 432ms/epoch - 2ms/step\n",
            "Epoch 45/90\n",
            "227/227 - 0s - loss: 0.4556 - accuracy: 0.7762 - 370ms/epoch - 2ms/step\n",
            "Epoch 46/90\n",
            "227/227 - 0s - loss: 0.4546 - accuracy: 0.7793 - 388ms/epoch - 2ms/step\n",
            "Epoch 47/90\n",
            "227/227 - 0s - loss: 0.4547 - accuracy: 0.7733 - 383ms/epoch - 2ms/step\n",
            "Epoch 48/90\n",
            "227/227 - 0s - loss: 0.4544 - accuracy: 0.7755 - 367ms/epoch - 2ms/step\n",
            "Epoch 49/90\n",
            "227/227 - 0s - loss: 0.4538 - accuracy: 0.7762 - 392ms/epoch - 2ms/step\n",
            "Epoch 50/90\n",
            "227/227 - 0s - loss: 0.4534 - accuracy: 0.7764 - 366ms/epoch - 2ms/step\n",
            "Epoch 51/90\n",
            "227/227 - 0s - loss: 0.4527 - accuracy: 0.7773 - 356ms/epoch - 2ms/step\n",
            "Epoch 52/90\n",
            "227/227 - 0s - loss: 0.4528 - accuracy: 0.7784 - 430ms/epoch - 2ms/step\n",
            "Epoch 53/90\n",
            "227/227 - 0s - loss: 0.4526 - accuracy: 0.7776 - 363ms/epoch - 2ms/step\n",
            "Epoch 54/90\n",
            "227/227 - 0s - loss: 0.4520 - accuracy: 0.7815 - 394ms/epoch - 2ms/step\n",
            "Epoch 55/90\n",
            "227/227 - 0s - loss: 0.4517 - accuracy: 0.7791 - 410ms/epoch - 2ms/step\n",
            "Epoch 56/90\n",
            "227/227 - 0s - loss: 0.4510 - accuracy: 0.7793 - 368ms/epoch - 2ms/step\n",
            "Epoch 57/90\n",
            "227/227 - 0s - loss: 0.4509 - accuracy: 0.7800 - 397ms/epoch - 2ms/step\n",
            "Epoch 58/90\n",
            "227/227 - 0s - loss: 0.4511 - accuracy: 0.7801 - 379ms/epoch - 2ms/step\n",
            "Epoch 59/90\n",
            "227/227 - 0s - loss: 0.4507 - accuracy: 0.7776 - 399ms/epoch - 2ms/step\n",
            "Epoch 60/90\n",
            "227/227 - 0s - loss: 0.4506 - accuracy: 0.7784 - 387ms/epoch - 2ms/step\n",
            "Epoch 61/90\n",
            "227/227 - 0s - loss: 0.4494 - accuracy: 0.7805 - 374ms/epoch - 2ms/step\n",
            "Epoch 62/90\n",
            "227/227 - 0s - loss: 0.4489 - accuracy: 0.7837 - 419ms/epoch - 2ms/step\n",
            "Epoch 63/90\n",
            "227/227 - 0s - loss: 0.4482 - accuracy: 0.7804 - 373ms/epoch - 2ms/step\n",
            "Epoch 64/90\n",
            "227/227 - 0s - loss: 0.4484 - accuracy: 0.7830 - 381ms/epoch - 2ms/step\n",
            "Epoch 65/90\n",
            "227/227 - 0s - loss: 0.4476 - accuracy: 0.7805 - 447ms/epoch - 2ms/step\n",
            "Epoch 66/90\n",
            "227/227 - 0s - loss: 0.4476 - accuracy: 0.7830 - 387ms/epoch - 2ms/step\n",
            "Epoch 67/90\n",
            "227/227 - 1s - loss: 0.4469 - accuracy: 0.7841 - 538ms/epoch - 2ms/step\n",
            "Epoch 68/90\n",
            "227/227 - 1s - loss: 0.4474 - accuracy: 0.7824 - 569ms/epoch - 3ms/step\n",
            "Epoch 69/90\n",
            "227/227 - 1s - loss: 0.4463 - accuracy: 0.7852 - 566ms/epoch - 2ms/step\n",
            "Epoch 70/90\n",
            "227/227 - 1s - loss: 0.4457 - accuracy: 0.7840 - 597ms/epoch - 3ms/step\n",
            "Epoch 71/90\n",
            "227/227 - 1s - loss: 0.4463 - accuracy: 0.7818 - 557ms/epoch - 2ms/step\n",
            "Epoch 72/90\n",
            "227/227 - 0s - loss: 0.4457 - accuracy: 0.7830 - 399ms/epoch - 2ms/step\n",
            "Epoch 73/90\n",
            "227/227 - 0s - loss: 0.4458 - accuracy: 0.7864 - 409ms/epoch - 2ms/step\n",
            "Epoch 74/90\n",
            "227/227 - 0s - loss: 0.4449 - accuracy: 0.7860 - 388ms/epoch - 2ms/step\n",
            "Epoch 75/90\n",
            "227/227 - 0s - loss: 0.4450 - accuracy: 0.7853 - 409ms/epoch - 2ms/step\n",
            "Epoch 76/90\n",
            "227/227 - 0s - loss: 0.4455 - accuracy: 0.7820 - 381ms/epoch - 2ms/step\n",
            "Epoch 77/90\n",
            "227/227 - 0s - loss: 0.4452 - accuracy: 0.7841 - 411ms/epoch - 2ms/step\n",
            "Epoch 78/90\n",
            "227/227 - 0s - loss: 0.4448 - accuracy: 0.7852 - 399ms/epoch - 2ms/step\n",
            "Epoch 79/90\n",
            "227/227 - 0s - loss: 0.4436 - accuracy: 0.7873 - 377ms/epoch - 2ms/step\n",
            "Epoch 80/90\n",
            "227/227 - 0s - loss: 0.4440 - accuracy: 0.7851 - 396ms/epoch - 2ms/step\n",
            "Epoch 81/90\n",
            "227/227 - 0s - loss: 0.4434 - accuracy: 0.7860 - 395ms/epoch - 2ms/step\n",
            "Epoch 82/90\n",
            "227/227 - 0s - loss: 0.4430 - accuracy: 0.7869 - 384ms/epoch - 2ms/step\n",
            "Epoch 83/90\n",
            "227/227 - 0s - loss: 0.4431 - accuracy: 0.7877 - 398ms/epoch - 2ms/step\n",
            "Epoch 84/90\n",
            "227/227 - 0s - loss: 0.4422 - accuracy: 0.7875 - 367ms/epoch - 2ms/step\n",
            "Epoch 85/90\n",
            "227/227 - 0s - loss: 0.4432 - accuracy: 0.7853 - 373ms/epoch - 2ms/step\n",
            "Epoch 86/90\n",
            "227/227 - 0s - loss: 0.4424 - accuracy: 0.7867 - 411ms/epoch - 2ms/step\n",
            "Epoch 87/90\n",
            "227/227 - 0s - loss: 0.4420 - accuracy: 0.7885 - 382ms/epoch - 2ms/step\n",
            "Epoch 88/90\n",
            "227/227 - 0s - loss: 0.4417 - accuracy: 0.7844 - 382ms/epoch - 2ms/step\n",
            "Epoch 89/90\n",
            "227/227 - 0s - loss: 0.4422 - accuracy: 0.7834 - 394ms/epoch - 2ms/step\n",
            "Epoch 90/90\n",
            "227/227 - 0s - loss: 0.4412 - accuracy: 0.7871 - 396ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# define os parâmetros do grid search\n",
        "optimizer = ['SGD', 'Adam']\n",
        "batch_size = [32, 64, 128]\n",
        "epochs = [80, 90, 100, 110, 120]\n",
        "param_grid = dict(optimizer=optimizer, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, n_jobs=None, cv=5)\n",
        "grid_result = grid.fit(x_train_res, y_train_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d01f18",
      "metadata": {
        "id": "c1d01f18",
        "outputId": "3842264e-e937-4048-c53c-1caf14d004c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.730528 using {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'}\n",
            "0.720721 (0.050409) with: {'batch_size': 32, 'epochs': 80, 'optimizer': 'SGD'}\n",
            "0.716858 (0.044401) with: {'batch_size': 32, 'epochs': 80, 'optimizer': 'Adam'}\n",
            "0.705811 (0.056954) with: {'batch_size': 32, 'epochs': 90, 'optimizer': 'SGD'}\n",
            "0.710919 (0.054359) with: {'batch_size': 32, 'epochs': 90, 'optimizer': 'Adam'}\n",
            "0.721554 (0.042070) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'SGD'}\n",
            "0.730528 (0.036195) with: {'batch_size': 32, 'epochs': 100, 'optimizer': 'Adam'}\n",
            "0.725010 (0.026198) with: {'batch_size': 32, 'epochs': 110, 'optimizer': 'SGD'}\n",
            "0.719898 (0.038894) with: {'batch_size': 32, 'epochs': 110, 'optimizer': 'Adam'}\n",
            "0.718109 (0.028253) with: {'batch_size': 32, 'epochs': 120, 'optimizer': 'SGD'}\n",
            "0.713404 (0.057759) with: {'batch_size': 32, 'epochs': 120, 'optimizer': 'Adam'}\n",
            "0.719757 (0.045733) with: {'batch_size': 64, 'epochs': 80, 'optimizer': 'SGD'}\n",
            "0.727356 (0.023932) with: {'batch_size': 64, 'epochs': 80, 'optimizer': 'Adam'}\n",
            "0.722795 (0.043210) with: {'batch_size': 64, 'epochs': 90, 'optimizer': 'SGD'}\n",
            "0.722522 (0.030010) with: {'batch_size': 64, 'epochs': 90, 'optimizer': 'Adam'}\n",
            "0.722797 (0.033222) with: {'batch_size': 64, 'epochs': 100, 'optimizer': 'SGD'}\n",
            "0.728598 (0.025302) with: {'batch_size': 64, 'epochs': 100, 'optimizer': 'Adam'}\n",
            "0.723209 (0.043324) with: {'batch_size': 64, 'epochs': 110, 'optimizer': 'SGD'}\n",
            "0.724457 (0.026133) with: {'batch_size': 64, 'epochs': 110, 'optimizer': 'Adam'}\n",
            "0.725557 (0.035214) with: {'batch_size': 64, 'epochs': 120, 'optimizer': 'SGD'}\n",
            "0.722244 (0.036958) with: {'batch_size': 64, 'epochs': 120, 'optimizer': 'Adam'}\n",
            "0.729424 (0.031489) with: {'batch_size': 128, 'epochs': 80, 'optimizer': 'SGD'}\n",
            "0.713274 (0.035017) with: {'batch_size': 128, 'epochs': 80, 'optimizer': 'Adam'}\n",
            "0.726111 (0.033391) with: {'batch_size': 128, 'epochs': 90, 'optimizer': 'SGD'}\n",
            "0.712718 (0.041518) with: {'batch_size': 128, 'epochs': 90, 'optimizer': 'Adam'}\n",
            "0.723763 (0.036966) with: {'batch_size': 128, 'epochs': 100, 'optimizer': 'SGD'}\n",
            "0.723903 (0.028749) with: {'batch_size': 128, 'epochs': 100, 'optimizer': 'Adam'}\n",
            "0.724315 (0.033728) with: {'batch_size': 128, 'epochs': 110, 'optimizer': 'SGD'}\n",
            "0.723068 (0.054013) with: {'batch_size': 128, 'epochs': 110, 'optimizer': 'Adam'}\n",
            "0.725695 (0.038787) with: {'batch_size': 128, 'epochs': 120, 'optimizer': 'SGD'}\n",
            "0.727216 (0.034861) with: {'batch_size': 128, 'epochs': 120, 'optimizer': 'Adam'}\n"
          ]
        }
      ],
      "source": [
        "# exibe resultados do grid search\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O grid search é uma \"mão na roda\" no momento de determinar hiperparâmetros da rede. Basta criar um modelo e dizer quais parâmetros você deseja que ele teste. Ele cria um ranking com os melhores resultados obtidos e quais parâmetros foram utilizados para tais resultados."
      ],
      "metadata": {
        "id": "M9_Kr8sdGfnJ"
      },
      "id": "M9_Kr8sdGfnJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - Treinando o modelo"
      ],
      "metadata": {
        "id": "isOKq_AizFAq"
      },
      "id": "isOKq_AizFAq"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3d864b70",
      "metadata": {
        "id": "3d864b70"
      },
      "outputs": [],
      "source": [
        "# Criando modelo com novos hiperparâmetros\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(16, input_dim=20, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d063a404",
      "metadata": {
        "id": "d063a404"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "29f43596",
      "metadata": {
        "id": "29f43596",
        "outputId": "5d238a00-7245-4fe4-b38e-c559349f58cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "227/227 [==============================] - 3s 6ms/step - loss: 0.5475 - binary_accuracy: 0.7268 - val_loss: 0.4950 - val_binary_accuracy: 0.7483\n",
            "Epoch 2/100\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.4921 - binary_accuracy: 0.7576 - val_loss: 0.4770 - val_binary_accuracy: 0.7616\n",
            "Epoch 3/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4844 - binary_accuracy: 0.7628 - val_loss: 0.5133 - val_binary_accuracy: 0.7465\n",
            "Epoch 4/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4817 - binary_accuracy: 0.7657 - val_loss: 0.4792 - val_binary_accuracy: 0.7720\n",
            "Epoch 5/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4811 - binary_accuracy: 0.7637 - val_loss: 0.4933 - val_binary_accuracy: 0.7606\n",
            "Epoch 6/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4791 - binary_accuracy: 0.7648 - val_loss: 0.5171 - val_binary_accuracy: 0.7540\n",
            "Epoch 7/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4789 - binary_accuracy: 0.7656 - val_loss: 0.5006 - val_binary_accuracy: 0.7588\n",
            "Epoch 8/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4764 - binary_accuracy: 0.7657 - val_loss: 0.4822 - val_binary_accuracy: 0.7682\n",
            "Epoch 9/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4755 - binary_accuracy: 0.7675 - val_loss: 0.4741 - val_binary_accuracy: 0.7720\n",
            "Epoch 10/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4747 - binary_accuracy: 0.7686 - val_loss: 0.5119 - val_binary_accuracy: 0.7588\n",
            "Epoch 11/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4743 - binary_accuracy: 0.7668 - val_loss: 0.4816 - val_binary_accuracy: 0.7654\n",
            "Epoch 12/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4750 - binary_accuracy: 0.7674 - val_loss: 0.4865 - val_binary_accuracy: 0.7682\n",
            "Epoch 13/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4725 - binary_accuracy: 0.7697 - val_loss: 0.4973 - val_binary_accuracy: 0.7625\n",
            "Epoch 14/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4726 - binary_accuracy: 0.7682 - val_loss: 0.4660 - val_binary_accuracy: 0.7767\n",
            "Epoch 15/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4718 - binary_accuracy: 0.7670 - val_loss: 0.4986 - val_binary_accuracy: 0.7635\n",
            "Epoch 16/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4710 - binary_accuracy: 0.7700 - val_loss: 0.4973 - val_binary_accuracy: 0.7654\n",
            "Epoch 17/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4710 - binary_accuracy: 0.7684 - val_loss: 0.4847 - val_binary_accuracy: 0.7663\n",
            "Epoch 18/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4701 - binary_accuracy: 0.7699 - val_loss: 0.4627 - val_binary_accuracy: 0.7805\n",
            "Epoch 19/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4711 - binary_accuracy: 0.7667 - val_loss: 0.4818 - val_binary_accuracy: 0.7739\n",
            "Epoch 20/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4696 - binary_accuracy: 0.7731 - val_loss: 0.4844 - val_binary_accuracy: 0.7739\n",
            "Epoch 21/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4695 - binary_accuracy: 0.7682 - val_loss: 0.4766 - val_binary_accuracy: 0.7720\n",
            "Epoch 22/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4691 - binary_accuracy: 0.7737 - val_loss: 0.4754 - val_binary_accuracy: 0.7739\n",
            "Epoch 23/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4681 - binary_accuracy: 0.7724 - val_loss: 0.4926 - val_binary_accuracy: 0.7644\n",
            "Epoch 24/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4682 - binary_accuracy: 0.7692 - val_loss: 0.4809 - val_binary_accuracy: 0.7673\n",
            "Epoch 25/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4683 - binary_accuracy: 0.7726 - val_loss: 0.5067 - val_binary_accuracy: 0.7597\n",
            "Epoch 26/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4676 - binary_accuracy: 0.7695 - val_loss: 0.4864 - val_binary_accuracy: 0.7729\n",
            "Epoch 27/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4674 - binary_accuracy: 0.7713 - val_loss: 0.4779 - val_binary_accuracy: 0.7748\n",
            "Epoch 28/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4662 - binary_accuracy: 0.7717 - val_loss: 0.4954 - val_binary_accuracy: 0.7540\n",
            "Epoch 29/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4667 - binary_accuracy: 0.7707 - val_loss: 0.4792 - val_binary_accuracy: 0.7711\n",
            "Epoch 30/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4659 - binary_accuracy: 0.7671 - val_loss: 0.4580 - val_binary_accuracy: 0.7900\n",
            "Epoch 31/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4656 - binary_accuracy: 0.7742 - val_loss: 0.4687 - val_binary_accuracy: 0.7833\n",
            "Epoch 32/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4655 - binary_accuracy: 0.7700 - val_loss: 0.4597 - val_binary_accuracy: 0.7833\n",
            "Epoch 33/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4650 - binary_accuracy: 0.7721 - val_loss: 0.4771 - val_binary_accuracy: 0.7701\n",
            "Epoch 34/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4644 - binary_accuracy: 0.7691 - val_loss: 0.4631 - val_binary_accuracy: 0.7796\n",
            "Epoch 35/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4640 - binary_accuracy: 0.7714 - val_loss: 0.4879 - val_binary_accuracy: 0.7616\n",
            "Epoch 36/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4637 - binary_accuracy: 0.7733 - val_loss: 0.4773 - val_binary_accuracy: 0.7767\n",
            "Epoch 37/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4629 - binary_accuracy: 0.7743 - val_loss: 0.4614 - val_binary_accuracy: 0.7805\n",
            "Epoch 38/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4635 - binary_accuracy: 0.7743 - val_loss: 0.5001 - val_binary_accuracy: 0.7550\n",
            "Epoch 39/100\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.4621 - binary_accuracy: 0.7748 - val_loss: 0.4833 - val_binary_accuracy: 0.7682\n",
            "Epoch 40/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4625 - binary_accuracy: 0.7739 - val_loss: 0.4834 - val_binary_accuracy: 0.7711\n",
            "Epoch 41/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4620 - binary_accuracy: 0.7754 - val_loss: 0.4669 - val_binary_accuracy: 0.7777\n",
            "Epoch 42/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4607 - binary_accuracy: 0.7713 - val_loss: 0.4904 - val_binary_accuracy: 0.7663\n",
            "Epoch 43/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4609 - binary_accuracy: 0.7726 - val_loss: 0.4868 - val_binary_accuracy: 0.7739\n",
            "Epoch 44/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4611 - binary_accuracy: 0.7722 - val_loss: 0.4757 - val_binary_accuracy: 0.7673\n",
            "Epoch 45/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4597 - binary_accuracy: 0.7755 - val_loss: 0.4757 - val_binary_accuracy: 0.7758\n",
            "Epoch 46/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4603 - binary_accuracy: 0.7753 - val_loss: 0.4643 - val_binary_accuracy: 0.7824\n",
            "Epoch 47/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4600 - binary_accuracy: 0.7704 - val_loss: 0.4842 - val_binary_accuracy: 0.7654\n",
            "Epoch 48/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4587 - binary_accuracy: 0.7755 - val_loss: 0.5036 - val_binary_accuracy: 0.7493\n",
            "Epoch 49/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4590 - binary_accuracy: 0.7755 - val_loss: 0.4701 - val_binary_accuracy: 0.7729\n",
            "Epoch 50/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4588 - binary_accuracy: 0.7779 - val_loss: 0.4954 - val_binary_accuracy: 0.7465\n",
            "Epoch 51/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4583 - binary_accuracy: 0.7791 - val_loss: 0.5060 - val_binary_accuracy: 0.7465\n",
            "Epoch 52/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4584 - binary_accuracy: 0.7772 - val_loss: 0.4836 - val_binary_accuracy: 0.7616\n",
            "Epoch 53/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4583 - binary_accuracy: 0.7764 - val_loss: 0.4964 - val_binary_accuracy: 0.7531\n",
            "Epoch 54/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4578 - binary_accuracy: 0.7795 - val_loss: 0.4828 - val_binary_accuracy: 0.7663\n",
            "Epoch 55/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4575 - binary_accuracy: 0.7801 - val_loss: 0.4878 - val_binary_accuracy: 0.7569\n",
            "Epoch 56/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4565 - binary_accuracy: 0.7775 - val_loss: 0.4681 - val_binary_accuracy: 0.7777\n",
            "Epoch 57/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4573 - binary_accuracy: 0.7773 - val_loss: 0.4849 - val_binary_accuracy: 0.7701\n",
            "Epoch 58/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4567 - binary_accuracy: 0.7739 - val_loss: 0.4807 - val_binary_accuracy: 0.7701\n",
            "Epoch 59/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4565 - binary_accuracy: 0.7775 - val_loss: 0.4785 - val_binary_accuracy: 0.7682\n",
            "Epoch 60/100\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.4554 - binary_accuracy: 0.7805 - val_loss: 0.4938 - val_binary_accuracy: 0.7474\n",
            "Epoch 61/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4561 - binary_accuracy: 0.7768 - val_loss: 0.4859 - val_binary_accuracy: 0.7569\n",
            "Epoch 62/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4565 - binary_accuracy: 0.7775 - val_loss: 0.4804 - val_binary_accuracy: 0.7777\n",
            "Epoch 63/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4561 - binary_accuracy: 0.7754 - val_loss: 0.4971 - val_binary_accuracy: 0.7436\n",
            "Epoch 64/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4560 - binary_accuracy: 0.7760 - val_loss: 0.4967 - val_binary_accuracy: 0.7578\n",
            "Epoch 65/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4549 - binary_accuracy: 0.7820 - val_loss: 0.5046 - val_binary_accuracy: 0.7455\n",
            "Epoch 66/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4556 - binary_accuracy: 0.7789 - val_loss: 0.4937 - val_binary_accuracy: 0.7427\n",
            "Epoch 67/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4546 - binary_accuracy: 0.7795 - val_loss: 0.4838 - val_binary_accuracy: 0.7569\n",
            "Epoch 68/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4541 - binary_accuracy: 0.7784 - val_loss: 0.4946 - val_binary_accuracy: 0.7550\n",
            "Epoch 69/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4544 - binary_accuracy: 0.7798 - val_loss: 0.4843 - val_binary_accuracy: 0.7720\n",
            "Epoch 70/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4538 - binary_accuracy: 0.7773 - val_loss: 0.4906 - val_binary_accuracy: 0.7512\n",
            "Epoch 71/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4536 - binary_accuracy: 0.7784 - val_loss: 0.4981 - val_binary_accuracy: 0.7540\n",
            "Epoch 72/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4534 - binary_accuracy: 0.7768 - val_loss: 0.4823 - val_binary_accuracy: 0.7625\n",
            "Epoch 73/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4525 - binary_accuracy: 0.7775 - val_loss: 0.4951 - val_binary_accuracy: 0.7531\n",
            "Epoch 74/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4522 - binary_accuracy: 0.7809 - val_loss: 0.4934 - val_binary_accuracy: 0.7531\n",
            "Epoch 75/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4525 - binary_accuracy: 0.7818 - val_loss: 0.4959 - val_binary_accuracy: 0.7569\n",
            "Epoch 76/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4529 - binary_accuracy: 0.7804 - val_loss: 0.5106 - val_binary_accuracy: 0.7446\n",
            "Epoch 77/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4519 - binary_accuracy: 0.7816 - val_loss: 0.5243 - val_binary_accuracy: 0.7304\n",
            "Epoch 78/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4516 - binary_accuracy: 0.7818 - val_loss: 0.4977 - val_binary_accuracy: 0.7550\n",
            "Epoch 79/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4510 - binary_accuracy: 0.7804 - val_loss: 0.5004 - val_binary_accuracy: 0.7635\n",
            "Epoch 80/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4517 - binary_accuracy: 0.7822 - val_loss: 0.5048 - val_binary_accuracy: 0.7474\n",
            "Epoch 81/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4508 - binary_accuracy: 0.7805 - val_loss: 0.4768 - val_binary_accuracy: 0.7692\n",
            "Epoch 82/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4519 - binary_accuracy: 0.7813 - val_loss: 0.4845 - val_binary_accuracy: 0.7701\n",
            "Epoch 83/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4507 - binary_accuracy: 0.7819 - val_loss: 0.4896 - val_binary_accuracy: 0.7682\n",
            "Epoch 84/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4509 - binary_accuracy: 0.7784 - val_loss: 0.4850 - val_binary_accuracy: 0.7644\n",
            "Epoch 85/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4500 - binary_accuracy: 0.7816 - val_loss: 0.4707 - val_binary_accuracy: 0.7767\n",
            "Epoch 86/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4504 - binary_accuracy: 0.7816 - val_loss: 0.4991 - val_binary_accuracy: 0.7502\n",
            "Epoch 87/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4496 - binary_accuracy: 0.7838 - val_loss: 0.4838 - val_binary_accuracy: 0.7635\n",
            "Epoch 88/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4489 - binary_accuracy: 0.7856 - val_loss: 0.5057 - val_binary_accuracy: 0.7559\n",
            "Epoch 89/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4491 - binary_accuracy: 0.7855 - val_loss: 0.4705 - val_binary_accuracy: 0.7748\n",
            "Epoch 90/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4493 - binary_accuracy: 0.7812 - val_loss: 0.4820 - val_binary_accuracy: 0.7644\n",
            "Epoch 91/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4493 - binary_accuracy: 0.7833 - val_loss: 0.4838 - val_binary_accuracy: 0.7644\n",
            "Epoch 92/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4492 - binary_accuracy: 0.7841 - val_loss: 0.4710 - val_binary_accuracy: 0.7729\n",
            "Epoch 93/100\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 0.4487 - binary_accuracy: 0.7837 - val_loss: 0.5022 - val_binary_accuracy: 0.7588\n",
            "Epoch 94/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4482 - binary_accuracy: 0.7875 - val_loss: 0.5009 - val_binary_accuracy: 0.7512\n",
            "Epoch 95/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4483 - binary_accuracy: 0.7875 - val_loss: 0.5084 - val_binary_accuracy: 0.7502\n",
            "Epoch 96/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4470 - binary_accuracy: 0.7870 - val_loss: 0.5270 - val_binary_accuracy: 0.7408\n",
            "Epoch 97/100\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.4475 - binary_accuracy: 0.7842 - val_loss: 0.4953 - val_binary_accuracy: 0.7654\n",
            "Epoch 98/100\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4474 - binary_accuracy: 0.7858 - val_loss: 0.4803 - val_binary_accuracy: 0.7606\n",
            "Epoch 99/100\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.4463 - binary_accuracy: 0.7844 - val_loss: 0.5065 - val_binary_accuracy: 0.7531\n",
            "Epoch 100/100\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 0.4465 - binary_accuracy: 0.7848 - val_loss: 0.4984 - val_binary_accuracy: 0.7455\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f026c0d3c10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Trinando modelo\n",
        "model.fit(\n",
        "    x_train_res, \n",
        "    y_train_res,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_data=(x_validation, y_validation),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 - Resultados"
      ],
      "metadata": {
        "id": "Co7tOFUjzXbE"
      },
      "id": "Co7tOFUjzXbE"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "67d0ecb2",
      "metadata": {
        "id": "67d0ecb2",
        "outputId": "b8ed2c8c-ff2b-4c49-eaa1-55ad29333a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4946 - binary_accuracy: 0.7282\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4945721924304962, 0.7282196879386902]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Retorna acurácia e loss para conjunto de teste\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5a879555",
      "metadata": {
        "id": "5a879555",
        "outputId": "7f839197-d4b7-49cf-ef73-a9016ad05822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Prevê churn baseado no conjunto de teste\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Tranforma predições em 0 e 1\n",
        "prediction_list = []\n",
        "for i in predictions:\n",
        "    if i>0.5:\n",
        "        prediction_list.append(1)\n",
        "    else:\n",
        "        prediction_list.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "6e64cf57",
      "metadata": {
        "id": "6e64cf57",
        "outputId": "b3f0e001-849f-4adb-9771-bf6e3569ea18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.71      0.79       776\n",
            "           1       0.49      0.78      0.60       280\n",
            "\n",
            "    accuracy                           0.73      1056\n",
            "   macro avg       0.69      0.74      0.70      1056\n",
            "weighted avg       0.79      0.73      0.74      1056\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sb\n",
        "\n",
        "# imprime o classification report\n",
        "print(classification_report(y_test, prediction_list))\n",
        "\n",
        "# plota a confusion matrix\n",
        "conf_mat = tf.math.confusion_matrix(labels=y_test,predictions=prediction_list)\n",
        "plt.figure(figsize = (10,4))\n",
        "sb.heatmap(conf_mat, annot=True,fmt='d')\n",
        "plt.xlabel('Predicted_churn')\n",
        "plt.ylabel('True_churn')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nosso modelo obteve uma baixa precisão (49%) ao prever usuários que cancelaram o serviço, o que nos leva a crer que nosso modelo não serviu ao seu propósito, porém, quando olhamos para o recall, que é a medida entre total de valores reais e valores preditos, obtivemos 78% para os usuários que cancelaram o serviço. Na prática, isso significa que muitos usuários que não tendem a cancelar o serviço seriam classificados como usuários que tendem a cancelar, mas em contrapartida, poucos usuários que tendem a cancelar o serviço são classificados como usuários que não tendem a cancelar. Para fins de comparação, vamos testar o dataset de treino sem o oversample."
      ],
      "metadata": {
        "id": "NfxxuBztziEI"
      },
      "id": "NfxxuBztziEI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando modelo sem oversample"
      ],
      "metadata": {
        "id": "-Wo9kqPAv51E"
      },
      "id": "-Wo9kqPAv51E"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f87e2b83",
      "metadata": {
        "id": "f87e2b83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac3f761-f866-4630-e203-35f22f0e72f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.4029 - binary_accuracy: 0.8114 - val_loss: 0.4475 - val_binary_accuracy: 0.7852\n",
            "Epoch 2/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3967 - binary_accuracy: 0.8099 - val_loss: 0.4514 - val_binary_accuracy: 0.7862\n",
            "Epoch 3/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3961 - binary_accuracy: 0.8146 - val_loss: 0.4484 - val_binary_accuracy: 0.7909\n",
            "Epoch 4/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3968 - binary_accuracy: 0.8126 - val_loss: 0.4475 - val_binary_accuracy: 0.7928\n",
            "Epoch 5/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3953 - binary_accuracy: 0.8172 - val_loss: 0.4563 - val_binary_accuracy: 0.7786\n",
            "Epoch 6/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3958 - binary_accuracy: 0.8118 - val_loss: 0.4593 - val_binary_accuracy: 0.7796\n",
            "Epoch 7/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3949 - binary_accuracy: 0.8101 - val_loss: 0.4479 - val_binary_accuracy: 0.7928\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3959 - binary_accuracy: 0.8144 - val_loss: 0.4472 - val_binary_accuracy: 0.7852\n",
            "Epoch 9/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3934 - binary_accuracy: 0.8164 - val_loss: 0.4487 - val_binary_accuracy: 0.7900\n",
            "Epoch 10/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3946 - binary_accuracy: 0.8156 - val_loss: 0.4493 - val_binary_accuracy: 0.7881\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3929 - binary_accuracy: 0.8144 - val_loss: 0.4480 - val_binary_accuracy: 0.7862\n",
            "Epoch 12/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3949 - binary_accuracy: 0.8146 - val_loss: 0.4479 - val_binary_accuracy: 0.7871\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3941 - binary_accuracy: 0.8146 - val_loss: 0.4485 - val_binary_accuracy: 0.7881\n",
            "Epoch 14/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3952 - binary_accuracy: 0.8158 - val_loss: 0.4516 - val_binary_accuracy: 0.7871\n",
            "Epoch 15/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3940 - binary_accuracy: 0.8160 - val_loss: 0.4546 - val_binary_accuracy: 0.7843\n",
            "Epoch 16/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3924 - binary_accuracy: 0.8134 - val_loss: 0.4495 - val_binary_accuracy: 0.7881\n",
            "Epoch 17/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3939 - binary_accuracy: 0.8158 - val_loss: 0.4487 - val_binary_accuracy: 0.7928\n",
            "Epoch 18/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3935 - binary_accuracy: 0.8193 - val_loss: 0.4487 - val_binary_accuracy: 0.7852\n",
            "Epoch 19/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3938 - binary_accuracy: 0.8164 - val_loss: 0.4513 - val_binary_accuracy: 0.7890\n",
            "Epoch 20/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3937 - binary_accuracy: 0.8118 - val_loss: 0.4501 - val_binary_accuracy: 0.7852\n",
            "Epoch 21/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3931 - binary_accuracy: 0.8152 - val_loss: 0.4527 - val_binary_accuracy: 0.7862\n",
            "Epoch 22/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3938 - binary_accuracy: 0.8172 - val_loss: 0.4494 - val_binary_accuracy: 0.7909\n",
            "Epoch 23/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3935 - binary_accuracy: 0.8174 - val_loss: 0.4523 - val_binary_accuracy: 0.7852\n",
            "Epoch 24/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3934 - binary_accuracy: 0.8146 - val_loss: 0.4511 - val_binary_accuracy: 0.7890\n",
            "Epoch 25/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3925 - binary_accuracy: 0.8181 - val_loss: 0.4581 - val_binary_accuracy: 0.7852\n",
            "Epoch 26/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3919 - binary_accuracy: 0.8132 - val_loss: 0.4544 - val_binary_accuracy: 0.7824\n",
            "Epoch 27/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3920 - binary_accuracy: 0.8160 - val_loss: 0.4542 - val_binary_accuracy: 0.7871\n",
            "Epoch 28/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3928 - binary_accuracy: 0.8162 - val_loss: 0.4605 - val_binary_accuracy: 0.7815\n",
            "Epoch 29/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3916 - binary_accuracy: 0.8185 - val_loss: 0.4560 - val_binary_accuracy: 0.7843\n",
            "Epoch 30/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3922 - binary_accuracy: 0.8140 - val_loss: 0.4541 - val_binary_accuracy: 0.7919\n",
            "Epoch 31/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3926 - binary_accuracy: 0.8156 - val_loss: 0.4528 - val_binary_accuracy: 0.7871\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3922 - binary_accuracy: 0.8152 - val_loss: 0.4529 - val_binary_accuracy: 0.7871\n",
            "Epoch 33/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3913 - binary_accuracy: 0.8162 - val_loss: 0.4576 - val_binary_accuracy: 0.7852\n",
            "Epoch 34/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3935 - binary_accuracy: 0.8138 - val_loss: 0.4540 - val_binary_accuracy: 0.7890\n",
            "Epoch 35/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3905 - binary_accuracy: 0.8162 - val_loss: 0.4553 - val_binary_accuracy: 0.7767\n",
            "Epoch 36/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3915 - binary_accuracy: 0.8164 - val_loss: 0.4542 - val_binary_accuracy: 0.7815\n",
            "Epoch 37/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3914 - binary_accuracy: 0.8199 - val_loss: 0.4521 - val_binary_accuracy: 0.7890\n",
            "Epoch 38/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3919 - binary_accuracy: 0.8162 - val_loss: 0.4533 - val_binary_accuracy: 0.7824\n",
            "Epoch 39/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3914 - binary_accuracy: 0.8166 - val_loss: 0.4522 - val_binary_accuracy: 0.7862\n",
            "Epoch 40/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3916 - binary_accuracy: 0.8181 - val_loss: 0.4532 - val_binary_accuracy: 0.7843\n",
            "Epoch 41/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3908 - binary_accuracy: 0.8185 - val_loss: 0.4535 - val_binary_accuracy: 0.7852\n",
            "Epoch 42/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3901 - binary_accuracy: 0.8209 - val_loss: 0.4545 - val_binary_accuracy: 0.7824\n",
            "Epoch 43/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3912 - binary_accuracy: 0.8174 - val_loss: 0.4513 - val_binary_accuracy: 0.7862\n",
            "Epoch 44/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8166 - val_loss: 0.4546 - val_binary_accuracy: 0.7871\n",
            "Epoch 45/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3906 - binary_accuracy: 0.8181 - val_loss: 0.4522 - val_binary_accuracy: 0.7852\n",
            "Epoch 46/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3904 - binary_accuracy: 0.8150 - val_loss: 0.4519 - val_binary_accuracy: 0.7881\n",
            "Epoch 47/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3897 - binary_accuracy: 0.8199 - val_loss: 0.4538 - val_binary_accuracy: 0.7881\n",
            "Epoch 48/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8166 - val_loss: 0.4528 - val_binary_accuracy: 0.7852\n",
            "Epoch 49/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8144 - val_loss: 0.4519 - val_binary_accuracy: 0.7843\n",
            "Epoch 50/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3894 - binary_accuracy: 0.8185 - val_loss: 0.4569 - val_binary_accuracy: 0.7871\n",
            "Epoch 51/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3894 - binary_accuracy: 0.8158 - val_loss: 0.4566 - val_binary_accuracy: 0.7843\n",
            "Epoch 52/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3894 - binary_accuracy: 0.8150 - val_loss: 0.4558 - val_binary_accuracy: 0.7805\n",
            "Epoch 53/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3901 - binary_accuracy: 0.8152 - val_loss: 0.4549 - val_binary_accuracy: 0.7824\n",
            "Epoch 54/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3897 - binary_accuracy: 0.8154 - val_loss: 0.4543 - val_binary_accuracy: 0.7852\n",
            "Epoch 55/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3896 - binary_accuracy: 0.8183 - val_loss: 0.4559 - val_binary_accuracy: 0.7796\n",
            "Epoch 56/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3889 - binary_accuracy: 0.8168 - val_loss: 0.4547 - val_binary_accuracy: 0.7833\n",
            "Epoch 57/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8174 - val_loss: 0.4569 - val_binary_accuracy: 0.7852\n",
            "Epoch 58/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3893 - binary_accuracy: 0.8211 - val_loss: 0.4592 - val_binary_accuracy: 0.7852\n",
            "Epoch 59/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3907 - binary_accuracy: 0.8156 - val_loss: 0.4560 - val_binary_accuracy: 0.7824\n",
            "Epoch 60/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3880 - binary_accuracy: 0.8189 - val_loss: 0.4572 - val_binary_accuracy: 0.7852\n",
            "Epoch 61/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3889 - binary_accuracy: 0.8185 - val_loss: 0.4549 - val_binary_accuracy: 0.7796\n",
            "Epoch 62/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3895 - binary_accuracy: 0.8191 - val_loss: 0.4599 - val_binary_accuracy: 0.7796\n",
            "Epoch 63/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3882 - binary_accuracy: 0.8187 - val_loss: 0.4554 - val_binary_accuracy: 0.7833\n",
            "Epoch 64/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3889 - binary_accuracy: 0.8207 - val_loss: 0.4550 - val_binary_accuracy: 0.7824\n",
            "Epoch 65/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3896 - binary_accuracy: 0.8162 - val_loss: 0.4562 - val_binary_accuracy: 0.7805\n",
            "Epoch 66/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3887 - binary_accuracy: 0.8142 - val_loss: 0.4586 - val_binary_accuracy: 0.7852\n",
            "Epoch 67/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3882 - binary_accuracy: 0.8201 - val_loss: 0.4573 - val_binary_accuracy: 0.7833\n",
            "Epoch 68/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3893 - binary_accuracy: 0.8191 - val_loss: 0.4581 - val_binary_accuracy: 0.7796\n",
            "Epoch 69/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3885 - binary_accuracy: 0.8170 - val_loss: 0.4588 - val_binary_accuracy: 0.7796\n",
            "Epoch 70/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3869 - binary_accuracy: 0.8193 - val_loss: 0.4568 - val_binary_accuracy: 0.7805\n",
            "Epoch 71/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3874 - binary_accuracy: 0.8213 - val_loss: 0.4587 - val_binary_accuracy: 0.7833\n",
            "Epoch 72/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3883 - binary_accuracy: 0.8207 - val_loss: 0.4561 - val_binary_accuracy: 0.7881\n",
            "Epoch 73/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8185 - val_loss: 0.4585 - val_binary_accuracy: 0.7881\n",
            "Epoch 74/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3889 - binary_accuracy: 0.8176 - val_loss: 0.4556 - val_binary_accuracy: 0.7843\n",
            "Epoch 75/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3881 - binary_accuracy: 0.8193 - val_loss: 0.4555 - val_binary_accuracy: 0.7833\n",
            "Epoch 76/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3877 - binary_accuracy: 0.8207 - val_loss: 0.4560 - val_binary_accuracy: 0.7824\n",
            "Epoch 77/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3876 - binary_accuracy: 0.8150 - val_loss: 0.4559 - val_binary_accuracy: 0.7852\n",
            "Epoch 78/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3865 - binary_accuracy: 0.8209 - val_loss: 0.4568 - val_binary_accuracy: 0.7843\n",
            "Epoch 79/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3871 - binary_accuracy: 0.8189 - val_loss: 0.4581 - val_binary_accuracy: 0.7862\n",
            "Epoch 80/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3878 - binary_accuracy: 0.8197 - val_loss: 0.4632 - val_binary_accuracy: 0.7777\n",
            "Epoch 81/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3875 - binary_accuracy: 0.8195 - val_loss: 0.4577 - val_binary_accuracy: 0.7824\n",
            "Epoch 82/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3874 - binary_accuracy: 0.8213 - val_loss: 0.4615 - val_binary_accuracy: 0.7833\n",
            "Epoch 83/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3892 - binary_accuracy: 0.8142 - val_loss: 0.4609 - val_binary_accuracy: 0.7805\n",
            "Epoch 84/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3873 - binary_accuracy: 0.8199 - val_loss: 0.4662 - val_binary_accuracy: 0.7815\n",
            "Epoch 85/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3866 - binary_accuracy: 0.8197 - val_loss: 0.4578 - val_binary_accuracy: 0.7871\n",
            "Epoch 86/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3868 - binary_accuracy: 0.8178 - val_loss: 0.4558 - val_binary_accuracy: 0.7843\n",
            "Epoch 87/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3850 - binary_accuracy: 0.8199 - val_loss: 0.4716 - val_binary_accuracy: 0.7739\n",
            "Epoch 88/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3863 - binary_accuracy: 0.8215 - val_loss: 0.4587 - val_binary_accuracy: 0.7824\n",
            "Epoch 89/100\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 0.3877 - binary_accuracy: 0.8203 - val_loss: 0.4605 - val_binary_accuracy: 0.7833\n",
            "Epoch 90/100\n",
            "155/155 [==============================] - 1s 5ms/step - loss: 0.3872 - binary_accuracy: 0.8197 - val_loss: 0.4580 - val_binary_accuracy: 0.7862\n",
            "Epoch 91/100\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.3872 - binary_accuracy: 0.8195 - val_loss: 0.4615 - val_binary_accuracy: 0.7871\n",
            "Epoch 92/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3861 - binary_accuracy: 0.8199 - val_loss: 0.4635 - val_binary_accuracy: 0.7852\n",
            "Epoch 93/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3864 - binary_accuracy: 0.8193 - val_loss: 0.4588 - val_binary_accuracy: 0.7890\n",
            "Epoch 94/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3859 - binary_accuracy: 0.8207 - val_loss: 0.4616 - val_binary_accuracy: 0.7815\n",
            "Epoch 95/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3863 - binary_accuracy: 0.8178 - val_loss: 0.4589 - val_binary_accuracy: 0.7862\n",
            "Epoch 96/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3864 - binary_accuracy: 0.8176 - val_loss: 0.4579 - val_binary_accuracy: 0.7815\n",
            "Epoch 97/100\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 0.3868 - binary_accuracy: 0.8189 - val_loss: 0.4627 - val_binary_accuracy: 0.7815\n",
            "Epoch 98/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3855 - binary_accuracy: 0.8197 - val_loss: 0.4606 - val_binary_accuracy: 0.7805\n",
            "Epoch 99/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3867 - binary_accuracy: 0.8221 - val_loss: 0.4617 - val_binary_accuracy: 0.7824\n",
            "Epoch 100/100\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 0.3857 - binary_accuracy: 0.8178 - val_loss: 0.4608 - val_binary_accuracy: 0.7871\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f026c316070>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Trinando modelo sem oversample\n",
        "model.fit(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_data=(x_validation, y_validation),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retorna acurácia e loss para conjunto de teste\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRRrhiLZ1-UA",
        "outputId": "5cdd37cc-0f09-4974-c294-b33767c51a2b"
      },
      "id": "cRRrhiLZ1-UA",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4304 - binary_accuracy: 0.7888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43039318919181824, 0.7888257503509521]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevê churn baseado no conjunto de teste\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Tranforma predições em 0 e 1\n",
        "prediction_list = []\n",
        "for i in predictions:\n",
        "    if i>0.5:\n",
        "        prediction_list.append(1)\n",
        "    else:\n",
        "        prediction_list.append(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXkvs8Qh2BOG",
        "outputId": "b41dd2b5-b424-4948-8c58-97a1706f5fbd"
      },
      "id": "DXkvs8Qh2BOG",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imprime o classification report\n",
        "print(classification_report(y_test, prediction_list))\n",
        "\n",
        "# plota a confusion matrix\n",
        "conf_mat = tf.math.confusion_matrix(labels=y_test,predictions=prediction_list)\n",
        "plt.figure(figsize = (10,4))\n",
        "sb.heatmap(conf_mat, annot=True,fmt='d')\n",
        "plt.xlabel('Predicted_churn')\n",
        "plt.ylabel('True_churn')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "nht3X1mU2LjA",
        "outputId": "a39d63a2-4e36-4545-f61d-bf6764c1e7e6"
      },
      "id": "nht3X1mU2LjA",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86       776\n",
            "           1       0.64      0.46      0.54       280\n",
            "\n",
            "    accuracy                           0.79      1056\n",
            "   macro avg       0.73      0.68      0.70      1056\n",
            "weighted avg       0.78      0.79      0.78      1056\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando os resultados, temos uma acurácia muito superior em relação ao modelo anterior, mas quando olhamos para o recall do modelo, é de apenas 46% para os usuários que cancelaram o serviço, uma queda drástica em relação ao modelo com oversampler. Mas na prática, qual modelo seria melhor? Acredito que isso iria depender de quais os seus objetivos com seu modelo. Por exemplo, se você é dono de uma empresa e quer reduzir o churn de clientes, gastando o mínimo possível, provavelmente o modelo que apresenta maior acurácia é a melhor opção. Todavia, se você quer reduzir ao máximo o churn de clientes, o modelo de maior recall seria a escolha mais provável. Em resumo, ambos os modelos tem suas aplicações, considerando as diferentes situações em que são utilizados."
      ],
      "metadata": {
        "id": "63FJ3p7E4BVJ"
      },
      "id": "63FJ3p7E4BVJ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
